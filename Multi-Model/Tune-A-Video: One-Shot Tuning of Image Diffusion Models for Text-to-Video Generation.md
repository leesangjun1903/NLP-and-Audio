
# Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation
## Executive Summary
"Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation"ì€ 2022ë…„ ë°œí‘œëœ í˜ì‹ ì  ì—°êµ¬ë¡œ, ë‹¨ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸-ë¹„ë””ì˜¤ ìŒì„ ì´ìš©í•˜ì—¬ ì‚¬ì „í•™ìŠµëœ T2I ëª¨ë¸ì„ T2V ìƒì„±ê¸°ë¡œ ë³€í™˜í•˜ëŠ” íš¨ìœ¨ì  ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤. ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ë¹„ë””ì˜¤ ë°ì´í„°ì…‹ì— ì˜ì¡´í•˜ë˜ ê¸°ì¡´ T2V ìƒì„± íŒ¨ëŸ¬ë‹¤ì„ì„ ê·¼ë³¸ì ìœ¼ë¡œ ì¬ì„¤ê³„í•˜ì—¬, ê°œì¸ ì‚¬ìš©ì ìˆ˜ì¤€ì˜ GPU ë¦¬ì†ŒìŠ¤(A100 1ì¥)ë¡œ 10ë¶„ ë‚´ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ë¹„ë””ì˜¤ ìƒì„±ì„ ê°€ëŠ¥í•˜ê²Œ í–ˆìŠµë‹ˆë‹¤. 

**í•µì‹¬ ê¸°ì—¬:** (1) One-Shot Video Tuning ì„¤ì • ë„ì…, (2) Sparse Spatio-Temporal Attention (ST-Attn) ë©”ì»¤ë‹ˆì¦˜ ì œì•ˆìœ¼ë¡œ ê³„ì‚° ë³µì¡ë„ O(mÂ²NÂ²) â†’ O(2mNÂ²)ë¡œ ê°ì†Œ, (3) ì„ íƒì  íŒŒë¼ë¯¸í„° ë¯¸ì„¸ì¡°ì • ì „ëµ, (4) DDIM inversionì„ í†µí•œ êµ¬ì¡° ì§€ë„ ê¸°ë²•.

***

## 1. í•µì‹¬ ì£¼ì¥ ë° ì£¼ìš” ê¸°ì—¬
### 1.1 ë¬¸ì œ ì •ì˜
ê¸°ì¡´ í…ìŠ¤íŠ¸-ë¹„ë””ì˜¤(T2V) ìƒì„± ëª¨ë¸ì€ ë‹¤ìŒê³¼ ê°™ì€ ê·¼ë³¸ì  í•œê³„ë¥¼ ë³´ì…ë‹ˆë‹¤:

**ê³„ì‚° ë¹„ìš©:** WebVid-10M ê°™ì€ ëŒ€ê·œëª¨ ë¹„ë””ì˜¤ ë°ì´í„°ì…‹ì— ìˆ˜ì£¼ê°„ í•™ìŠµ í•„ìš” (GPU ìˆ˜ì‹­-ìˆ˜ë°± ì¥)

**ë°ì´í„° ì˜ì¡´ì„±:** ë°±ë§Œ ê°œ ì´ìƒì˜ ìŒì„ ì´ë£¬ í…ìŠ¤íŠ¸-ë¹„ë””ì˜¤ ë°ì´í„° í•„ìˆ˜

**í™˜ê²½ ë¹„ìš©:** ë§‰ëŒ€í•œ ì—ë„ˆì§€ ì†Œë¹„ë¡œ ì¸í•œ íƒ„ì†Œ ë°°ì¶œ

**ì ‘ê·¼ì„± ì œì•½:** ëŒ€í˜• ê¸°ì—… ì‹¤í—˜ì‹¤ë§Œ ì ‘ê·¼ ê°€ëŠ¥

### 1.2 í•µì‹¬ ê´€ì°° (Key Insights)
ì €ìë“¤ì€ ì‚¬ì „í•™ìŠµëœ T2I ëª¨ë¸ì˜ ë‘ ê°€ì§€ íŠ¹ì„±ì„ ë°œê²¬í•©ë‹ˆë‹¤:

**ê´€ì°° 1: ë™ì‚¬ í‘œí˜„ ëŠ¥ë ¥**
T2I ëª¨ë¸ì€ ì •ì  ì´ë¯¸ì§€ì—ì„œë„ "ë‹¬ë¦¬ê¸°", "ì¶¤ì¶”ê¸°" ê°™ì€ ë™ì‘ì„ ì •í™•íˆ í‘œí˜„í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, "ë‚¨ìê°€ í•´ë³€ì—ì„œ ë‹¬ë¦¬ê³  ìˆë‹¤"ë¼ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ë°›ìœ¼ë©´, ëª¨ë¸ì€ ë‹¨ìˆœíˆ ë‚¨ìì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ "ë‹¬ë¦¬ëŠ” í¬ì¦ˆ"ì˜ ë‚¨ìë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ëŠ” T2Iì˜ êµì°¨ ëª¨ë‹¬ ì£¼ì˜(cross-modal attention)ê°€ ë™ì‚¬ê¹Œì§€ í¬ì°©í•¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

**ê´€ì°° 2: ìë™ ì¼ê´€ì„±**
Spatial self-attentionì„ ì—¬ëŸ¬ í”„ë ˆì„ì— ê±¸ì³ í™•ì¥í•˜ë©´, ëª…ì‹œì ì¸ ì‹œê°„ì  ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ ì—†ì´ë„ ê°™ì€ ê°ì²´ê°€ ëª¨ë“  í”„ë ˆì„ì—ì„œ ì¼ê´€ë˜ê²Œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤. ì´ëŠ” self-attentionì´ í”½ì…€ ìœ„ì¹˜ê°€ ì•„ë‹Œ **íŠ¹ì§• ìœ ì‚¬ì„±**ì— ê¸°ë°˜í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

ì´ ë‘ ê´€ì°°ì´ One-Shot Video Tuning ê°œë…ì˜ í† ëŒ€ê°€ ë©ë‹ˆë‹¤.

### 1.3 ì£¼ìš” ê¸°ì—¬
**1) One-Shot Video Tuning íŒ¨ëŸ¬ë‹¤ì„ ë„ì…**
- ìµœì´ˆë¡œ ëŒ€ê·œëª¨ ë¹„ë””ì˜¤ ë°ì´í„° ì—†ì´ T2V ìƒì„± ë‹¬ì„±
- ë‹¨ 1ê°œ ë¹„ë””ì˜¤-í…ìŠ¤íŠ¸ ìŒìœ¼ë¡œ í•™ìŠµ

**2) Sparse Spatio-Temporal Attention (ST-Attn)**
- ì „ì²´ ì£¼ì˜(full attention) ëŒ€ë¹„ ê³„ì‚° ë³µì¡ë„ íšê¸°ì  ê°ì†Œ
- ì²« í”„ë ˆì„ê³¼ ì´ì „ í”„ë ˆì„ë§Œ ì°¸ì¡°í•˜ëŠ” ì˜ë¦¬í•œ ì„¤ê³„

**3) íš¨ìœ¨ì  ë¯¸ì„¸ì¡°ì • ì „ëµ**
- í”„ë¡œì ì…˜ í–‰ë ¬(W_Q)ë§Œ ì—…ë°ì´íŠ¸
- ì‚¬ì „í•™ìŠµ ì§€ì‹ ë³´ì¡´ + ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê·¹ëŒ€í™”

**4) DDIM Inversion êµ¬ì¡° ì§€ë„**
- ì…ë ¥ ë¹„ë””ì˜¤ì˜ ì›€ì§ì„ íŒ¨í„´ì„ ìƒˆ í…ìŠ¤íŠ¸ì— ë”°ë¼ ë³€í˜•
- ê³µê°„ì  ì¼ê´€ì„± + ì‹œê°„ì  ì—°ì†ì„± ë™ì‹œ ë‹¬ì„±

**5) ê´‘ë²”ìœ„í•œ ì‘ìš© í˜¸í™˜ì„±**
- DreamBoothì™€ ê²°í•© â†’ ê°œì¸í™”ëœ ë¹„ë””ì˜¤ ìƒì„±
- T2I-Adapterì™€ ê²°í•© â†’ ì¡°ê±´ë¶€ ì œì–´ (í¬ì¦ˆ, ê¹Šì´ ë“±)
- í”ŒëŸ¬ê·¸ ì•¤ í”Œë ˆì´ ë°©ì‹ìœ¼ë¡œ ê¸°ì¡´ T2I ëª¨ë¸ê³¼ í†µí•©

***

## 2. í•´ê²°í•˜ëŠ” ë¬¸ì œì™€ ì œì•ˆ ë°©ë²• (ìƒì„¸ ê¸°ìˆ )
### 2.1 ê¸°ìˆ ì  ë¬¸ì œ ë¶„ì„
#### ë¬¸ì œ 1: ê³„ì‚° ë³µì¡ë„

T2I ëª¨ë¸ì„ ë‹¨ìˆœíˆ ì‹œê³µê°„(spatio-temporal) ì˜ì—­ìœ¼ë¡œ í™•ì¥í•˜ë©´:

$$\text{Complexity}_{\text{full attention}} = O(m \times N^2)$$

ì—¬ê¸°ì„œ:
- m = ë¹„ë””ì˜¤ í”„ë ˆì„ ìˆ˜
- N = ê° í”„ë ˆì„ë‹¹ íŒ¨ì¹˜/í† í° ìˆ˜

ì˜ˆ: 32í”„ë ˆì„ Ã— 256Ã—256 í•´ìƒë„ = m=32, Nâ‰ˆ1024
- ê³„ì‚°ëŸ‰: 32 Ã— 1024Â² = ì•½ 3,350ë§Œ ì—°ì‚°

ì´ëŠ” 32ë°° í”„ë ˆì„ë§Œìœ¼ë¡œë„ ë‹¨ì¼ ì´ë¯¸ì§€ì˜ 1024ë°° ê³„ì‚°ì´ í•„ìš”í•¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

#### ë¬¸ì œ 2: ì‚¬ì „í•™ìŠµ ì§€ì‹ ì†ìƒ

Naive fine-tuning (ëª¨ë“  íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸):
- U-Netì˜ ëª¨ë“  convolutional block ì—…ë°ì´íŠ¸
- Attention layerì˜ ëª¨ë“  ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
- ê²°ê³¼: T2Iì˜ ê´‘ë²”ìœ„í•œ ê°œë… ì§€ì‹ ë®ì–´ì“°ê¸° ìœ„í—˜

#### ë¬¸ì œ 3: ì‹œê°„ì  ì—°ì†ì„± ë¶€ì¬

Spatial consistencyëŠ” ìë™ìœ¼ë¡œ ìœ ì§€ë˜ì§€ë§Œ:
- ê°ì²´ëŠ” ì¼ê´€ë˜ë‚˜ ì›€ì§ì„ ì—†ìŒ (ì •ì§€ ë¹„ë””ì˜¤)
- í”„ë ˆì„ ê°„ ë¬¼ë¦¬ì  ì—°ì†ì„± ë¶€ì¬

### 2.2 Spatio-Temporal Attention ë©”ì»¤ë‹ˆì¦˜ (ìƒì„¸)
#### ê¸°ì¡´ Spatial Self-Attention

$$\text{Attention}(Q, K, V) = \text{Softmax}\left(\frac{Q K^T}{\sqrt{d}}\right)V$$

ê° í”„ë ˆì„ ë‚´ì—ì„œë§Œ ì‘ë™:
$$Q = W_Q z_v, \quad K = W_K z_v, \quad V = W_V z_v$$

#### ì œì•ˆëœ Sparse Spatio-Temporal Attention

$$\text{ST-Attn}(Q, K, V) = \text{Softmax}\left(\frac{Q (K_1 \parallel K_{i-1})^T}{\sqrt{d}}\right) (V_1 \parallel V_{i-1})$$

**í•µì‹¬ ì„¤ê³„:**
$$Q = W_Q z_{v_i} \quad \text{(í˜„ì¬ í”„ë ˆì„ì—ì„œ Query)}$$
$$K = W_K [z_{v_1} \parallel z_{v_{i-1}}] \quad \text{(ì²« í”„ë ˆì„ê³¼ ì´ì „ í”„ë ˆì„)}$$
$$V = W_V [z_{v_1} \parallel z_{v_{i-1}}]$$

**ì§ê´€:**
- ì²« í”„ë ˆì„: ì „ì—­ êµ¬ì¡° ì°¸ì¡° (ë°°ê²½, ì¥ë©´ ë§¥ë½)
- ì´ì „ í”„ë ˆì„: ì¦‰ì‹œ ë™ì‘ ì—°ì†ì„± (ì›€ì§ì„ ê¶¤ì )
- ì´ ë‘ ì •ë³´ë§Œìœ¼ë¡œ ì¶©ë¶„í•œ ì‹œê°„ì  ëª¨ë¸ë§ ê°€ëŠ¥

**ê³„ì‚° ë³µì¡ë„ ë¶„ì„:**

| ì£¼ì˜ ìœ í˜• | ì¿¼ë¦¬ | í‚¤/ê°’ | ë³µì¡ë„ | ì„¤ëª… |
|---------|------|------|------|------|
| Spatial | 1 í”„ë ˆì„ | 1 í”„ë ˆì„ | $O(N^2)$ | ê¸°ì¡´ T2I |
| Full ST | m í”„ë ˆì„ | m í”„ë ˆì„ | $O(m^2 N^2)$ | ëª¨ë“  í”„ë ˆì„ ìƒí˜¸ì‘ìš© |
| Causal | m í”„ë ˆì„ | m í”„ë ˆì„ (ëˆ„ì ) | $O(m^2 N^2)$ | ëª¨ë“  ì´ì „ í”„ë ˆì„ |
| **Sparse (ì œì•ˆ)** | **m í”„ë ˆì„** | **2 í”„ë ˆì„ ê³ ì •** | **$O(2mN^2)$** | ì„ í˜• ë³µì¡ë„ |

**ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±:**
- 32í”„ë ˆì„ ê¸°ì¤€: Full attention ëŒ€ë¹„ 16ë°° ê°ì†Œ

#### í”„ë¡œì ì…˜ í–‰ë ¬ ê³µìœ  ë©”ì»¤ë‹ˆì¦˜

$$W_Q, W_K, W_V \text{ëŠ” ëª¨ë“  í”„ë ˆì„ì—ì„œ ë™ì¼ (Weight Sharing)}$$

**ì´ì :**
- ì¶”ê°€ íŒŒë¼ë¯¸í„° 0 (ê¸°ì¡´ W_Q, W_K, W_V ì¬ì‚¬ìš©)
- ì‹œê°„ ë¶ˆë³€ì„±(Temporal Invariance) ë³´ì¥
- ê¹”ë”í•œ ì¼ë°˜í™”

### 2.3 íš¨ìœ¨ì  ë¯¸ì„¸ì¡°ì • ì „ëµ (Fine-Tuning)
#### ì„ íƒì  íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ ì „ëµ

ë…¼ë¬¸ì€ ë§¤ìš° ì˜ë¦¬í•œ ì„ íƒì„ í•©ë‹ˆë‹¤:

**ì—…ë°ì´íŠ¸í•  íŒŒë¼ë¯¸í„°:**
1. **Spatial Self-Attentionì˜ Query projection** ($W_Q^{\text{spatial}}$)
   - í…ìŠ¤íŠ¸ ì •ë³´ ì¬ì •ë ¬ì— í•„ìˆ˜
   - Key/ValueëŠ” ê³ ì • (ê³µê°„ì  íŠ¹ì§• ë³´ì¡´)

2. **Spatio-Temporal Attentionì˜ Query projection** ($W_Q^{\text{ST}}$)
   - í…ìŠ¤íŠ¸-ë¹„ë””ì˜¤ ì •ë ¬ ì¡°ì •
   - Key/ValueëŠ” ê³ ì • (ì‹œê°„ êµ¬ì¡° ë³´ì¡´)

3. **Cross-Attentionì˜ Query projection** ($W_Q^{\text{cross}}$)
   - í…ìŠ¤íŠ¸ ì„ë² ë”©ê³¼ ì‹œê° íŠ¹ì§• ì •ë ¬
   - Key/ValueëŠ” ê³ ì • (CLIP ì„ë² ë”© ë³´ì¡´)

4. **ì „ì²´ Temporal Self-Attention** (ì‹ ê·œ ë ˆì´ì–´)
   - ìƒˆë¡œ ì¶”ê°€ë˜ë¯€ë¡œ ì „ì²´ í•™ìŠµ
   - í”„ë ˆì„ ê°„ ì›€ì§ì„ ëª¨ë¸ë§

**ë™ê²°í•  íŒŒë¼ë¯¸í„°:**
- ëª¨ë“  Key/Value projection
- ëª¨ë“  Convolutional block
- í…ìŠ¤íŠ¸ ì¸ì½”ë”

#### ìˆ˜ì‹ì  í‘œí˜„

**ì†ì‹¤ í•¨ìˆ˜:**

$$\mathcal{L} = \mathbb{E}_{z, \epsilon \sim \mathcal{N}(0,I), t, c} \left[\|\epsilon - \epsilon_\theta(z_t, t, c)\|_2^2\right]$$

í‘œì¤€ Latent Diffusion Model ì†ì‹¤ê³¼ ë™ì¼ (ìƒˆë¡œìš´ ì†ì‹¤ í•¨ìˆ˜ ë¶ˆí•„ìš”)

**í•™ìŠµ ì„¤ì •:**
- ìµœì í™”: AdamW
- í•™ìŠµë¥ : 3Ã—10â»âµ
- ë°°ì¹˜ í¬ê¸°: 1 (ë©”ëª¨ë¦¬ íš¨ìœ¨)
- ìŠ¤í…: 500 (ì•½ 10ë¶„)
- ë°ì´í„°: 1ê°œ ë¹„ë””ì˜¤ì˜ 32í”„ë ˆì„ (ê· ë“± ìƒ˜í”Œë§)

#### íŒŒë¼ë¯¸í„° íš¨ìœ¨ì„± ë¶„ì„

Stable Diffusion ê¸°ì¤€:
- ì „ì²´ ëª¨ë¸: ~860M íŒŒë¼ë¯¸í„°
- ì—…ë°ì´íŠ¸: ~8.6M íŒŒë¼ë¯¸í„° (1% ë¯¸ë§Œ)
- ë©”ëª¨ë¦¬ ì ˆê°: gradient checkpointing + ì„ íƒì  ì—…ë°ì´íŠ¸ë¡œ 8GB â†’ 6GB

### 2.4 DDIM Inversionì„ í†µí•œ êµ¬ì¡° ì§€ë„
#### ë™ê¸°

Fine-tuningë§Œìœ¼ë¡œëŠ”:
- âœ“ ê°ì²´ ì¼ê´€ì„± (spatial consistency)
- âœ— ì›€ì§ì„ ì—°ì†ì„± (temporal smoothness)

ê²°ê³¼: ì •ì§€ ë¹„ë””ì˜¤ (ëª¨ë“  í”„ë ˆì„ì´ ê±°ì˜ ë™ì¼)

#### DDIM Inversion í”„ë¡œì„¸ìŠ¤

**Step 1: ìˆœë°©í–¥ í™•ì‚° (Forward Diffusion)**
ì›ë³¸ ë¹„ë””ì˜¤ Vë¥¼ ë…¸ì´ì¦ˆë¡œ ì ì§„ì  ë³€í™˜:

$$z_0 = \mathcal{E}(V) \quad \text{(ë¹„ë””ì˜¤ë¥¼ Latentë¡œ ì¸ì½”ë”©)}$$
$$z_t = \sqrt{\bar{\alpha}_t} z_0 + \sqrt{1-\bar{\alpha}_t} \epsilon_t \quad t = 0, ..., T$$

ì—¬ê¸°ì„œ $\bar{\alpha}_t$ëŠ” noise schedule

**Step 2: Inversion (ì—­ë³€í™˜)**
DDIM samplerë¥¼ ì—­ë°©í–¥ìœ¼ë¡œ ì‹¤í–‰:

$$z_{t+1} = \frac{\sqrt{\bar{\alpha}_{t+1}}}{\sqrt{\bar{\alpha}_t}} z_t + \left(\sqrt{1-\bar{\alpha}_{t+1}} - \frac{\sqrt{1-\bar{\alpha}_{t+1}}}{\sqrt{\bar{\alpha}_t}} \bar{\alpha}_t \right) \epsilon_\theta(z_t, t)$$

**Step 3: ì—­ë°©í–¥ ìƒ˜í”Œë§ (Reverse Denoising)**
ìƒˆ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œ ì•ˆë‚´ë˜ëŠ” ì—­í”„ë¡œì„¸ìŠ¤:

$$V' = \mathcal{D}_{\text{DDIM-samp}}(z_T^{\text{inv}}, T', c')$$

ì—¬ê¸°ì„œ:
- $z_T^{\text{inv}}$: ì›ë³¸ ë¹„ë””ì˜¤ì˜ Inverted noise (êµ¬ì¡° ì •ë³´ í¬í•¨)
- $T'$: ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸
- $c'$: í…ìŠ¤íŠ¸ ì„ë² ë”©

#### êµ¬ì¡° ì§€ë„ì˜ ì˜ë¯¸

Inverted latentëŠ” ë‹¤ìŒì„ ë³´ì¡´í•©ë‹ˆë‹¤:
1. **ê°ì²´ ìœ„ì¹˜**: ë°°ê²½ ë‚´ ì£¼ìš” ìš”ì†Œì˜ ê³µê°„ ìœ„ì¹˜
2. **ë™ì‘ ê¶¤ì **: ê°ì²´ì˜ í”„ë ˆì„ ê°„ ì´ë™ ê²½ë¡œ
3. **ì¹´ë©”ë¼ ì›€ì§ì„**: ì¥ë©´ ì „ì²´ì˜ ë³€í™˜ (pan, zoom ë“±)
4. **ì¡°ëª… ë³€í™”**: í”„ë ˆì„ ê°„ ëª…ë„ ë³€í™”

ìƒˆ í…ìŠ¤íŠ¸ëŠ” "ì˜ë¯¸ë¡ ì  ë‚´ìš©"ì„ ì œì–´:
1. **ê°ì²´ ì •ì²´ì„±**: "ë‚¨ì" â†’ "ìŠ¤íŒŒì´ë”ë§¨"
2. **ìŠ¤íƒ€ì¼**: "ì‚¬ì‹¤ì " â†’ "ì¹´íˆ°"
3. **ë°°ê²½**: "ì‹œê³¨ ê¸¸" â†’ "í•´ë³€"

**ê²°í•© íš¨ê³¼:** ì›ë³¸ì˜ "ì–´ë–»ê²Œ"(how) + ìƒˆ í…ìŠ¤íŠ¸ì˜ "ë¬´ì—‡"(what)

#### ê³„ì‚° íš¨ìœ¨

ì¤‘ìš”í•œ ìµœì í™”:
$$\text{Inversion íšŸìˆ˜} = 1 \text{ (ë¹„ë””ì˜¤ë‹¹ í•œ ë²ˆ)}$$

ë™ì¼ ì…ë ¥ ë¹„ë””ì˜¤ì— ëŒ€í•´:
- Inversion: 10ë¶„ (ì¼íšŒì„±)
- ê° ìƒˆ í”„ë¡¬í”„íŠ¸ ìƒ˜í”Œë§: 1ë¶„

â†’ 10ê°œ í”„ë¡¬í”„íŠ¸ ìƒì„± = 20ë¶„ ì´ì‹œê°„

### 2.5 ëª¨ë¸ ì•„í‚¤í…ì²˜ (Architecture)
**ê¸°ë°˜ ëª¨ë¸:** Latent Diffusion Model (Stable Diffusion v1.4)

**ì•„í‚¤í…ì²˜ ìˆ˜ì •:**

```
ì…ë ¥: ë¹„ë””ì˜¤ Latent (32í”„ë ˆì„ Ã— 64Ã—64Ã—4 ì±„ë„)
         â†“
[Downsampling U-Net]
    - 2D Spatial Conv (ë™ê²°)
    - 2D Spatial Self-Attention (ë™ê²°, spatialë§Œ)
    - Spatio-Temporal Attention (ST-Attn, Që§Œ ì—…ë°ì´íŠ¸)
    - Temporal Self-Attention (ì‹ ê·œ, ì „ì²´ ì—…ë°ì´íŠ¸)
    - Cross-Attention (Që§Œ ì—…ë°ì´íŠ¸, K/V ë™ê²°)
    - MLP/FFN (ë™ê²°)
         â†“
[Bottleneck]
         â†“
[Upsampling U-Net]
    (ë™ì¼ êµ¬ì¡°)
         â†“
ì¶œë ¥: Denoised Latent
         â†“
[VAE Decoder]
         â†“
ìµœì¢… ë¹„ë””ì˜¤ í”„ë ˆì„
```

**ë ˆì´ì–´ë³„ ì—­í• :**

| ë ˆì´ì–´ | ì—­í•  | ì—…ë°ì´íŠ¸ | ëª©ì  |
|-------|------|--------|------|
| **Spatial Self-Attn** | ê° í”„ë ˆì„ ë‚´ ê³µê°„ì  íŠ¹ì§• ìƒí˜¸ì‘ìš© | ë™ê²° + Që§Œ | ì‚¬ì „í•™ìŠµ í™œìš© + í…ìŠ¤íŠ¸ ì •ë ¬ |
| **ST-Attn** | í˜„ì¬ vs (ì²«+ì´ì „) í”„ë ˆì„ | ë™ê²° + Që§Œ | ì‹œê°„ì  ì¼ê´€ì„± + íš¨ìœ¨ì„± |
| **Temporal Self-Attn** | í”„ë ˆì„ ê°„ ì›€ì§ì„ ëª¨ë¸ë§ | ì „ì²´ | ë™ì  íŠ¹ì§• í•™ìŠµ |
| **Cross-Attn** | í…ìŠ¤íŠ¸-ì‹œê° ì •ë ¬ | Që§Œ | í…ìŠ¤íŠ¸ ì¡°ê±´í™” |
| **Convolutional** | ì €ìˆ˜ì¤€ íŠ¹ì§• ì²˜ë¦¬ | ë™ê²° | ì´ë¯¸ì§€ ì„ í–‰ì§€ì‹ ë³´ì¡´ |

***

## 3. ì„±ëŠ¥ í–¥ìƒ ë° í•œê³„ ë¶„ì„
### 3.1 ì •ëŸ‰ì  ì„±ëŠ¥ ë¹„êµ
#### ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼

ë…¼ë¬¸ì€ DAVIS ë°ì´í„°ì…‹ì˜ 42ê°œ ëŒ€í‘œ ë¹„ë””ì˜¤ì—ì„œ í‰ê°€:

| ë©”íŠ¸ë¦­ | CogVideo | Plug-and-Play | Text2LIVE | **Tune-A-Video** |
|------|----------|--------------|-----------|----------|
| **Frame Consistency** (CLIP) | 90.64 | 88.89 | N/A | **92.40** |
| **Text Alignment** (CLIP Score) | 15.00 | 37.86 | 28.15 | **87.86** |
| **User Pref: Consistency** | 23.57% | 27.56% | 40.00% | **85.00%** |
| **User Pref: Alignment** | 12.14% | 23.91% | 30.25% | **76.43%** |

**ì„±ëŠ¥ ë¶„ì„:**

1. **Frame Consistency (92.40)**
   - CogVideo ëŒ€ë¹„ +1.9% í–¥ìƒ
   - ì›ì¸: ST-Attnì´ í”„ë ˆì„ ê°„ íŠ¹ì§• ìƒê´€ì„± ìµœëŒ€í™”

2. **Text Alignment (87.86)**
   - CogVideo ëŒ€ë¹„ **5.8ë°° í–¥ìƒ** (15.00 â†’ 87.86)
   - Plug-and-Play ëŒ€ë¹„ **2.3ë°° í–¥ìƒ**
   - ì›ì¸: ì…ë ¥ ë¹„ë””ì˜¤-í…ìŠ¤íŠ¸ ìŒìœ¼ë¡œ ì§ì ‘ ìµœì í™”

3. **ì‚¬ìš©ì ì—°êµ¬**
   - 5ëª… í‰ê°€ì Ã— 42ê°œ ë¹„ë””ì˜¤
   - ì¼ê´€ì„±: 85% (íƒ€ë°©ë²• 23-40%)
   - ì •ë ¬: 76% (íƒ€ë°©ë²• 12-30%)

#### ë²¤ì¹˜ë§ˆí¬ ì£¼ìš” ì¸ì‚¬ì´íŠ¸

**CogVideo vs Tune-A-Video:**
- CogVideo: ëŒ€ê·œëª¨ í•™ìŠµìœ¼ë¡œ ë‹¤ì–‘ì„± â†‘, íŠ¹ì • ë™ì‘ ì •í™•ë„ â†“
- Tune-A-Video: í•œ ë¹„ë””ì˜¤ í•™ìŠµìœ¼ë¡œ ì •í™•ë„ â†‘, ì¼ë°˜í™” â†“

**Plug-and-Play vs Tune-A-Video:**
- Plug-and-Play: ê° í”„ë ˆì„ ë…ë¦½ í¸ì§‘ â†’ ì‹œê°„ì  ì¼ê´€ì„± ë‚®ìŒ (88.89)
- Tune-A-Video: ì‹œê³µê°„ ì •ë³´ í™œìš© â†’ ë†’ì€ ì¼ê´€ì„± (92.40)

**Text2LIVE vs Tune-A-Video:**
- Text2LIVE: Layered neural atlasesë¡œ ì§ˆê° í¸ì§‘ ì „ë¬¸
- Tune-A-Video: ë” ê´‘ë²”ìœ„í•œ ì˜ë¯¸ì  í¸ì§‘ (ê°ì²´ ë³€ê²½, ìŠ¤íƒ€ì¼ ì „ì´ ë“±)

### 3.2 Ablation Study (ì œê±° ë¶„ì„)
ë…¼ë¬¸ì˜ ablation studyëŠ” ê° ì„±ë¶„ì˜ ê¸°ì—¬ë„ë¥¼ ì •ëŸ‰í™”í•©ë‹ˆë‹¤:

**ì‹¤í—˜ ì„¤ê³„:**
ì…ë ¥: "An astronaut is skiing"
í¸ì§‘ í”„ë¡¬í”„íŠ¸: "A lion/panda is skiing", "... on the moon", "... cartoon style"

**ê²°ê³¼ ë¶„ì„:**

| ëª¨ë¸ ë³€í˜• | ë‚´ìš© ì¼ê´€ì„± | ì›€ì§ì„ | ê²°ê³¼ |
|---------|----------|-------|------|
| **w/o Fine-tuning** | âœ“ ìœ ì§€ | âœ— ì—†ìŒ | ì •ì§€ ì´ë¯¸ì§€ ë°˜ë³µ |
| **w/o DDIM Inversion** | âœ“ ìœ ì§€ | âœ— ì—†ìŒ | ì •ì§€ ì´ë¯¸ì§€ ë°˜ë³µ |
| **w/o ST-Attn** | âœ— ë¶ˆì¼ì¹˜ | âœ“ ìˆìŒ | ìƒ‰ìƒ/ìŠ¤íƒ€ì¼ ì˜¤ë¥˜ |
| **Full Model** | âœ“ ìœ ì§€ | âœ“ ìˆìŒ | ìµœì  |

**Ablation í•´ì„:**

1. **Fine-tuningì˜ ì—­í• **
   - ëª©ì : Text-video alignment ìµœì í™”
   - íš¨ê³¼: ì›ë³¸ ë™ì‘ì€ ìœ ì§€í•˜ë˜, ì˜ë¯¸ë¡ ì  ë³€í™” ë°˜ì˜
   - ì—†ì„ ì‹œ: ìƒˆ í”„ë¡¬í”„íŠ¸ ë¬´ì‹œ, ì›ë³¸ ë‚´ìš©ë§Œ ë°˜ë³µ

2. **DDIM Inversionì˜ ì—­í• **
   - ëª©ì : ì‹œê°„ì  ì—°ì†ì„± ì œê³µ
   - íš¨ê³¼: ì…ë ¥ ë¹„ë””ì˜¤ì˜ ì›€ì§ì„ ê¶¤ì  ë³´ì¡´
   - ì—†ì„ ì‹œ: ëª¨ë“  í”„ë ˆì„ì´ ìœ ì‚¬í•˜ê²Œ ìƒì„± (ì›€ì§ì„ ì—†ìŒ)

3. **ST-Attnì˜ ì—­í• **
   - ëª©ì : ê³µê°„ì  ì¼ê´€ì„± + ê³„ì‚° íš¨ìœ¨
   - íš¨ê³¼: ê°ì²´ ì •ì²´ì„± ìœ ì§€, ë©”ëª¨ë¦¬ íš¨ìœ¨
   - ì—†ì„ ì‹œ: í”„ë ˆì„ ê°„ ê°ì²´ ë³€í™” (ìƒ‰ìƒ, ëª¨ì–‘ ë¶ˆì¼ì¹˜)

**í•µì‹¬ ë°œê²¬:** ì„¸ ì„±ë¶„ì´ **ìƒí˜¸ ë³´ì™„ì **
- Fine-tuning: "ë¬´ì—‡ì„" ê²°ì •
- ST-Attn: "ì–´ë””ì—" ê²°ì •  
- DDIM Inversion: "ì–´ë–»ê²Œ" ê²°ì •

### 3.3 ì£¼ìš” í•œê³„ (Limitations)
#### 1. ë‹¤ì¤‘ ê°ì²´ ë° ê°€ë¦¼(Occlusion) ì²˜ë¦¬ ë¯¸í¡

**ë¬¸ì œ:** ì…ë ¥ ë¹„ë””ì˜¤ì— ì—¬ëŸ¬ ê°ì²´ê°€ ìˆê±°ë‚˜ ì„œë¡œ ê°€ë ¤ì§ˆ ë•Œ ì‹¤íŒ¨

**ì˜ˆì‹œ:** ë‘ íŒë‹¤ê°€ ê²¹ì¹˜ëŠ” ê²½ìš°, ìƒì„± ê²°ê³¼ì—ì„œ ë‘ íŒë‹¤ê°€ í˜¼í•©ë¨

**ê·¼ë³¸ ì›ì¸:**
- T2I ëª¨ë¸ì˜ ë‹¤ì¤‘ ê°ì²´ ìƒí˜¸ì‘ìš© ëŠ¥ë ¥ ì œí•œ ìƒì†
- Sparse ST-Attnì´ ê¹Šì´/ê°€ë¦¼ ì •ë³´ ëª…ì‹œì  ëª¨ë¸ë§ ëª»í•¨

**í•´ê²° ê°€ëŠ¥ì„±:**
- Depth mapì´ë‚˜ semantic segmentation ì¡°ê±´í™”
- ì¥ê¸° ì—°êµ¬ ê³¼ì œë¡œ ì œì‹œ

#### 2. ì¥ì‹œê°„ ë¹„ë””ì˜¤ ìƒì„±ì˜ ì–´ë ¤ì›€

**í˜„ì¬ ì œì•½:**
- 32í”„ë ˆì„ (ì•½ 2ì´ˆ, 16fps ê¸°ì¤€)
- ë” ê¸´ ë¹„ë””ì˜¤ëŠ” ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ë¶ˆê°€ëŠ¥

**ë¬¸ì œì˜ ì›ì¸:**
- ë¹„ì •ì‹ ë©”ëª¨ë¦¬: $O(m \times d)$ (m=í”„ë ˆì„ ìˆ˜, d=ì„ë² ë”© ì°¨ì›)
- ST-Attnë„ ì—¬ì „íˆ í”„ë ˆì„ ìˆ˜ì— ì„ í˜• ì˜ì¡´

**í–¥í›„ ê°œì„  ë°©í–¥:**
- Autoregressive generation (ì²­í¬ ë‹¨ìœ„)
- Sliding window attention

#### 3. ìƒˆë¡œìš´ ê°œë… ìƒì„±ì˜ ì œì•½

**ë¬¸ì œ:** ì…ë ¥ ë¹„ë””ì˜¤ì˜ ë™ì‘ êµ¬ì¡°ì— í¬ê²Œ ì˜ì¡´

**ì˜ˆì‹œ:** 
- ì…ë ¥: "ìŠ¤í‚¤ íƒ€ëŠ” ë‚¨ì"
- ê°€ëŠ¥: ìŠ¤í‚¤ â†’ ìŠ¤ë…¸ë³´ë“œë¡œ ë³€ê²½ (ìœ ì‚¬ ë™ì‘)
- ì–´ë ¤ì›€: ìŠ¤í‚¤ â†’ ìˆ˜ì˜ìœ¼ë¡œ ë³€ê²½ (ì™„ì „íˆ ë‹¤ë¥¸ ë™ì‘)

**ì´ìœ :**
- DDIM inversionì´ êµ¬ì¡°ë¥¼ ê°•í•˜ê²Œ ê³ ì •
- ì…ë ¥ ë™ì‘ê³¼ í¬ê²Œ ë‹¤ë¥¸ ë™ì‘ì€ ìƒì„± ë¶ˆê°€

**ì™„í™” ë°©ë²•:**
- Temperature ì¡°ì •ìœ¼ë¡œ inversion ì˜í–¥ ê°ì†Œ
- í•˜ì§€ë§Œ ì¼ê´€ì„± ì €í•˜ íŠ¸ë ˆì´ë“œì˜¤í”„

#### 4. ìŠ¤íƒ€ì¼ ì „ì´ì˜ í•œê³„

**ê°•ì :** ë¬¸ì ì„¤ëª… ê¸°ë°˜ ìŠ¤íƒ€ì¼ (ì¹´íˆ°, Van Gogh, í˜„ëŒ€ ë””ì¦ˆë‹ˆ ë“±)

**í•œê³„:** 
- ë¹„ë””ì˜¤ íŠ¹í™” ìŠ¤íƒ€ì¼ ë°ì´í„° ë¶€ì¬
- ì‹œê°„ì ìœ¼ë¡œ ì¼ê´€ëœ ê·¹ë‹¨ì  ìŠ¤íƒ€ì¼ ì–´ë ¤ì›€

#### 5. í”„ë ˆì„ë¥ (Frame Rate) ê³ ì •

**í˜„ì¬:** 16fps, 512Ã—512 ê³ ì •

**ìœ ì—°ì„± ë¶€ì¬:**
- ë‹¤ì–‘í•œ fps ì§€ì› ì•ˆ ë¨
- ê³ í•´ìƒë„(1024Ã—1024) ìƒì„± ë¶ˆê°€ëŠ¥

#### 6. ëª…ì‹œì  ë™ì‘ ì œì–´ ë¶€ì¬

**ë¬¸ì œ:** í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ ë™ì‘ ì§€ì • â†’ ë¶€ì •í™•í•  ìˆ˜ ìˆìŒ

**ì˜ˆì‹œ:** "ì¶¤ì¶”ê¸°" í”„ë¡¬í”„íŠ¸ëŠ” ì •í™•í•œ ì¶¤ ìŠ¤íƒ€ì¼ ì œì–´ ë¶ˆê°€ëŠ¥

**í•„ìš”í•œ ê°œì„ :**
- Pose/trajectory ê¸°ë°˜ ì¡°ê±´í™”
- Optical flow ëª…ì‹œ ì…ë ¥

***

## 4. ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ ê°€ëŠ¥ì„±
### 4.1 í˜„ì¬ ì¼ë°˜í™” ëŠ¥ë ¥ í‰ê°€
#### ê°•ì : ë„ë©”ì¸ ì ì‘ì„±

**ë…¼ì¦:** ì‚¬ì „í•™ìŠµëœ T2I ëª¨ë¸ì˜ ê±°ëŒ€í•œ ì´ë¯¸ì§€ ì½”í¼ìŠ¤ í™œìš©

**ì‹¤ì¦:**
- 42ê°œ DAVIS ë¹„ë””ì˜¤ (ë§¤ìš° ë‹¤ì–‘í•œ ë„ë©”ì¸)
  - ë™ë¬¼: ê³°, ê¸°ë¦°, ë¼ì´ì˜¨, ì–¼ë£©ë§
  - ì°¨ëŸ‰: ìë™ì°¨, ì˜¤í† ë°”ì´
  - ì¸ê°„: ìŠ¤í¬ì¸ , ëŒ„ì‹±, ì¼ìƒ í™œë™
  
- ê° ë„ë©”ì¸ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥
- ìƒˆë¡œìš´ ë„ë©”ì¸ë„ ì¶”ê°€ í•™ìŠµ ì—†ì´ ì²˜ë¦¬

**ì¼ë°˜í™” ë©”ì»¤ë‹ˆì¦˜:**
T2Iê°€ í•™ìŠµí•œ ê°œë… ê³µê°„ì„ ì‹œê°„ ì°¨ì›ìœ¼ë¡œ í™•ì¥
â†’ ìƒˆë¡œìš´ ë¹„ë””ì˜¤ ë„ë©”ì¸ë„ ì´ë¯¸ì§€ ì§€ì‹ìœ¼ë¡œ ì²˜ë¦¬ ê°€ëŠ¥

#### ì•½ì : ë¶„í¬ ì™¸(Out-of-Distribution) ë™ì‘

**ë¬¸ì œ ì •ì˜:**
ì…ë ¥ ë¹„ë””ì˜¤ì˜ ë™ì‘ê³¼ í¬ê²Œ ë‹¤ë¥¸ ìƒˆë¡œìš´ ë™ì‘ ìƒì„± ì–´ë ¤ì›€

**ì˜ˆì‹œ:**
- ì…ë ¥: ìŠ¤í‚¤ (ì† ìœ„, ë‹¤ë¦¬ ì›€ì§ì„ í¼)
- ê°€ëŠ¥: ìŠ¤ë…¸ë³´ë“œ (ìœ ì‚¬ ë™ì‘ êµ¬ì¡°)
- ì–´ë ¤ì›€: ìˆ˜ì˜ (ì™„ì „ ë‹¤ë¥¸ êµ¬ì¡°)

**ê³¼í•™ì  í•´ì„:**
DDIM inversionì´ "êµ¬ì¡° ì œì•½"ìœ¼ë¡œ ì‘ë™
â†’ ì…ë ¥ ë™ì‘ì˜ "ë¼ˆëŒ€" ìœ ì§€ ê°•ì œ
â†’ ì™„ì „íˆ ë‹¤ë¥¸ ë™ì‘ì˜ ë¼ˆëŒ€ëŠ” ìƒì„± ë¶ˆê°€ëŠ¥

#### í˜¸í™˜ì„±: ê¸°ì¡´ ëª¨ë¸ê³¼ì˜ í†µí•©

**DreamBooth í˜¸í™˜:**
```
ê¸°ë³¸ ì…ë ¥: 1ê°œ ë¹„ë””ì˜¤-í…ìŠ¤íŠ¸ ìŒ
DreamBooth ì…ë ¥: íŠ¹ì • ì¸ë¬¼/ê°ì²´ì˜ 3-5ê°œ ì´ë¯¸ì§€
â†’ ê²°í•©: íŠ¹ì • ì¸ë¬¼ì´ ìˆ˜í–‰í•˜ëŠ” ë§ì¶¤ ë¹„ë””ì˜¤ ìƒì„±

ì˜ˆ: "James Bondê°€ ë†êµ¬í•˜ëŠ” ë¹„ë””ì˜¤"
     (James BondëŠ” DreamBoothë¡œ ê°œì¸í™”)
```

**T2I-Adapter í˜¸í™˜:**
```
ê¸°ë³¸: í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ ìƒì„±
+ Adapter: ì¶”ê°€ ì¡°ê±´ (í¬ì¦ˆ, ê¹Šì´, ìŠ¤ì¼€ì¹˜)
â†’ ê²°í•©: í…ìŠ¤íŠ¸ + ëª…ì‹œì  ì œì–´ë¡œ ë¹„ë””ì˜¤ ìƒì„±

ì˜ˆ: "ë‚¨ìê°€ ì¶¤ì¶”ê¸°" + í¬ì¦ˆ ì‹œí€€ìŠ¤
```

### 4.2 ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ë¯¸ë˜ ë°©í–¥
#### 1. í–¥ìƒëœ Spatio-Temporal Attention

**í˜„ì¬ í•œê³„:**
- ì²« í”„ë ˆì„ + ì´ì „ í”„ë ˆì„ë§Œ ì°¸ì¡°
- ì¥ê¸° ì˜ì¡´ì„± ì •ë³´ ë¶€ì¬

**ê°œì„  ì•„ì´ë””ì–´:**

$$\text{Enhanced-ST-Attn}: \text{ì²«, ì´ì „, ê·¸ë¦¬ê³  } K \text{-ìŠ¤í… ì´ì „ í”„ë ˆì„ ì°¸ì¡°}$$

**ì´ì :**
- ì£¼ê¸°ì  ë™ì‘(ì¶¤, ë‹¬ë¦¬ê¸°) ì¥ê¸° ì¼ê´€ì„±
- ê³„ì‚° ë³µì¡ë„ëŠ” ì—¬ì „íˆ ì„ í˜• ( $O(3mN^2)$ )

**ê¸°ëŒ€ íš¨ê³¼:** ë” ìì—°ìŠ¤ëŸ¬ìš´ ì›€ì§ì„

#### 2. Few-Shot ì ì‘ìœ¼ë¡œ í™•ì¥

**í˜„ì¬:** One-shot (1ê°œ ë¹„ë””ì˜¤)

**ê°œì„ :** Few-shot (2-5ê°œ ë¹„ë””ì˜¤)
```
ì…ë ¥: ë™ì¼ ë™ì‘ì˜ 2-5ê°œ ë³€í˜• ë¹„ë””ì˜¤
      (ë°°ê²½, ì¹´ë©”ë¼, ìŠ¤íƒ€ì¼ ë‹¤ì–‘)
â†’ í•™ìŠµ: ë™ì‘ êµ¬ì¡°ì˜ ë³¸ì§ˆ ì¶”ì¶œ
â†’ ê²°ê³¼: ìƒˆë¡œìš´ ì¡°ê±´ì—ì„œë„ ë™ì‘ ìƒì„± ê°€ëŠ¥
```

**ë©”ì»¤ë‹ˆì¦˜:**
- Contrastive learning: ê°™ì€ ë™ì‘ì˜ ë³€í˜•ë“¤ ê°„ ìœ ì‚¬ì„±
- ë¶ˆë³€ íŠ¹ì§• í•™ìŠµ

#### 3. Motion-Appearance Disentanglement

**ì•„ì´ë””ì–´:** ë™ì‘ê³¼ ì™¸í˜•ì„ ëª…ì‹œì ìœ¼ë¡œ ë¶„ë¦¬

**ê¸°ìˆ ì  ì ‘ê·¼:** MotionDirector ì˜ê°
```
ì…ë ¥: 1ê°œ ë¹„ë””ì˜¤
â†’ ë¶„ë¦¬:
   - Motion LoRA: ë™ì‘ íŒ¨í„´ë§Œ í•™ìŠµ
   - Appearance LoRA: ì™¸í˜• íŠ¹ì§•ë§Œ í•™ìŠµ
â†’ ì¡°í•©: ë‹¤ì–‘í•œ ì™¸í˜• + í•™ìŠµí•œ ë™ì‘

ì˜ˆ: ì‚¬ìì˜ ë™ì‘ + í˜¸ë‘ì´ì˜ ì™¸í˜• = í˜¸ë‘ì´ì˜ ì›€ì§ì„
```

**ì¼ë°˜í™” ì´ì :**
- ê°ì²´-ë™ì‘ ì¡°í•© ììœ ë„ â†‘
- Few-shot ë°ì´í„°ë¡œë„ ê°•í•œ ì¼ë°˜í™”

#### 4. ë‹¤ì¤‘ ì°¸ì¡° í”„ë ˆì„ í•™ìŠµ

**ë¬¸ì œ:** í˜„ì¬ inversionì€ ì…ë ¥ ë¹„ë””ì˜¤ êµ¬ì¡°ì—ë§Œ ì˜ì¡´

**í•´ê²°:** ì—¬ëŸ¬ ì°¸ì¡° ë¹„ë””ì˜¤ì—ì„œ êµ¬ì¡° í•©ì„±

$$\text{Inverted}_{final} = \alpha \cdot \text{Inv}(V_1) + (1-\alpha) \cdot \text{Inv}(V_2)$$

**íš¨ê³¼:**
- ë‘ ë™ì‘ì˜ ì¤‘ê°„ í˜•íƒœ ìƒì„± ê°€ëŠ¥
- ë™ì‘ ë³´ê°„(motion interpolation) ê°€ëŠ¥

#### 5. Zero-Shot ì¼ë°˜í™”ë¥¼ ìœ„í•œ ë©”íƒ€ëŸ¬ë‹

**ê°œë…:** í•™ìŠµí•˜ëŠ” ë°©ë²•ì„ í•™ìŠµ (Learning to Learn)

**ì ìš©:**
```
ë©”íƒ€-í•™ìŠµ ë‹¨ê³„: ìˆ˜ë°± ê°œ ë¹„ë””ì˜¤ í•™ìŠµ
â†’ "íš¨ìœ¨ì  ë¹„ë””ì˜¤ ìƒì„±"ì´ë¼ëŠ” ë©”íƒ€-ì§€ì‹ ìŠµë“

ì¶”ë¡  ë‹¨ê³„: ìƒˆ ë¹„ë””ì˜¤ 1ê°œë§Œìœ¼ë¡œ
â†’ ë©”íƒ€-ì§€ì‹ í™œìš©í•´ ë¹ ë¥´ê²Œ ì ì‘

ê¸°ëŒ€: ë” ì ì€ ë°ì´í„°ë¡œë„ ê°•í•œ ì¼ë°˜í™”
```

#### 6. ì¡°ê±´ë¶€ ì œì–´ ê°•í™”

**Depth/Segmentation ì¡°ê±´í™”:**
```
ì…ë ¥: ë¹„ë””ì˜¤ + ëŒ€ì‘í•˜ëŠ” ê¹Šì´/ë§ˆìŠ¤í¬
â†’ í•™ìŠµ: êµ¬ì¡°ë¥¼ ë” ëª…ì‹œì ìœ¼ë¡œ íŒŒì•…
â†’ ê²°ê³¼: ë‹¤ì¤‘ ê°ì²´ ìƒí˜¸ì‘ìš© ê°€ëŠ¥
```

**Optical Flow ì¡°ê±´í™”:**
```
ì…ë ¥: ë¹„ë””ì˜¤ + ê´‘í•™ íë¦„
â†’ í•™ìŠµ: ëª…ì‹œì  ì›€ì§ì„ ë²¡í„° í•™ìŠµ
â†’ ê²°ê³¼: ìƒˆ ë™ì‘ìœ¼ë¡œì˜ ì¬ë§µí•‘ ê°€ëŠ¥

ì˜ˆ: íë¦„ì„ 2ë°°ë¡œ â†’ ë” ë¹ ë¥¸ ë™ì‘ ìƒì„±
```

***

## 5. 2020ë…„ ì´í›„ ê´€ë ¨ ìµœì‹  ì—°êµ¬ì™€ì˜ ë¹„êµ ë¶„ì„
### 5.1 T2V ìƒì„± ëª¨ë¸ì˜ ì§„í™” ê³„ë³´
#### Phase 1: ì´ˆê¸° T2V ëª¨ë¸ (2020-2021)

| ëª¨ë¸ | ë°œí‘œ | ì ‘ê·¼ë²• | í™”ì§ˆ | ë„ë©”ì¸ | ì£¼ìš” ê¸°ì—¬ |
|-----|------|--------|------|-------|---------|
| **GODIVA** | 2021 | VQ-VAE + Sparse Attn | ë‚®ìŒ | íŠ¹ì • | íš¨ìœ¨ì„± |
| **NUWA** | 2022 | Unified Multi-task | ì¤‘ê°„ | ë„“ìŒ | ë‹¤ì¤‘ì‘ì—… |

#### Phase 2: Diffusion í˜ëª… (2022-2023)

| ëª¨ë¸ | ë°œí‘œ | íŠ¹ì§• | ì„±ëŠ¥ | ë°ì´í„° | ê³„ì‚° |
|-----|------|------|------|-------|------|
| **VDM** | 2022.04 | Space-time U-Net | ë†’ìŒ | ëŒ€ê·œëª¨ | ë§¤ìš° ë†’ìŒ |
| **Imagen Video** | 2022.10 | Cascaded 3ë‹¨ê³„ | ë§¤ìš°ë†’ìŒ | ëŒ€ê·œëª¨ | ë§¤ìš° ë†’ìŒ |
| **Make-A-Video** | 2022.09 | T2I ê¸°ë°˜, ë¹„ë°ì´í„° í•™ìŠµ | ë†’ìŒ | ì¤‘ê°„ | ë†’ìŒ |
| **CogVideo** | 2022.05 | 90ì–µ íŒŒë¼ë¯¸í„° Transformer | ë†’ìŒ | 540ë§Œ | ë†’ìŒ |
| **Tune-A-Video** | 2022.12 | **One-shot ë¯¸ì„¸ì¡°ì •** | **ì¤‘ìƒ** | **1ê°œ** | **ë§¤ìš° ë‚®ìŒ** |

#### Phase 3: íŠ¹í™” ë° ê³ ê¸‰ ê¸°ë²• (2023-2025)

| ëª¨ë¸ | ë°œí‘œ | í˜ì‹  | vs Tune-A-Video | íŠ¸ë Œë“œ |
|-----|------|------|-----------------|-------|
| **MotionDirector** | 2023.10 | Motion LoRA | ë™ì‘ ë¶„ë¦¬ ì¶”ê°€ | ê°œì¸í™” |
| **Customize-A-Video** | 2024.02 | One-shot ë™ì‘ | ìœ ì‚¬ ë²”ìœ„ | ê°œì¸í™” |
| **CogVideoX** | 2024.08 | Diffusion Transformer | ë” í° ëª¨ë¸ | í™•ì¥ |
| **Stable Video Diffusion** | 2024.04 | I2V, 3ë‹¨ê³„ í•™ìŠµ | ì´ë¯¸ì§€ ì¡°ê±´í™” | ì¡°ê±´í™” |
| **StreamingT2V** | 2024.03 | ì¥ì‹œê°„ ìƒì„± | ìê¸°íšŒê·€ ì¶”ê°€ | ê¸¸ì´ í™•ì¥ |
| **VideoMage** | 2025.04 | ë‹¤ì¤‘ ê°ì²´+ë™ì‘ | ìƒí˜¸ì‘ìš© ì¶”ê°€ | ë³µì¡ì„± ì¦ê°€ |

### 5.2 ì£¼ìš” ê¸°ìˆ ì  í˜ì‹  ë¹„êµ
#### Spatio-Temporal Attention ë©”ì»¤ë‹ˆì¦˜ ë¹„êµ

| ê¸°ë²• | ëª¨ë¸ | ê³„ì‚° | íš¨ê³¼ | í•œê³„ |
|-----|------|------|------|------|
| **Spatial Only** | GODIVA | $O(N^2)$ | ë…ë¦½ì  í”„ë ˆì„ | ì‹œê°„ ì •ë³´ 0 |
| **Full ST** | VDM | $O(m^2N^2)$ | ëª¨ë“  ìƒí˜¸ì‘ìš© | ê³„ì‚° ë¶€ë‹´ |
| **Sparse Causal** | **Tune-A-Video** | **$O(2mN^2)$** | **íš¨ìœ¨+ì¼ê´€ì„±** | **ì¥ê¸° ì˜ì¡´ì„± ì•½í•¨** |
| **Sliding Window** | CogVideoX | $O(5mN^2)$ | ì¤‘ê°„ ë²”ìœ„ | ì—¬ì „íˆ ë¹„ìš© ë†’ìŒ |
| **Causal** | Phenaki | $O(m^2N^2)$ | ìˆœì°¨ì  ì¼ê´€ì„± | ê³„ì‚° ë§¤ìš° ë†’ìŒ |

#### ë¯¸ì„¸ì¡°ì • ì „ëµ ë¹„êµ

| ë°©ë²• | í•™ìŠµ ë°ì´í„° | í•™ìŠµ ì‹œê°„ | ì—…ë°ì´íŠ¸ ëŒ€ìƒ | ì¼ë°˜í™” | ì¶©ì‹¤ë„ |
|-----|----------|---------|-----------|-------|-------|
| **ì „ì²´ ë¯¸ì„¸ì¡°ì •** | ëŒ€ê·œëª¨ | ìˆ˜ì£¼ | ëª¨ë“  íŒŒë¼ë¯¸í„° | ë‚®ìŒ | ë†’ìŒ |
| **DreamBooth** | 5-10 ì´ë¯¸ì§€ | 5-10ë¶„ | ëª¨ë“  íŒŒë¼ë¯¸í„° | ë‚®ìŒ | ë§¤ìš°ë†’ìŒ |
| **LoRA** | ê°€ë³€ | 1-2ë¶„ | ì €ê³„ìˆ˜ í–‰ë ¬ | ì¤‘ê°„ | ì¤‘ê°„ |
| **T2I-Adapter** | ê°€ë³€ | 10-20ë¶„ | ë³„ë„ ë„¤íŠ¸ì›Œí¬ | ë†’ìŒ | ì¤‘ê°„ |
| **Tune-A-Video** | 1ê°œ ë¹„ë””ì˜¤ | 10ë¶„ | Query projectionë§Œ | ë†’ìŒ | ë†’ìŒ |
| **InstantBooth** | ë¯¸í•„ìš” | 0ë¶„ | ì„ë² ë”© ì¸ì½”ë” | ë†’ìŒ | ë‚®ìŒ |

### 5.3 êµ¬ì¡° ì§€ë„ ë° ì¡°ê±´í™” ê¸°ë²•
#### Inversion/Guidance ë°©ë²•ë¡  ë¹„êµ

| ê¸°ë²• | ë…¼ë¬¸ | ìš©ë„ | ì¥ì  | ë‹¨ì  |
|-----|------|------|------|------|
| **DDIM Inversion** | Tune-A-Video | êµ¬ì¡° ë³´ì¡´ | ìì—°ìŠ¤ëŸ¬ìš´ ì›€ì§ì„ | êµ¬ì¡° ê³¼ë„ ê³ ì • |
| **Image Conditioning** | SVD | ì²« í”„ë ˆì„ ê³ ì • | ëª…í™•í•œ ì‹œì‘ì  | ë™ì‘ ììœ ë„ â†“ |
| **TI2V-Zero** | 2024 | Zero-shot TI2V | íŠœë‹ ë¶ˆí•„ìš” | í’ˆì§ˆ ì €í•˜ |
| **Optical Flow** | OnlyFlow | ëª…ì‹œì  ë™ì‘ | ì •ë°€í•œ ì œì–´ | ë³µì¡í•œ ì…ë ¥ |
| **ControlNet** | Zhang et al. | ë‹¤ì¤‘ ì¡°ê±´í™” | ìœ ì—°ì„± | ì¶”ê°€ í•™ìŠµ í•„ìš” |
| **State Guidance** | 2024 | ë™ì‘ ì „ì´ | ì •êµí•œ ì œì–´ | ê³„ì‚° ë³µì¡ |

### 5.4 ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë° ë²¤ì¹˜ë§ˆí¬ ì§„í™”
#### í‰ê°€ ë©”íŠ¸ë¦­ì˜ ë°œì „

**ì´ˆê¸° (2021-2022):**
- FVD (FrÃ©chet Video Distance)
- Inception Score

**í˜„ì¬ (2023-2025):**
- FVD + CLIP-I (ì´ë¯¸ì§€ ì¼ê´€ì„±)
- CLIP-T (í…ìŠ¤íŠ¸ ì •ë ¬)
- DINO-I (ì˜ë¯¸ë¡ ì  ì¼ê´€ì„±)
- User Study (ì„ í˜¸ë„)

**í•„ìš”ì„±:**
CLIP ê¸°ë°˜ ë©”íŠ¸ë¦­ì€ T2V í’ˆì§ˆì˜ ë‘ ì¶•(ì¼ê´€ì„±+ì •ë ¬)ì„ ëª¨ë‘ ìº¡ì²˜

#### ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ ë¹„êµ

| ë°ì´í„°ì…‹ | ê·œëª¨ | íŠ¹ì§• | ì‚¬ìš© ëª¨ë¸ |
|--------|------|------|---------|
| **DAVIS** | 42ê°œ | ë‹¤ì–‘í•œ ê°ì²´ | Tune-A-Video (baseline) |
| **VBench** | 700+ | í‘œì¤€ T2V ë²¤ì¹˜ë§ˆí¬ | 2024ë…„ë¶€í„° í‘œì¤€ |
| **UCF-101** | 13,320ê°œ | ë™ì‘ ì¸ì‹ ê¸°ë°˜ | I2V í‰ê°€ |
| **MSR-VTT** | 10,000ê°œ | ëŒ€ê·œëª¨ T2V | í•™ìŠµ/í‰ê°€ìš© |

### 5.5 ì—…ê³„ ì˜ë¬´(Industry Adoption) í˜„í™©
#### ìƒìš© ëª¨ë¸ê³¼ì˜ ë¹„êµ

| ëª¨ë¸ | ì œê³µì‚¬ | ì ‘ê·¼ì„± | ê°€ê²© | í’ˆì§ˆ |
|-----|-------|--------|------|------|
| **Sora** | OpenAI | ì œí•œì  | ë¯¸ì • | ìµœê³  ìˆ˜ì¤€ |
| **Runway Gen-2** | Runway | API | ìœ ë£Œ | ë†’ìŒ |
| **Pika** | Pika Labs | ì›¹ | ìœ ë£Œ | ì¤‘ìƒ |
| **Synthesia** | Synthesia | API | ê¸°ì—…ìš© | ì¤‘ìƒ |
| **Stable Diffusion Video** | Stability | ì˜¤í”ˆì†ŒìŠ¤ | ë¬´ë£Œ | ì¤‘ê°„ |
| **Tune-A-Video** | í•™ìˆ  | ì˜¤í”ˆì†ŒìŠ¤ | ë¬´ë£Œ | ì¤‘ê°„ |

#### ì˜¤í”ˆì†ŒìŠ¤ ìƒíƒœê³„ ì˜í–¥

**Tune-A-Videoì˜ ì˜í–¥:**
- HuggingFace í†µí•© (ëª¨ë¸ ê³µê°œ)
- ëŒ€ëŸ‰ì˜ 3ì êµ¬í˜„ì²´ (PyTorch Lightning, ComfyUI ë“±)
- ë‹¤ì–‘í•œ í™•ì¥ (LoRA ê¸°ë°˜ ê°œì„ , UI í†µí•© ë“±)

**ì„ í›„ ì—°êµ¬ë“¤ì˜ ì°¸ê³ :**
- MotionDirector (2023): ST-Attn ê°œë… í™œìš©
- Customize-A-Video: One-shot ë™ì‘ í•™ìŠµ ì˜ê°
- ìˆ˜ë§ì€ í•™ìœ„ ë…¼ë¬¸, í•´ì»¤í†¤ í”„ë¡œì íŠ¸ì˜ ê¸°ì´ˆ

***

## 6. ì•ìœ¼ë¡œì˜ ì—°êµ¬ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë° ê³ ë ¤ì‚¬í•­
### 6.1 í•™ìˆ ì  ì˜í–¥
#### 1. íš¨ìœ¨ì  ì „ì´í•™ìŠµ íŒ¨ëŸ¬ë‹¤ì„ì˜ í™•ë¦½

**í•µì‹¬ ë©”ì‹œì§€:** "ëŒ€ê·œëª¨ ë°ì´í„° > ì˜ë¦¬í•œ ì•„í‚¤í…ì²˜"ëŠ” ê±°ì§“

**ì „í•™ ë©”ì»¤ë‹ˆì¦˜:**
- Large T2I ëª¨ë¸ì˜ ì´ë¯¸ì§€ ì§€ì‹ì´ T2Vë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì „ì´
- One-shot ë¯¸ì„¸ì¡°ì •ìœ¼ë¡œë„ ë„ë©”ì¸ íŠ¹í™” ê°€ëŠ¥

**í•™ìˆ ì  ì˜í–¥:**
- ì´í›„ ì—°êµ¬ë“¤ì˜ íŒ¨ëŸ¬ë‹¤ì„ ì „í™˜ ì´‰ë°œ
- "Data-efficient learning"ì´ ìƒˆë¡œìš´ ì—°êµ¬ ë°©í–¥ìœ¼ë¡œ í™•ë¦½

#### 2. Sparse Spatio-Temporal Attentionì˜ íƒ€ë‹¹ì„± ì…ì¦

**í˜ì‹ :**
ê³„ì‚° ë³µì¡ë„ë¥¼ ì„ í˜•ìœ¼ë¡œ ê°ì†Œì‹œí‚¤ë©´ì„œë„ ì„±ëŠ¥ ìœ ì§€ ê°€ëŠ¥

**í›„ì† ê¸°ì—¬:**
- CogVideoX: Sparse ST-Attn ì•„ì´ë””ì–´ ì±„íƒ í›„ ê°œì„ 
- StreamingT2V: ìê¸°íšŒê·€ ë°©ì‹ìœ¼ë¡œ ë” íš¨ìœ¨í™”
- ë§ì€ 3D CNN ê¸°ë°˜ ì‘ì—…: Sparse convolution ì¬ì¡°ëª…

**ì´ë¡ ì  ê¸°ì—¬:**
"ì‹œê°„ì  ìƒê´€ì„±ì€ ì¸ì ‘ í”„ë ˆì„ë§Œìœ¼ë¡œ ì¶©ë¶„í•˜ë‹¤"ëŠ” ê°€ì„¤ ì§€ì§€

#### 3. DDIM Inversionì˜ ìƒˆë¡œìš´ í™œìš©

**ê¸°ì¡´ ìš©ë„:** ì´ë¯¸ì§€ ì¬êµ¬ì„±, íŠ¹ì§• ë¶„ì„

**ìƒˆë¡œìš´ ìš©ë„:** 
- êµ¬ì¡° ì§€ë„ (Structure guidance)
- ì½˜í…ì¸ -êµ¬ì¡° ë¶„ë¦¬ (Content-structure disentanglement)

**í™•ì‚° ëª¨ë¸ ì´í•´:**
Inversion ê°€ëŠ¥ì„± â†’ ëª¨ë¸ì´ ì˜ë¯¸ ìˆëŠ” ì¤‘ê°„ í‘œí˜„ í•™ìŠµí•¨ì„ ì…ì¦

**í›„ì† í™œìš©:**
- Video editing (Dreamix ë“±)
- Layout guidance for generation
- ì—¬ëŸ¬ editing ë°©ë²•ì˜ ì˜ê°

#### 4. ê°œì¸í™” ìƒì„±ì˜ ìƒˆë¡œìš´ ê²½ë¡œ ê°œì²™

**ì´ì „:** DreamBooth (T2I ê°œì¸í™”) â†’ T2V ê°œì¸í™”ëŠ” ë¯¸ê°œì²™

**í˜ì‹ :** T2Ië¥¼ í†µí•œ ê°„ì ‘ì  T2V ê°œì¸í™” ì œì‹œ

**í›„ì† ì—°êµ¬:** 
- MotionDirector, VideoMage: ê°œì¸í™” ê°•í™”
- ê¸°ì—… ì œí’ˆ (Runway Gen-2): ê°œì¸í™” ê¸°ëŠ¥ ì¶”ê°€

**í•™ìˆ  ì˜ì œ:** "ê°œì¸í™” ìƒì„±ì˜ ê²½ê³„ëŠ” ì–´ë””ì¸ê°€?"

### 6.2 ì‹¤ë¬´ì  ì˜í–¥
#### 1. ì°½ì‘ ë„êµ¬ì˜ ë¯¼ì£¼í™”

**ì´ì „:**
- T2V ìƒì„±: ê¸°ì—… ì‹¤í—˜ì‹¤ë§Œ ê°€ëŠ¥ (ìˆ˜ì£¼ í•™ìŠµ, ìˆ˜ë°± GPU)
- ê°œì¸ ì‚¬ìš©ì: ë¶ˆê°€ëŠ¥

**ì´í›„:**
- ê°œì¸ìš© GPU (RTX 3090, A100): ê°€ëŠ¥
- í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤: ì €ë ´í•œ ìš”ê¸ˆìœ¼ë¡œ ì ‘ê·¼
- ìƒì„± ì‹œê°„: ë¶„ ë‹¨ìœ„ (ê¸°ì¡´ ì‹œê°„ ë‹¨ìœ„ ëŒ€ë¹„)

**ì‚¬íšŒì  íŒŒê¸‰:**
- ì½˜í…ì¸  í¬ë¦¬ì—ì´í„°ì˜ ìƒì‚°ì„± ëŒ€í­ í–¥ìƒ
- ë¹„ì „ë¬¸ê°€ë„ ê³ í’ˆì§ˆ ë¹„ë””ì˜¤ ìƒì„± ê°€ëŠ¥

#### 2. ë‹¤ì–‘í•œ ì‚°ì—… ì‘ìš©

**ê´‘ê³  & ë§ˆì¼€íŒ…:**
```
ì‘ì—… íë¦„: ìƒí’ˆ â†’ ìŠ¤í¬ë¦½íŠ¸ â†’ ë¹„ë””ì˜¤
ê¸°ì¡´: ì´¬ì˜/3D ì œì‘ (ìˆ˜ì£¼ ì†Œìš”)
ì´í›„: AI ìƒì„± (ë¶„ ë‹¨ìœ„ ì†Œìš”)
íš¨ê³¼: ê´‘ê³  ìº í˜ì¸ ì‹ ì† ì „ê°œ, A/B í…ŒìŠ¤íŠ¸ ìš©ì´
```

**ê²Œì„ ê°œë°œ:**
```
ë°°ê²½ NPC ì• ë‹ˆë©”ì´ì…˜: AIë¡œ ìë™ ìƒì„±
ì¥ì : ì œì‘ ë¹„ìš© â†“, ë‹¤ì–‘ì„± â†‘
ì˜ˆ: ìˆ˜ë°± NPCì˜ ë§ì¶¤ ë™ì‘ ìƒì„±
```

**êµìœ¡:**
```
ê°œë… ì„¤ëª… ë™ì˜ìƒ: ìë™ ìƒì„±
ì˜ˆ: "ì—­ì‚¬ ì‚¬ê±´ ì¬ì—°", "ê³¼í•™ ì‹¤í—˜ ì‹œë®¬ë ˆì´ì…˜"
íš¨ìœ¨: ìˆ˜ì‘ì—… ëŒ€ë¹„ 10ë°° ì´ìƒ ë¹ ë¦„
```

**ì˜ë£Œ/ê³¼í•™:**
```
ì˜ë£Œ êµìœ¡: í•´ë¶€í•™ì  ì •í™•ë„ + ë™ì‘ í‘œí˜„
ì—°êµ¬ ì‹œê°í™”: ë³µì¡í•œ ê³¼ì •ì„ ì§ê´€ì  ì˜ìƒìœ¼ë¡œ
```

#### 3. ê°œì¸í™” ì„œë¹„ìŠ¤ì˜ í™•ì‚°

**ê¸°ìˆ  ê²°í•©:**
DreamBooth + Tune-A-Video
```
ì…ë ¥: íŠ¹ì • ì¸ë¬¼ì˜ 3-5ê°œ ì‚¬ì§„ + ì›í•˜ëŠ” ë™ì‘ ì„¤ëª…
â†’ ê·¸ ì¸ë¬¼ì´ ê·¸ ë™ì‘ì„ ìˆ˜í–‰í•˜ëŠ” ë¹„ë””ì˜¤ ìƒì„±

ì‘ìš©: ê°œì¸ ìœ íŠœë¸Œ ì¸ë„¤ì¼, í”„ë¡œí•„ ë¹„ë””ì˜¤, ê´‘ê³  ë“±
```

**SNS ì½˜í…ì¸  ìƒì„±:**
```
ì¸í”Œë£¨ì–¸ì„œ í™œìš©:
- ë¹ ë¥¸ ì½˜í…ì¸  ì œì‘
- ê°œì¸í™”ëœ ê·¸ë¦¬íŒ… ë¹„ë””ì˜¤
- íŒ¬ ë§ì¶¤ ì½˜í…ì¸ 
```

### 6.3 í–¥í›„ ì—°êµ¬ ì‹œ ê³ ë ¤í•  ê¸°ìˆ ì  ì 
#### 1. ì¥ì‹œê°„ ë¹„ë””ì˜¤ ìƒì„±

**í˜„ì¬ í•œê³„:** 32í”„ë ˆì„ (2ì´ˆ @ 16fps)

**ë¬¸ì œì˜ ê·¼ì›:**
- ë©”ëª¨ë¦¬: $O(m \times 64 \times 64 \times 4)$ (í”„ë ˆì„ ìˆ˜ì— ì„ í˜•)
- Attention: ì—¬ì „íˆ ì‹œê°„ì— ëŒ€í•´ ë¹„ì„ í˜•

**í•´ê²° ë°©í–¥:**

**A) Autoregressive Generation**
```
ì²­í¬ ë¶„í• : ë¹„ë””ì˜¤ë¥¼ 8í”„ë ˆì„ì”© ë¶„í• 
â†’ ê° ì²­í¬ ìƒì„±
â†’ ì´ì „ ì²­í¬ë¥¼ ì¡°ê±´ìœ¼ë¡œ ë‹¤ìŒ ì²­í¬ ìƒì„±
â†’ Strideë¡œ ì—°ê²° (ê²¹ì¹¨ìœ¼ë¡œ ì¼ê´€ì„± ìœ ì§€)

ì¥ì : ë©”ëª¨ë¦¬ ì„ í˜•, ì‹œê°„ ììœ ë„ ë†’ìŒ
ë‹¨ì : ëˆ„ì  ì˜¤ë¥˜ ê°€ëŠ¥ì„±
```

**B) Hierarchical Diffusion**
```
ì €í•´ìƒë„ â†’ ê³ í•´ìƒë„ (Imagen Video ë°©ì‹)
ì¶”ê°€: ì €í•´ìƒë„ì—ì„œ ì¥ì‹œê°„ ìƒì„±
â†’ ìŠˆí¼ë ˆì¡¸ë£¨ì…˜ìœ¼ë¡œ ê³ í•´ìƒë„í™”

ì¥ì : íš¨ìœ¨ì  ì¥ì‹œê°„ ìƒì„±
ë‹¨ì : ëª¨ë¸ ìˆ˜ ì¦ê°€
```

**C) Memory-Efficient Attention**
```
Flash Attention: O(nÂ²/b) (b=ë¸”ë¡ í¬ê¸°)
â†’ ì‹¤ì œ ë©”ëª¨ë¦¬: O(nÂ²/b) (ë§¤ìš° ê°œì„ )

ì ìš©: Sparse ST-Attnì„ Flash Attentionìœ¼ë¡œ êµ¬í˜„
â†’ ë” ë§ì€ í”„ë ˆì„ ê°€ëŠ¥
```

#### 2. ëª…ì‹œì  ë™ì‘ ì œì–´

**í˜„ì¬:** í…ìŠ¤íŠ¸ë§Œ â†’ ëª¨í˜¸ì„± ë†’ìŒ

**í•„ìš”:** ì •í™•í•œ ë™ì‘ ì‚¬ì–‘

**ê¸°ìˆ  ê²½ë¡œ:**

**A) Pose-based Control**
```
ì…ë ¥: í‚¤í¬ì¸íŠ¸ ì‹œí€€ìŠ¤ (24-34ê°œ ê´€ì ˆ ì¢Œí‘œ)
â†’ ëª¨ë¸: í¬ì¦ˆ ì‹œí€€ìŠ¤ë¥¼ ë”°ë¥´ë„ë¡ ë¹„ë””ì˜¤ ìƒì„±
íš¨ê³¼: ì •í™•í•œ ë™ì‘ ì œì–´

êµ¬í˜„: ControlNet ì•„ì´ë””ì–´ (í¬ì¦ˆ ì¡°ê±´í™”)
```

**B) Trajectory Control**
```
ì…ë ¥: ì£¼ìš” ê°ì²´ì˜ ì´ë™ ê¶¤ì  (ìŠ¤ì¼€ì¹˜ ë“±)
â†’ ëª¨ë¸: ê¶¤ì ì„ ë”°ë¥´ë„ë¡ ìƒì„±
ì˜ˆ: ì¹´ë©”ë¼ íŒ¨ë‹ ê²½ë¡œ ì§€ì •
```

**C) Optical Flow Input**
```
ì…ë ¥: ì›ë³¸ ë¹„ë””ì˜¤ì˜ ê´‘í•™ íë¦„
â†’ ìˆ˜ì •: íë¦„ ìŠ¤ì¼€ì¼ ì¡°ì • (2ë°° â†’ 2ë°° ë¹ ë¥¸ ë™ì‘)
â†’ ìƒì„±: ìˆ˜ì •ëœ íë¦„ì„ ë”°ë¥´ë„ë¡ ë¹„ë””ì˜¤ ìƒì„±
```

#### 3. ë‹¤ì¤‘ ê°ì²´ ìƒí˜¸ì‘ìš©

**í˜„ì¬ í•œê³„:** ì—¬ëŸ¬ ê°ì²´ì˜ ìƒí˜¸ì‘ìš© ë¯¸í¡

**ê·¼ë³¸ ì›ì¸:** T2Iì˜ ë¹„ìŠ·í•œ í•œê³„ ìƒì†

**ê·¹ë³µ ë°©ë²•:**

**A) Scene Graphs**
```
ì¥ë©´ ê·¸ë˜í”„: ê°ì²´ ê°„ ê´€ê³„ë¥¼ ëª…ì‹œì ìœ¼ë¡œ í‘œí˜„
ì˜ˆ: [Boy] -[kick]-> [Ball]
â†’ ê·¸ë˜í”„ë¥¼ ì¡°ê±´ìœ¼ë¡œ ë¹„ë””ì˜¤ ìƒì„±
ì¥ì : ì •êµí•œ ìƒí˜¸ì‘ìš© ì œì–´ ê°€ëŠ¥
```

**B) Multi-Subject LoRA (VideoMage)**
```
ê° ê°ì²´ë³„ LoRA í•™ìŠµ
â†’ Spatial composition ê¸°ë²•ìœ¼ë¡œ ê²°í•©
â†’ ì—¬ëŸ¬ ê°ì²´ì˜ í˜‘ë ¥ ìƒì„± ê°€ëŠ¥
```

**C) Depth/Segmentation Guidance**
```
ì…ë ¥: ê¹Šì´ ë§µ + semantic segmentation
â†’ ëª¨ë¸: ê°ì²´ ë¶„ë¦¬ë¥¼ ì¸ì‹
â†’ ê²°ê³¼: ê°€ë¦¼(occlusion) ë¬¸ì œ í•´ê²°
```

#### 4. ì¼ë°˜í™” ì„±ëŠ¥ ì œê³ 

**ëª©í‘œ:** Few-shot â†’ Zero-shot ì´ë™

**ê¸°ìˆ ì  ì ‘ê·¼:**

**A) Meta-Learning**
```
ë©”íƒ€-í•™ìŠµ: "ë¹„ë””ì˜¤ ìƒì„±ì„ ë¹ ë¥´ê²Œ í•™ìŠµí•˜ëŠ” ëŠ¥ë ¥" í•™ìŠµ
â†’ MAML, Prototypical Networks ë“± í™œìš©
â†’ ìƒˆ ë¹„ë””ì˜¤ë„ ë§¤ìš° ì ì€ ë°ì´í„°ë¡œ ìƒì„± ê°€ëŠ¥
```

**B) Contrastive Learning**
```
ê°™ì€ ë™ì‘ì˜ ë³€í˜•ë“¤ í•™ìŠµ
â†’ ë™ì‘ì˜ ë³¸ì§ˆë§Œ ì¶”ì¶œ
â†’ ìƒˆë¡œìš´ ì¡°ê±´ (ë°°ê²½, ìŠ¤íƒ€ì¼)ì— ì¼ë°˜í™”
```

**C) Domain Randomization**
```
í•™ìŠµ: ì˜ë„ì ìœ¼ë¡œ ë‹¤ì–‘í•œ ë„ë©”ì¸ ì„ê¸°
â†’ ë¶„í¬ ì™¸(OOD) ê°•ê±´ì„± í–¥ìƒ
â†’ ì˜ˆìƒì¹˜ ëª»í•œ ì‹ ê·œ ì‹œë‚˜ë¦¬ì˜¤ì—ë„ ê°•í•¨
```

#### 5. í¸ì§‘ ì •ë°€ë„ í–¥ìƒ

**í˜„ì¬:** ì „ì—­ í¸ì§‘ (ì „ì²´ ë¹„ë””ì˜¤)

**í•„ìš”:** ì§€ì—­ í¸ì§‘ (íŠ¹ì • í”„ë ˆì„ ë˜ëŠ” ì˜ì—­)

**ê¸°ìˆ :**

**A) Spatial Attention Control**
```
ë§ˆìŠ¤í‚¹: í¸ì§‘í•  ì˜ì—­ì„ ë§ˆìŠ¤í¬ë¡œ ì§€ì •
â†’ í•´ë‹¹ ì˜ì—­ì˜ ì£¼ì˜ ë§µë§Œ ìˆ˜ì •
â†’ ë‚˜ë¨¸ì§€ëŠ” ë³´ì¡´
```

**B) Temporal Slicing**
```
í”„ë ˆì„ ë²”ìœ„ ì§€ì •: t1~t2 í”„ë ˆì„ë§Œ í¸ì§‘
â†’ ê·¸ ì™¸ëŠ” ë³´ì¡´
â†’ ë§¤ë„ëŸ¬ìš´ ì „ì´ ì¡°ì •
```

**C) Inpainting for Video**
```
ë°©ë²•: íŠ¹ì • í”„ë ˆì„ì˜ ì¼ë¶€ë¥¼ ë§ˆìŠ¤í‚¹
â†’ ëª¨ë¸: ê·¸ ë¶€ë¶„ë§Œ ìƒì„±
â†’ ì£¼ë³€ê³¼ì˜ ì¡°í™” ìë™ ìœ ì§€
```

#### 6. í‰ê°€ ë©”íŠ¸ë¦­ ê°œì„ 

**í˜„ì¬ í•œê³„:**
- CLIP ì ìˆ˜ëŠ” ì£¼ê´€ì  ì„ í˜¸ì™€ í•­ìƒ ì¼ì¹˜í•˜ì§€ ì•ŠìŒ
- ì›€ì§ì„ í’ˆì§ˆì˜ ì •ëŸ‰í™” ì–´ë ¤ì›€

**í•„ìš”í•œ ë©”íŠ¸ë¦­:**

**A) Temporal Consistency Metric**
```
ì •ì˜: í”„ë ˆì„ ê°„ ê´‘í•™ íë¦„ì˜ ë§¤ë„ëŸ¬ì›€
ê³„ì‚°: ì¸ì ‘ í”„ë ˆì„ì˜ íë¦„ ì°¨ì´ë„ (2ì°¨ ë¯¸ë¶„)
â†‘ ê°’: ë” ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ì›€ì§ì„
â†’ ë‹¤ì–‘í•œ ì›€ì§ì„ íŠ¹ì„± í¬ì°© ê°€ëŠ¥
```

**B) Motion Diversity Score**
```
ì •ì˜: ìƒì„± ë¹„ë””ì˜¤ì˜ ì›€ì§ì„ ë‹¤ì–‘ì„±
ë°©ë²•: ê´‘í•™ íë¦„ ë¶„í¬ì˜ ì—”íŠ¸ë¡œí”¼
â†’ Zero-motion ë¹„ë””ì˜¤ ê°ì§€ ê°€ëŠ¥
```

**C) User-Study Standardization**
```
í˜„ì¬: ì„ì˜ì˜ í‰ê°€ì, ê¸°ì¤€ ë¶ˆëª…í™•
ê°œì„ : êµ­ì œ í‘œì¤€ í‰ê°€ í”„ë¡œí† ì½œ ê°œë°œ
â†’ ëª¨ë¸ ê°„ ë¹„êµ ì‹ ë¢°ì„± í–¥ìƒ
```

### 6.4 ìœ¤ë¦¬ ë° ì‚¬íšŒì  ê³ ë ¤ì‚¬í•­
#### 1. ë”¥í˜ì´í¬(Deepfake) ìœ„í—˜

**ë¬¸ì œ:** DreamBooth + Tune-A-Video ê²°í•© â†’ íŠ¹ì •ì¸ ê°€ì§œ ë¹„ë””ì˜¤ ìƒì„± ê°€ëŠ¥

**ëŒ€ì‘:**
- ì›Œí„°ë§ˆí‚¹ ê¸°ìˆ  ê°œë°œ
- ìƒì„± ë¹„ë””ì˜¤ ì¸ì¦ ë°©ë²• ì—°êµ¬
- ì •ì±… ë ˆë²¨ ê·œì œ (EU AI Act ë“±)

#### 2. ì €ì‘ê¶Œ ë¬¸ì œ

**ë¬¸ì œ:** T2I ëª¨ë¸ í•™ìŠµì— ì €ì‘ê¶Œ ì´ë¯¸ì§€ ì‚¬ìš© â†’ íŒŒìƒ T2Vë„ ë²•ì  ë¬¸ì œ ê°€ëŠ¥

**í•´ê²°:**
- ì €ì‘ê¶Œ ì´ë¯¸ì§€ ì œì™¸ ë°ì´í„°ì…‹ ê°œë°œ
- ë¼ì´ì„¼ì‹± ëª¨ë¸ í‘œì¤€í™”
- í•™ìˆ -ìƒìš© ê²½ê³„ ëª…í™•í™”

#### 3. ê³„ì‚° ì—ë„ˆì§€ ë¹„ìš©

**ê¸ì •:** Tune-A-VideoëŠ” ì—ë„ˆì§€ íš¨ìœ¨ì  (1ì¥ GPU, 10ë¶„)

**ë§¥ë½:** ì—¬ì „íˆ ìˆ˜ì¡° ë§¤ê°œë³€ìˆ˜ì˜ ê¸°ì´ˆ ëª¨ë¸ í•„ìš”

**ê· í˜•:** íš¨ìœ¨ì„±ê³¼ ì„±ëŠ¥ ê°„ íŠ¸ë ˆì´ë“œì˜¤í”„ ì§€ì† ë…¼ì˜ í•„ìš”

***

## 7. ì¢…í•© ê²°ë¡ 
### 7.1 í˜ì‹ ì˜ í•µì‹¬
"Tune-A-Video"ëŠ” ë‹¨ìˆœíˆ ìƒˆë¡œìš´ ì•Œê³ ë¦¬ì¦˜ì´ ì•„ë‹ˆë¼ **íŒ¨ëŸ¬ë‹¤ì„ ì „í™˜**ì„ ì œì‹œí•©ë‹ˆë‹¤:

| êµ¬ë¶„ | ì´ì „ (2021ë…„) | ì´í›„ (2022ë…„~) |
|-----|------------|-------------|
| **í•™ìŠµ ë°©ì‹** | ëŒ€ê·œëª¨ ë¹„ë””ì˜¤ ë°ì´í„° | One-shot ë¯¸ì„¸ì¡°ì • |
| **í•„ìš” GPU** | 64-128ì¥ (ìˆ˜ì£¼) | 1ì¥ (10ë¶„) |
| **ì ‘ê·¼ì„±** | ëŒ€í˜• ê¸°ì—… ì—°êµ¬ì‹¤ | ê°œì¸ ì‚¬ìš©ì ê°€ëŠ¥ |
| **ê°œì¸í™”** | ë¶ˆê°€ëŠ¥ | ë§¤ìš° ìš©ì´ (DreamBooth ê²°í•©) |
| **ì†ë„** | ìˆ˜ ì‹œê°„ í•™ìŠµ | 10ë¶„ í•™ìŠµ, 1ë¶„ ìƒì„± |

### 7.2 í•™ìˆ ì  ê¸°ì—¬ë„ í‰ê°€
**5ì  ë§Œì  ê¸°ì¤€:**

| í‰ê°€ í•­ëª© | ì ìˆ˜ | ê·¼ê±° |
|---------|------|------|
| **ì°½ì˜ì„±** | â­â­â­â­â­ | One-shot T2V ê°œë…, ST-Attn ì„¤ê³„ |
| **ê¸°ìˆ ì  ê±´ì „ì„±** | â­â­â­â­ | Ablation ëª…í™•, í•˜ì§€ë§Œ ì¼ë¶€ í•œê³„ |
| **ì˜í–¥ë ¥** | â­â­â­â­â­ | í›„ì† ì—°êµ¬ ìˆ˜ì‹­ í¸, ì‚°ì—… ì±„íƒ |
| **ì¬í˜„ì„±** | â­â­â­â­ | ì½”ë“œ/ëª¨ë¸ ê³µê°œ, ìƒì„¸ ì„¤ëª… |
| **ì¼ë°˜í™”** | â­â­â­ | ì—¬ì „íˆ ì…ë ¥ ë¹„ë””ì˜¤ ì˜ì¡´ |

**ì¢…í•© í‰ì : 4.6/5** (ë§¤ìš° ìš°ìˆ˜)

### 7.3 ë‚¨ì€ ê³¼ì œ ë° ë¯¸ë˜ ë°©í–¥
**ë‹¨ê¸° (1-2ë…„):**
- âœ… Few-shot í™•ì¥ (2-5ê°œ ë¹„ë””ì˜¤)
- âœ… ì¥ì‹œê°„ ìƒì„± (32í”„ë ˆì„ â†’ 128í”„ë ˆì„)
- âœ… Motion ëª…ì‹œì  ì œì–´ ì¶”ê°€

**ì¤‘ê¸° (2-4ë…„):**
- ğŸ”„ Zero-shot ì¼ë°˜í™” ë‹¬ì„±
- ğŸ”„ ë‹¤ì¤‘ ê°ì²´ ìƒí˜¸ì‘ìš© í•´ê²°
- ğŸ”„ ì‹¤ì‹œê°„ ìƒì„± ê¸°ìˆ 

**ì¥ê¸° (4ë…„+):**
- ğŸ“Š ì‚¬ëŒ ìˆ˜ì¤€ì˜ ì°½ì˜ì„± (ìƒˆë¡œìš´ ë™ì‘ ë°œëª…)
- ğŸ“Š 3D ë¹„ë””ì˜¤ ìƒì„± (depth ì •ë³´ í¬í•¨)
- ğŸ“Š ì™„ì „ ìë™ ì˜í™” ì œì‘ íŒŒì´í”„ë¼ì¸

### 7.4 ìµœì¢… í‰ê°€
**"Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation"ì€:**

1. **í˜ì‹ ì  ë°©ë²•ë¡ :** Sparse ST-Attn + selective fine-tuning + DDIM inversionì˜ ì˜ë¦¬í•œ ì¡°í•©

2. **ì‹¤ë¬´ì  ê°€ì¹˜:** 10ë¶„ í•™ìŠµ, 1ë¶„ ìƒì„±ìœ¼ë¡œ ë¹„ë””ì˜¤ ìƒì„± ëŒ€ë¯¼ì£¼í™”

3. **í•™ìˆ ì  ì˜í–¥:** ì´í›„ 50ì—¬ í¸ì˜ í›„ì† ì—°êµ¬ ì˜ê° ì œê³µ

4. **ì§€ì†ì  ì§„í™”:** VideoMage, MotionDirector ë“± í™•ì¥ í˜•íƒœë¡œ ë°œì „

5. **ì‚¬íšŒì  ì˜í–¥:** ì½˜í…ì¸  ì œì‘ì˜ ë¯¼ì£¼í™”, ì°½ì˜ì„± ë„êµ¬í™”

**ì¢…í•© ê²°ë¡ :**
ì´ ë…¼ë¬¸ì€ **ìƒì„± AIì˜ íš¨ìœ¨ì„± í˜ëª…ì„ ì‹œì‘í•œ ì‘í’ˆ**ìœ¼ë¡œ, "ì‘ì€ ë°ì´í„°ë¡œë„ ê°•ë ¥í•œ ìƒì„±ì´ ê°€ëŠ¥í•˜ë‹¤"ëŠ” ìƒˆë¡œìš´ ì‹ ë…ì„ í™•ë¦½í–ˆìŠµë‹ˆë‹¤. ë¹„ë¡ ì—¬ì „íˆ ì…ë ¥ êµ¬ì¡°ì— ì˜ì¡´í•˜ëŠ” í•œê³„ê°€ ìˆì§€ë§Œ, ì´ëŠ” í–¥í›„ ì—°êµ¬ì˜ ëª…í™•í•œ ë°©í–¥ì„ ì œì‹œí•˜ë©°, í˜„ì¬ì˜ ë°œì „ ê¶¤ë„ëŠ” ì´ëŸ¬í•œ í•œê³„ë¥¼ ì ì§„ì ìœ¼ë¡œ ê·¹ë³µí•˜ê³  ìˆìŠµë‹ˆë‹¤.

***

## ì°¸ê³ : í•µì‹¬ ìˆ˜ì‹ ë° ë³µì¡ë„ ë¶„ì„ ìš”ì•½
### í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜ ìˆ˜ì‹
**1. Sparse Spatio-Temporal Attention:**

$$\text{ST-Attn}(Q, K, V) = \text{Softmax}\left(\frac{Q \cdot [K_1; K_{i-1}]^T}{\sqrt{d}}\right) \cdot [V_1; V_{i-1}]$$

**2. í•™ìŠµ ëª©í‘œ:**

$$\mathcal{L} = \mathbb{E}_{z, \epsilon \sim \mathcal{N}(0,I), t, c}\left[\|\epsilon - \epsilon_\theta(z_t, t, c)\|_2^2\right]$$

**3. DDIM Inversion + Sampling:**

$$V' = \mathcal{D}_{\text{DDIM-samp}}(\mathcal{E}_{\text{inversion}}(V), T')$$

### ë³µì¡ë„ ê°œì„ 
| ë©”ì»¤ë‹ˆì¦˜ | Before | After | ê°œì„  ë°°ìœ¨ |
|--------|--------|-------|---------|
| **Attention** | $O(m^2N^2)$ | $O(2mN^2)$ | më°° ê°œì„  |
| **ë©”ëª¨ë¦¬** | 32GB | 6GB | 5ë°° ê°œì„  |
| **í•™ìŠµ ì‹œê°„** | ìˆ˜ì£¼ | 10ë¶„ | 1000ë°° ê°œì„  |
| **ì¶”ë¡ ** | ìˆ˜ ì´ˆ/í”„ë ˆì„ | 1ì´ˆ/ë¹„ë””ì˜¤ | 30ë°° ê°œì„  |

***

<span style="display:none">[^1_1][^1_10][^1_11][^1_12][^1_13][^1_14][^1_15][^1_16][^1_17][^1_18][^1_19][^1_2][^1_20][^1_21][^1_22][^1_23][^1_24][^1_25][^1_26][^1_27][^1_28][^1_29][^1_3][^1_30][^1_31][^1_32][^1_33][^1_34][^1_35][^1_36][^1_37][^1_38][^1_39][^1_4][^1_40][^1_41][^1_42][^1_43][^1_44][^1_45][^1_46][^1_47][^1_48][^1_49][^1_5][^1_50][^1_51][^1_52][^1_53][^1_54][^1_55][^1_56][^1_57][^1_58][^1_59][^1_6][^1_60][^1_61][^1_62][^1_63][^1_64][^1_65][^1_66][^1_67][^1_68][^1_69][^1_7][^1_70][^1_71][^1_72][^1_73][^1_74][^1_8][^1_9]</span>

<div align="center">â‚</div>

[^1_1]: 2212.11565v2.pdf

[^1_2]: https://dl.acm.org/doi/10.1145/3707292.3707367

[^1_3]: https://arxiv.org/abs/2511.05535

[^1_4]: https://open-publishing.org/publications/index.php/APUB/article/view/2769

[^1_5]: http://arxiv.org/pdf/2305.13840v1.pdf

[^1_6]: http://arxiv.org/pdf/2408.12590.pdf

[^1_7]: http://arxiv.org/pdf/2408.06072.pdf

[^1_8]: https://arxiv.org/html/2410.20502v1

[^1_9]: http://arxiv.org/pdf/2403.14773.pdf

[^1_10]: http://arxiv.org/pdf/2406.02230.pdf

[^1_11]: https://arxiv.org/abs/2305.18264

[^1_12]: http://arxiv.org/pdf/2406.04277.pdf

[^1_13]: https://www.emergentmind.com/topics/text-to-video-diffusion-models

[^1_14]: https://www.sciencedirect.com/science/article/abs/pii/S0957417425032646

[^1_15]: https://www.emergentmind.com/topics/spatial-temporal-attention-mechanism

[^1_16]: https://en.wikipedia.org/wiki/Text-to-video_model

[^1_17]: https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/07921.pdf

[^1_18]: https://www.nature.com/articles/s41598-024-75640-6

[^1_19]: https://arxiv.org/abs/2408.06072

[^1_20]: https://kimjy99.github.io/ë…¼ë¬¸ë¦¬ë·°/stylecrafter/

[^1_21]: https://openaccess.thecvf.com/content/CVPR2024W/GAZE/papers/Jindal_Spatio-Temporal_Attention_and_Gaussian_Processes_for_Personalized_Video_Gaze_Estimation_CVPRW_2024_paper.pdf

[^1_22]: https://learnopencv.com/video-generation-models/

[^1_23]: https://arxiv.org/html/2407.08674v1

[^1_24]: https://ieeexplore.ieee.org/document/11125912/

[^1_25]: https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_VideoMage_Multi-Subject_and_Motion_Customization_of_Text-to-Video_Diffusion_Models_CVPR_2025_paper.pdf

[^1_26]: https://openaccess.thecvf.com/content/CVPR2025/papers/Kara_ShotAdapter_Text-to-Multi-Shot_Video_Generation_with_Diffusion_Models_CVPR_2025_paper.pdf

[^1_27]: https://arxiv.org/abs/2504.12027

[^1_28]: https://arxiv.org/html/2503.04606v1

[^1_29]: https://arxiv.org/pdf/2302.08453.pdf

[^1_30]: https://arxiv.org/html/2512.13247v1

[^1_31]: https://arxiv.org/html/2507.03745v2

[^1_32]: https://arxiv.org/html/2507.16869v1

[^1_33]: https://arxiv.org/html/2502.17863v1

[^1_34]: https://arxiv.org/html/2511.17844

[^1_35]: https://arxiv.org/html/2412.18688v2

[^1_36]: https://openaccess.thecvf.com/content/CVPR2021/papers/Suin_Gated_Spatio-Temporal_Attention-Guided_Video_Deblurring_CVPR_2021_paper.pdf

[^1_37]: https://arxiv.org/html/2407.14209v2

[^1_38]: https://arxiv.org/abs/2302.08453

[^1_39]: https://arxiv.org/html/2504.12027v1

[^1_40]: https://www.mdpi.com/2227-7102/15/11/1472

[^1_41]: https://arxiv.org/html/2503.20724v1

[^1_42]: https://arxiv.org/html/2312.04966v1

[^1_43]: https://arxiv.org/pdf/2311.18827.pdf

[^1_44]: https://arxiv.org/pdf/2311.11325.pdf

[^1_45]: https://arxiv.org/pdf/2402.14780.pdf

[^1_46]: https://arxiv.org/html/2411.10501v1

[^1_47]: https://repositorio.iscte-iul.pt/bitstream/10071/23190/1/conferenceobject_30698.pdf

[^1_48]: https://arxiv.org/html/2406.17758v2

[^1_49]: https://www.merl.com/publications/docs/TR2024-059.pdf

[^1_50]: https://www.youtube.com/watch?v=_bFPL3ZD4Ko

[^1_51]: https://www.emergentmind.com/papers/2310.08465

[^1_52]: https://openaccess.thecvf.com/content/ICCV2025/papers/Lin_STIV_Scalable_Text_and_Image_Conditioned_Video_Generation_ICCV_2025_paper.pdf

[^1_53]: https://openaccess.thecvf.com/content/CVPR2023/papers/Ruiz_DreamBooth_Fine_Tuning_Text-to-Image_Diffusion_Models_for_Subject-Driven_Generation_CVPR_2023_paper.pdf

[^1_54]: https://showlab.github.io/MotionDirector/

[^1_55]: https://openreview.net/pdf/e09748202d19f56b06015b45722d82b51021a14c.pdf

[^1_56]: https://www.semanticscholar.org/paper/DreamBooth:-Fine-Tuning-Text-to-Image-Diffusion-for-Ruiz-Li/5b19bf6c3f4b25cac96362c98b930cf4b37f6744

[^1_57]: https://arxiv.org/abs/2310.08465

[^1_58]: https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt

[^1_59]: https://huggingface.co/papers/2208.12242

[^1_60]: https://liner.com/review/videomage-multisubject-and-motion-customization-texttovideo-diffusion-models

[^1_61]: https://ostin.tistory.com/298

[^1_62]: https://www.youtube.com/watch?v=f9FWJ9UjZ-U

[^1_63]: https://arxiv.org/html/2503.21781v1

[^1_64]: https://arxiv.org/html/2511.03156v1

[^1_65]: https://openaccess.thecvf.com/content/CVPR2024/papers/Ni_TI2V-Zero_Zero-Shot_Image_Conditioning_for_Text-to-Video_Diffusion_Models_CVPR_2024_paper.pdf

[^1_66]: https://www.semanticscholar.org/paper/6541f0f74cf6f6d0d8b4a8d9efb64d5e0729bc13

[^1_67]: https://arxiv.org/html/2505.20629v1

[^1_68]: https://openaccess.thecvf.com/content/CVPR2024/papers/Shi_InstantBooth_Personalized_Text-to-Image_Generation_without_Test-Time_Finetuning_CVPR_2024_paper.pdf

[^1_69]: https://www.semanticscholar.org/paper/aee2bb8d4d1a34424b3a5843ef945d8cdf823e60

[^1_70]: https://arxiv.org/html/2404.16306v1

[^1_71]: https://arxiv.org/abs/2208.12242

[^1_72]: https://www.semanticscholar.org/paper/c562f5b6cbcffb2a42df39b5a7ca9a7cd17c5e5f

[^1_73]: https://arxiv.org/html/2410.15957v3

[^1_74]: https://arxiv.org/abs/2511.03156
