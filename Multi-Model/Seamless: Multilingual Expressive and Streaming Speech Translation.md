# Seamless: Multilingual Expressive and Streaming Speech Translation

**핵심 주장 및 주요 기여**  
Seamless는 대규모 다국어·다중모달 음성·텍스트 번역 시스템을 통합하여, 1) 표현력을 보존하는 고품질 음성 간 직접 번역(SeamlessExpressive), 2) 실시간 스트리밍 번역(SeamlessStreaming)을 동시에 지원하는 **세계 최초의 공개 시스템**을 제안한다. 이를 위해  
- **SeamlessM4T v2**: 100개 입력 언어·96개 출력 언어를 지원하는 기반 모델로, 비-자동회귀 UnitY2 텍스트→단위 변환기와 대규모 W2V-BERT 2.0 음성 인코더를 도입해 번역 정확도 및 추론 속도를 3배 개선  
- **SeamlessExpressive**: 어투·음색·리듬·중단 등을 보존하는 Prosody UnitY2와 PRETSSEL 텍스트리스 음향모델로 음성 표현력을 크게 향상  
- **SeamlessStreaming**: Efficient Monotonic Multihead Attention(EMMA) 기반 동시통역 정책을 결합해 101개 입력 언어↔36개 출력 언어의 실시간 음성·텍스트 번역 구현  

# 1. 해결 과제  
– 기존 대규모 음성 번역 모델들은  
  1) 말투·음색·리듬·중단 등 인간적 표현 보존 미흡  
  2) 오프라인 배치 방식만 지원해 실시간 대화 불가능  
  3) 다국어 실시간 직접 음성→음성 번역 미지원  
본 논문은 위 세 가지 한계를 **통합 모델 설계**로 동시 극복하고자 한다.  

# 2. 제안 기법  
## 2.1 SeamlessM4T v2 기반 구조  
– **X2T 모듈**: 대규모 W2V-BERT 2.0 음성 인코더 + NLLB 기반 Transformer 텍스트 디코더; 음성→텍스트(S2TT), ASR, TTS, 텍스트→텍스트 번역(2T T) 지원  
– **UnitY2 비-자동회귀 T2U**: 텍스트→10K 단위(20 ms 간격) 변환기로, 계층적 업샘플링(부분어→문자→단위) 및 span-based Glancing 학습 활용  
– **학습 데이터**: 4.5M시간 음성 자체지도, 350K시간 S2TT, 145K시간 S2S 자동·유사정렬·유사라벨링 결합  
– **목표함수**: 음성→텍스트, 텍스트→텍스트, ASR, 자가지도(CTC), 지식증류(KL) 결합  

## 2.2 SeamlessExpressive (오프라인)  
– **문제**: 말투·리듬·중단·음색 보존  
– **Prosody UnitY2**: 소스 음성에서 Prosody Embedding(ECAPA-TDNN) 추출→글로킹 T2U에 FiLM 조건부 주입→단위생성  
– **PRETSSEL**: (텍스트리스) Mel 예측 오디오 생성기로, UnitY2 단위+Prosody Embedding+언어 임베딩을 FiLM으로 결합  
– **학습**: 6개 언어(영·불·독·이·중·서) mExpresso, mDRAL 등 30K시간 병렬 표현 정렬 데이터로 미세조정  
– **성과**: 주요 표현성 지표 AutoPCP +10–20%, 화자유사도 +20–30%, 음성 출력 품질(MOS) 유지  

## 2.3 SeamlessStreaming (실시간)  
– **EMMA**: 안정적 수치식(Equation 28)으로 단어 단위 Monotonic Attention 확장  
– **지연제어**: Latency = 평균 지연(AL, Equation 37), Duration-adaptive(AL) 및 음성 종료지연 사용  
– **학습**: 2단계 미세조정(1단계: S2T+EMMA; 2단계: T2U)  
- **지원**: 101개 입력 언어→텍스트 96개 / 음성 36개; ASR 96개 동시 번역  
- **성능**: 오프라인 대비 S2TT BLEU 손실 10–20%, 지연 〈2 s; S2ST ASR-BLEU 손실 15–25%, 종료지연 〈4 s  

# 3. 성능 향상 및 한계  
– **정확도**: Fleurs S2TT X→E BLEU 26.6 (+2.5), S2ST X→E ASR-BLEU 39.2 (+3.5) 최고  
– **속도**: UnitY2로 S2S 추론 3× 가속 (Figure 30)  
– **견고성**: 잡음·말투 변동 대비 BLEU+42%, WER+56% 개선  
– **책임성**: 적대 입력 통한 Red-Teaming 최소화, MuTox 음성독성 탐지(21개 언어), MinTox 추론시 독성 억제, 27.5%
여성편향 감소  
– **워터마킹**: Frenquency 레벨 삽입·정확 검출(1 sf 샘플 단위)  
– **한계**:  
  1) 오프라인 모델 의존도↑→실시간 제약  
  2) 저자원 언어·성별·악센트별 성능 불균일  
  3) 미세과제(하위문맥) 유지 어려움  

# 4. 일반화 성능 전망  
SeamlessM4T v2의 **대규모 데이터·자체지도 학습**과 **Non-Auto T2U**는 소량 자원, 신규 도메인 언어에
대한 적은 미세조정만으로도 높은 전이 성능을 기대할 수 있다. 특히 비-자동회귀 T2U는 신규 단어·문장 길이
확장 시에도 안정적 추론을 보장하므로 다음과 같은 연구로 이어질 전망이다.  
- 신규 언어·악센트 빠른 추가  
- 장문·강의·방송용 실시간·표현 번역  
- 사후편집·피드백 기반 적응형 모델  

# 5. 사회적 파급 및 향후 과제  
– **사용자 경험**: 웨어러블·AR/VR·스트리밍 멀티언어 실시간 음성통역, 교육·공공기관·의료 접근성 제고  
– **윤리·안전**: 독성·편향·딥페이크 대응 워터마킹+검출, 다중 모달 속성 기반 오용 방지·AI 리터러시 강화  
– **차세대 연구**: 손말·제스처·표정 통합 번역, 시청각·생체정보·문맥 기반 적응형 통합 통번역 시스템 실현  
– **고려사항**: 디지털 리터러시· 개인정보보호·사회문화적 문맥 민감성 확보 필요  

Seamless는 음성 번역 분야에서 **“표현력·속도·다국어”**라는 세 마리 토끼를 동시에 잡아, 과학소설 속
“Universal Translator”에 한걸음 더 다가선 획기적 기술로서 차세대 연구를 촉발할 것입니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/6ba9d7a8-431a-4a2d-8a43-767fc1a9406e/2312.05187v1.pdf)
