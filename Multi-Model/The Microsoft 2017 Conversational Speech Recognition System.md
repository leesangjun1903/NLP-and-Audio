# The Microsoft 2017 Conversational Speech Recognition System

## 1. 핵심 주장 및 주요 기여 요약  
**주장:** Microsoft의 2017년 대화형 음성인식 시스템은 새로운 CNN-BLSTM 음향 모델과 문자 기반 및 세션 기반 LSTM 언어 모델을 결합하고, 이들 모델의 프레임 수준·단어 수준 결합 및 혼동 네트워크 재스코어링을 통해 Switchboard 벤치마크에서 5.1%의 단어 오류율(WER)을 달성하여 인간 다중 필사자 수준의 정확도에 도달했다.[1]
**주요 기여:**  
- CNN-BLSTM 음향 모델 도입 및 네 가지 서로 다른 senone 세트를 활용한 프레임-수준 조합  
- 문자 기반 및 대화 세션 전체를 컨텍스트로 삼는 세션-기반 LSTM 언어 모델 추가  
- N-gram, LSTM-LM, 혼동 네트워크 단계별 재스코어링과 backchannel 패널티 기반 최적화  

## 2. 문제 정의, 제안 방법, 모델 구조, 성능 향상 및 한계  

### 2.1 해결하고자 하는 문제  
- **대화체 음성인식의 난제:** Switchboard 같은 자연 대화에는 불규칙한 발화, 중첩 발화, filled pause(“uh”, “um”)와 backchannel(“uh-huh”) 혼동 문제 등이 있어 높은 정확도 달성이 어려움.[1]

### 2.2 제안하는 방법  
- **음향 모델( Acoustic Models):**  
  - ResNet, LACE, BLSTM, 그리고 새로 도입된 CNN-BLSTM 아키텍처를 사용.[1]
  - 서로 다른 senone(하위 음소 단위) 클러스터링(9k vs. 27k)과 사전(phone set)으로 네 종류의 senone 세트 생성.  
  - 동일 senone을 갖는 모델 간에는 프레임 수준(posteriors) 결합, 그 외는 단어 수준(confusion network) 결합 수행.  
- **언어 모델( Language Models):**  
  - 기존 단어 기반 LSTM-LM에 추가하여 문자(character) 기반 LSTM-LM과, 대화 전체 컨텍스트(session history) 및 화자 변화·중첩 여부를 입력으로 하는 세션-기반 LSTM-LM 도입.[1]
  - N-gram 디코딩 → 500-best list 생성 → LSTM-LM 재스코어 → 로그선형 결합 → 혼동 네트워크 재스코어 → backchannel 패널티 적용 순서.  

### 2.3 수식 핵심  
- **시퀀스 훈련:** 최대 상호 정보량( MMI)을 목표로 하여 음소·senone을 분모 그래프(trigram LM)로 한 단계로 학습.[1]
- **세션-기반 LSTM 입력 확장:**  

$$
    x_t = [w_{t-1}, \dots, w_1;\; b_t;\; o_t]
  $$  
  
  - $$w_{t-1}\dots w_1$$: 이전 발화 단어 시퀀스  
  - $$b_t$$: 화자 변경 여부(0/1)  
  - $$o_t$$: 발화 중첩 여부(0/1)  
- **혼동 네트워크 재스코어:** backchannel 수를 $$c$$라 할 때, 최종 점수에 $$\lambda \cdot c$$ 패널티 부과, $$\lambda$$는 개발집합 최적화로 학습.  

### 2.4 모델 구조  
| 구성 요소             | 구조 요약                                                   |
|----------------------|-------------------------------------------------------------|
| CNN-BLSTM            | 입력 윈도우(−3,3) → 3개의 Conv layers → 6-layer BLSTM      |
| 세션-기반 LSTM-LM    | 문자/단어 트리그램 임베딩 → 2~3개의 LSTM 레이어(+맥락 입력)   |
| 시스템 결합          | 7개의 최적 조합 시스템 동등 가중 혼동 네트워크 & 재스코어링 |

### 2.5 성능 향상  
- 기본 N-gram LM 대비 개별 시스템에 LSTM-LM 적용 시 22–25% 상대적 오류율 감소.  
- 프레임 수준 모델 조합으로 추가 15–20% 절대 WER 개선(예: 8.4% → 7.2%).  
- 혼동 네트워크 및 backchannel 패널티 적용 후 최종 5.1% WER 달성.[1]

### 2.6 한계  
- **노이즈된 1-best 히스토리 의존성:** 세션-LM 입력으로 1-best 사용 시 실제 히스토리 이용 대비 perplexity 이득의 7–8%가 상쇄.[1]
- **계산 비용:** 다중 모델 훈련과 재스코어링 단계가 매우 비용이 높고 복잡도가 높음.  
- **장르 한정성:** Switchboard 대화 도메인에 최적화되어 있어 CallHome 등 다른 장르 일반화 가능성 미확인.  

## 3. 일반화 성능 향상 관점  
- **다양한 senone 세트 및 모델 아키텍처 결합:** 서로 다른 오류 특성을 지닌 모델 조합이 오버피팅 위험을 줄이고 **다양한 음향 상황**에서 강건함을 제공한다.  
- **세션-기반 컨텍스트 이용:** 대화 전역의 토픽 일관성과 인접화 발화 패턴을 학습함으로써 **대화체 변이**에 대한 적응 가능성 확대.  
- **문자 기반 LSTM-LM:** OOV 및 희귀 단어 처리를 개선해 **도메인 변화** 시에도 언어 모델 범용성을 높일 수 있음.  

## 4. 향후 연구에 대한 영향 및 고려사항  
- **세션-LM 일반화:** 다른 대화 도메인(CallHome, 온라인 스트리밍 등)에서의 세션-LM 효과 재검증 필요.  
- **노이즈 히스토리 보완:** 1-best 대신 n-best 히스토리 활용이나 히스토리 보정 기법 개발로 세션-LM 이득 회복 연구.  
- **효율적 추론:** 모델 압축·지식 증류·온디바이스 적용을 위한 경량화 방안 모색.  
- **다국어 확장:** 다양한 언어·악센트에 대한 senone 및 세션-LM 일반화 가능성 탐색.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/54c65bc3-4883-43bc-8b25-4603e9712f37/1708.06073v2.pdf)
