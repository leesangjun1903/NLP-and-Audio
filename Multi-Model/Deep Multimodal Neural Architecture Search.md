# Deep Multimodal Neural Architecture Search

**주요 주장 및 기여**  
Deep Multimodal Neural Architecture Search(MMnas)은 **여러 멀티모달 학습 과제**(VQA, 이미지–텍스트 매칭, 비주얼 그라운딩)를 하나의 **통일된 인코더-디코더 백본**과 과제별 헤드를 통해 처리하면서, **자동화된 NAS(Neural Architecture Search) 기법**으로 각 과제에 최적화된 구조를 탐색한다. 수동 설계된 모델보다 **파라미터 효율적**이며, **태스크 특성에 맞춘 최적 구조**를 찾음으로써 모든 과제에서 **기존 최첨단 기법을 능가**하는 성능을 달성한 것이 핵심 기여이다.[1]

## 문제 정의  
기존 멀티모달 모델들은 대개 하나의 과제에 특화된 **수작업 구조**를 사용하므로, 다른 과제로 일반화하기 어렵다. 이를 해결하기 위해 다음 세 가지 과제에서 모두 동작 가능한 **통합적 구조 생성 방법**이 필요하다.  
- **VQA**(Visual Question Answering)  
- **ITM**(Image–Text Matching)  
- **VG**(Visual Grounding)

## 제안 방법

### 1. 통일된 인코더-디코더 백본  
입력된 **이미지 객체 특징** $$X$$와 **문장 특징** $$Y$$를 처리하기 위해, 다층의 인코더 블록과 디코더 블록을 쌓은 구조를 사용한다.  
- **인코더 블록**  
  - 후보 연산: **Self-Attention(SA)**, **Feed-Forward Network(FFN)**  
  - 문장 $$Y$$만을 받아 내부 상호작용을 모델링  

$$
    \mathrm{enc}_i = \mathrm{Op}_i(Y_{i-1}),\quad Y_0 = Y
  $$

- **디코더 블록**  
  - 후보 연산: **SA**, **Guided-Attention(GA)**, **Relation SA(RSA)**, **FFN**  
  - 이미지 특징 $$X$$, 관계 특징 $$R$$, 인코더 출력 $$Y$$를 결합  

$$
    \mathrm{dec}_j = \mathrm{Op}_j(X_{j-1},\,Y),\quad X_0 = X
  $$

### 2. NAS 기반 탐색 알고리즘  
- **Supernet**: 모든 후보 연산을 가중치 공유 방식으로 포함  
- **One-shot gradient NAS**:  
  1) 모델 가중치 $$\omega$$ 학습 (아키텍처 가중치 $$\alpha$$ 고정)  
  2) 아키텍처 가중치 $$\alpha$$ 학습 ($$\omega$$ 고정)  
  3) 각 블록에서 $$\max(\alpha)$$ 연산 선택하여 최종 구조 확정[1]

### 3. 과제별 헤드  
- **VQA 헤드**: 문장–이미지 축소(attentional reduction) 후 분류  
- **ITM 헤드**: 축소된 특성으로 매칭 점수 계산, BCE 손실[1]
- **VG 헤드**: 객체별 랭킹 점수 및 바운딩박스 오프셋 회귀, KL 랭크 손실과 Smooth L1 회귀 손실 조합[1]

## 성능 개선 및 한계

### 성능 향상  
- VQA-v2: 전체 정확도 71.46%로 기존 최고치 대비 +0.56%p 개선, 특히 수치 응답(Number) 정확도에서 +1.42%p 상승.[1]
- Flickr30K ITM: R@1=78.3%, R@10=97.4%로 크게 향상.[1]
- RefCOCO 시리즈 VG: COCO 사전학습 MRCN 백본 사용 시 TestA 82.5% 달성.[1]

### 한계  
- **탐색 비용**: Supernet 구축 및 양단계 최적화로 연산량이 크며, 대규모 데이터셋에 최적화된 사전학습 없이도 높은 성능을 유지하려면 추가 연구 필요.  
- **일반화 보장**: NAS로 찾아진 구조가 다른 멀티모달 과제나 데이터셋으로 전이될 때 성능 보장이 아직 미검증.

## 일반화 성능 향상 가능성  
MMnas는 **모듈화된 연산 풀**과 **gradient one-shot NAS**를 통해 각 과제의 특성에 맞춘 구조를 자동 탐색하므로,  
- **파라미터 효율성**: 사전학습 없이도 작은 모델로 높은 성능 달성  
- **태스크 적응성**: VQA, ITM, VG에서 각각 다른 최적 구조를 설계, 과제 간 지식 공유 및 전이 가능성 보유[1]

특히 **RSA(Relation SA)** 연산 도입으로 객체 간 공간 관계를 모델링해 수치 응답 과제에서 일반화 성능을 크게 개선했다.[1]

## 향후 영향 및 고려 사항  
- **대규모 사전학습 결합**: MMnas로 탐색된 구조에 멀티모달 BERT 스타일의 대규모 사전학습을 적용하면 추가 성능 향상이 기대됨.  
- **확장성**: 연산 풀에 새로운 모듈(e.g., Transformer block variants)을 추가해 더 다양한 과제에 적용 가능.  
- **탐색 비용 절감**: Proxyless NAS, 차별화된 채널 연결 기법 등으로 검색 효율을 높이는 후속 연구 필요.

MMnas는 **NAS를 멀티모달 학습에 적용한 최초의 통합** 프레임워크로, **작은 규모에서도 태스크별 최적화된 구조**를 자동으로 발굴함으로써 향후 멀티모달 AI 모델 경량화 및 범용화 연구에 중요한 기준점을 제공할 것이다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/199a4142-9426-46c3-9cce-b7392873981f/2004.12070v2.pdf)
