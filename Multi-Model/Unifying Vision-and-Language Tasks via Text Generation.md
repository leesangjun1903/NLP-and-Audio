# Unifying Vision-and-Language Tasks via Text Generation

## 주요 주장 및 기여  
**“Unifying Vision-and-Language Tasks via Text Generation”** 논문은 서로 다른 시각·언어(VL) 과제를  
단일 아키텍처와 동일한 언어 모델링 목표(조건부 텍스트 생성)로 통합하는 **범용 프레임워크**를 제안한다.[1]
기존 VQA, 시각 추론, 지칭 표현 이해, 이미지 캡션 등 각기 다른 과제에 맞춰 별도 설계한 분류기·스코어러·디코더 대신,  
이미지-텍스트 입력을 받아 텍스트 형태로 정답 레이블을 생성하도록 함으로써  
모든 VL 과제를 **하나의 생성적 모델**로 처리할 수 있음을 보여준다.[1]

## 해결하려는 문제  
- **과제별 모델 설계 비용**: VQA는 다중 레이블 분류기, 지칭 표현은 영역 스코어링, 이미지 캡션은 디코더 등 과제마다 고유 구조·목표 필요  
- **제한된 일반화 능력**: 분류 방식 기반의 모델은 빈도 높은 레이블 집합에만 최적화되어 희귀 답변(out-of-domain)에 약함  

이 논문은 위 문제를 해결하기 위해 **공통 언어 모델(head)과 최대우도 추정(MLE) 목표** 아래,  
모든 과제를 텍스트 생성 문제로 재정의한다.[1]

## 제안 방법  
### 1. 모델 구조  
- **VL-T5, VL-BART**: T5Base 및 BARTBase를 시각 입력 처리 가능하도록 확장한 인코더-디코더 아키텍처  
- **멀티모달 인코더**: Faster R-CNN 기반 객체 영역(n≤36) 특징, 박스 좌표, 이미지·영역 ID 임베딩을 합산하여 토큰 임베딩과 함께 입력  
- **텍스트 임베딩**: 과제별 접두어(prefix) 삽입(vqa, visual grounding 등) + “vis_i” 시각 센티넬 토큰으로 영역 ID 표현  
- **공통 언어 모델 헤드**: 모든 과제에 대해 동일한 디코더 및 언어 모델링(head)만 사용  

### 2. 학습 목표  
모든 과제에서 입력 텍스트 $$x$$·이미지 $$v$$ 기반으로 레이블 텍스트 $$y$$를 생성하도록 MLE 학습  

$$
\mathcal{L}_{\mathrm{GEN}} = -\sum_{j=1}^{|y|}\log P(y_j \mid y_{<j}, x, v)
$$  

– 추가적인 분류기나 스코어러 없이, 언어 모델의 음절 단위 확률 예측으로 모든 과제를 통합해 학습.[1]

## 성능 향상 및 일반화 능력  
1. **다양한 VL 벤치마크(7개)**: VQA, GQA, NLVR2, RefCOCOg, VCR(QA/QAR), COCO 캡션, Multi30K En-De 번역에서  
   - 단일 통합 모델로 **기존 과제별 SOTA 모델**과 거의 동등한 성능 달성.[1]
2. **희귀 답변 일반화**: VQA에서 top-$$K$$ 후보에 정답이 포함되지 않는 out-of-domain 질문 성능 비교  
   - 분류 기반 UNITER 대비 3점 우월, 생성 기반 VL-T5/VL-BART는 희귀 답변 정확도에서 각각 +6.0, +6.2점 향상.[1]
3. **멀티태스크 학습**: 7개 과제를 하나의 모델로 동시 finetuning 시, 단일 과제 전용 모델 대비 성능 손실 미미.[1]

## 한계 및 일반화 성능 향상 가능성  
- **지칭 표현 이해(RefCOCOg)**: VL-BART 학습 불안정, 절대 위치 임베딩 방식 차이로 validation 성능 저하 관찰  
- **입력 접두어(prompt engineering)**: 단순 접두어 사용, 과제별 최적화된 프롬프트 설계로 추가 성능 향상 여지  
- **대규모 비전-언어 전처리**: VL-T5/BART 사전학습 데이터(180K 이미지) 규모가 일부 SOTA 모델 대비 작음, 데이터 확장 시 성능 개선 기대  

## 향후 연구 영향 및 고려 사항  
- **범용 멀티모달 모델**: 단일 언어 모델링 목표로 다양한 VL 과제를 다룬다는 개념은 향후 멀티모달 AI 연구의 **통합적** 설계 방향 제시  
- **프롬프트 기반 적응**: 접두어(prompt) 설계·최적화 연구를 통해 생성 모델의 **콜드 스타트 일반화** 능력 증대  
- **다른 모달리티 확장**: 텍스트·이미지 외에도 오디오·비디오 등 다양한 모달리티를 동일 생성적 프레임워크로 통합하는 연구 적용 가능  
- **효율적 멀티태스크 학습**: 모델 파라미터·계산량을 선별적 공유하는 아키텍처 최적화로 대규모 멀티태스크 동시 학습 성능 극대화 추진  

***
 file:1[1]
 file:1 Table 3

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/61bc1a4a-fe9d-496a-aa86-f4cfae7a65ab/2102.02779v2.pdf)
