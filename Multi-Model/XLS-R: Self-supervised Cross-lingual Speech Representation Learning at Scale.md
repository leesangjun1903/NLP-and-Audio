# XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale

**주요 주장 및 기여**  
XLS-R은 128개 언어, 436K시간 규모의 공개 음성 데이터를 활용해 최대 2B 파라미터의 크로스-링구얼 자기지도 학습 모델을 제안한다. 이를 통해 저자원 언어에서의 음성인식 및 음성번역 성능을 획기적으로 개선하고, 단일 모델로 다수 언어를 지원하는 범용 음성 표현 학습의 가능성을 입증했다.

## 1. 해결하고자 하는 문제  
기존 멀티링구얼 음성 모델은  
- 학습 데이터 규모(최대 50K시간) 및 모델 크기(300M 파라미터)에 한계  
- 고자원 언어 편중으로 저자원 언어 일반화 어려움  
를 안고 있었다.

## 2. 제안 방법  
1) **대규모 데이터 수집**  
   - VoxPopuli(372Kh, 23개 유럽어), MLS(50Kh), CommonVoice(7Kh, 60개 언어), VoxLingua107(6.6Kh, 107개 언어), BABEL(1Kh).  
   - 총 436Kh, 128개 언어.  

2) **모델 구조**  
   - 기반: wav2vec 2.0의 CNN + Transformer  
   - 모델 변형: 0.3B, 1B, 2B 파라미터 버전  
   - 각 샘플 z_t를 Gumbel softmax로 양자화(100개의 distractor와 대조학습)  

3) **학습 목표**  
   - 대조 손실:  

$$ -\log \frac{\exp(\mathrm{sim}(c_t, q_t))}{\sum_{\tilde q \in Q_t}\exp(\mathrm{sim}(c_t, \tilde q))} $$  

   - 마스크된 시간-스텝 예측 및 코드북 다양성 페널티  

4) **언어·데이터 균형화**  
   - 언어별·코퍼스별 샘플링 확률 ∝ $$n_l^\alpha$$ (α=0.5)로 저자원 언어 업샘플링  

## 3. 성능 향상  
- **음성번역(X→En)**: prior SOTA 대비 평균 +7.4 BLEU 개선, 특히 중·저자원 언어에서 대폭 상승  
- **음성번역(En→X)**: 2B 모델이 monolingual 대비 동등 또는 우수한 성능 달성  
- **음성인식(ASR)**: BABEL, CommonVoice, VoxPopuli 등에서 WER 또는 PER 14–34% 상대 개선  
- **언어식별(LID)**: VoxLingua107에서 에러율 15% 상대 감소  
- **스피커식별(SID)**: VoxCeleb1에서 95.8% 정확도  

## 4. 모델의 한계  
- **모델 간섭(interference)**: LibriSpeech 10 h 세팅에서 monolingual 대비 소폭 열세  
- **컴퓨팅 자원**: 2B 모델 학습에 수백 GPU 요구, 실용성 제한  
- **도메인 편향**: 대규모 코퍼스가 일부 도메인(의회 연설 등)에 치중  

## 5. 일반화 성능 향상 가능성  
- **저자원 언어 전이**: 대규모 다국어 사전학습이 미미한 자원 언어에서도 강력한 성능 발휘  
- **모델 확장성**: 파라미터 수 증가가 대체로 성능 지속 개선  
- **비지도 데이터 활용**: 도메인 차이를 넘는 외부 코퍼스(VoxPopuli, 유튜브)도 일반화에 기여  

## 6. 향후 연구 및 고려 사항  
- **효율적 경량화**: 대규모 모델의 경량화·지식증류로 실제 응용 가능성 확대  
- **도메인 적응**: 다양한 환경(잡음, 방언)에서의 견고성 강화  
- **다중모달 확장**: 텍스트·이미지와 결합한 통합 표현 학습  
- **지속적 업데이트**: 신규 언어·코퍼스 추가 학습을 위한 온라인·연속 학습 전략  

XLS-R은 대규모 다국어 자기지도 음성 표현 학습의 새로운 기준을 제시하며, 저자원 언어 지원과 범용 음성 AI 구축에 중요한 토대를 마련했다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/684ba101-74b2-468e-8dce-8a3c9c6ea268/2111.09296v3.pdf)
