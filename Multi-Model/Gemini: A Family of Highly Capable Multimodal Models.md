# Gemini: A Family of Highly Capable Multimodal Models

**핵심 주장 및 주요 기여**  
Gemini는 이미지, 오디오, 비디오, 텍스트를 통합 학습해 강력한 범용 멀티모달 역량을 갖춘 Ultra·Pro·Nano 세 가지 크기의 모델 군이다. 이 가운데 Ultra 모델은 32개 벤치마크 중 30개에서 최첨단 성능을 달성하고, MMLU 시험에서 인간 전문가 수준(90.04%)을 최초로 돌파했다. 또한 20개 멀티모달 벤치마크 전부에서 최고 성능을 기록해, 다중 모달 간 추론과 언어 이해 능력을 획기적으로 발전시켰다.[1]

***

## 1. 해결하고자 하는 문제
기존 대형 언어 모델과 멀티모달 모델은 개별 모달리티에서 뛰어난 성능을 보였지만, 모든 모달리티를 동시에 강력하게 다루면서 범용 추론 능력까지 확보한 모델은 드물었다. Gemini는  
- 텍스트·이미지·오디오·비디오를 **조인트(pre-)학습**  
- 32K 토큰 초장문 처리  
- TPU 기반 대규모 분산 학습 인프라 활용  
를 통해, **모달별 최첨단 성능**과 **통합 멀티모달 추론 능력**을 동시에 달성하고자 한다.[1]

***

## 2. 제안 방법

### 2.1 모델 구조  
Gemini는 디코더형 Transformer를 기반으로, 32K 컨텍스트 길이를 지원하는 **멀티쿼리 어텐션**(multi-query attention) 및 효율적 어텐션 기법을 도입했다.  
- Ultra: 최고 성능(수십억~조 단위 파라미터)  
- Pro: 서비스 규모 최적화  
- Nano: 1.8B/3.25B 파라미터, 4비트 양자화한 온디바이스용  

모델 입력은 텍스트와 함께 이미지·비디오 프레임(시퀀스), 오디오(16kHz 피처)를 **토큰 단위로 인터리브** 처리하며, 출력 역시 텍스트·이미지 토큰을 융합 생성한다.[1]

### 2.2 학습 및 수식  
1) **사전학습(pre-training)**  
   - 웹·도서·코드 문서와 이미지·오디오·비디오 데이터를 대규모 혼합  
   - SentencePiece 토크나이저로 멀티언어·멀티모달 토큰화  
   - 토큰 수에 따른 학습 예산 최적화(모델 크기별 상이)  
2) **사후학습(post-training)**  
   - 지도학습(SFT), 보상모델(RM), RLHF 순차적 파이프라인  
   - 인간 평가 기반 페어별 선호도 $$r_\theta(x,y)$$ 학습 후  
   - PPO 등 RL 기법으로 성능·정확도·안전성 정합성 보강  
3) **불확실도 라우팅 체인오브쏘트(self-consistency)**  
   - $$k$$개 CoT 샘플 $$\{y_i\}_{i=1}^k$$ 생성  
   - 합의도(consensus) 임계치 $$\tau$$ 초과 시 다수결, 미만 시 최대우도 선택  

$$
     \hat y = 
     \begin{cases}
       \text{mode}(\{y_i\}), & \frac{\max_i \text{count}(y_i)}{k} > \tau,\\
       \arg\max_y P(y\mid x), & \text{otherwise.}
     \end{cases}
   $$

***

## 3. 성능 향상 및 한계

### 3.1 벤치마크 성능  
- **MMLU 시험**: 90.04%로 인간 전문가(89.8%) 초과 달성.[1]
- **멀티모달 추론**: MMMU 벤치마크에서 62.4%로 기존 최고보다 +5.0%p 향상.[1]
- **텍스트·이미지·비디오·오디오** 각 분야 최첨단 경신  
- **Nano** 모델도 온디바이스 환경에서 Pro 대비 Reasoning·Factuality 0.64~0.91 비율로 우수한 일반화 성능 보임.[1]

### 3.2 모델 일반화 및 한계  
- **컨텍스트 활용**: Ultra는 32K 토큰 문서에서 98% 정확히 키-값 검색.[1]
- **다중언어**: WMT23 번역에서 평균 BLEURT 74.4(1-shot).[1]
- **Hallucination·정확도**: 사후학습으로 비사실적 비율 6.7→3.8%, 출처표기(AIS) 40.2→60.0% 개선.[1]
- **한계**:  
  - 인과추론·반사실적 추론에는 여전히 취약  
  - 대규모 학습·메모리·추론 비용 부담  
  - 편향·유해정보 완전 제거 불가  

***

## 4. 일반화 성능 향상 요인

1. **모달 통합 학습**: 텍스트·이미지·오디오·비디오 혼합 사전학습으로 도메인간 지식 전이  
2. **초장문 컨텍스트**: 32K 길이 지원해 긴 문서·비디오·오디오 일관성 유지  
3. **사후학습 RLHF**: 다단계 피드백을 통한 목표 역량별 정합성 강화  
4. **Nano 경량화**: 증류·양자화로 작은 모델도 높은 일반화 성능 확보  

***

## 5. 향후 연구 영향 및 고려사항

- **융합 에이전트 개발**: AlphaCode 2 등 검색·툴 사용 결합한 복합 시스템 연구 가속  
- **데이터 분포 최적화**: 멀티모달·멀티언어 데이터 배합비 탐색  
- **신뢰성·검증 메커니즘**: Fact-checking·출처 생성 고도화  
- **효율화**: 모델 경량화·추론 최적화로 실시간·온디바이스 적용 확대  
- **윤리·안전**: 편향·유해정보·오용 방지 위한 평가·제어 기법 발전  

Gemini는 범용 멀티모달 AI 연구의 새로운 지평을 열었으며, 향후 에이전트·교육·의료·크리에이티브 분야 응용을 위한 기초가 될 것이다. 미래 연구에서는 데이터·평가·안전 측면의 보완을 통해 더욱 견고하고 신뢰할 수 있는 멀티모달 시스템 개발이 필요하다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/8ae0a616-4cf3-4df5-863e-c256407c2dc5/2312.11805v5.pdf)
