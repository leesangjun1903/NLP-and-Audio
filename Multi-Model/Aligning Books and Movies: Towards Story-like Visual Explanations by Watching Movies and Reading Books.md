# Aligning Books and Movies: Towards Story-like Visual Explanations by Watching Movies and Reading Books

**핵심 주장 및 주요 기여**  
“Aligning Books and Movies” 논문은 영화 장면(비주얼)과 책의 문장(텍스트)을 정교하게 정렬하여, 기존의 단순 캡션을 넘어선 스토리 기반의 시각적 설명을 자동으로 생성하는 프레임워크를 제안한다.  
1. 책과 영화 자막의 문장, 그리고 영화 샷(shot)을 대응시키는 새로운 **MovieBook Dataset**(11편 영화·책, 2,070개의 정밀 매핑)와 대규모 **BookCorpus**(11,038권, 74M 문장)를 구축했다.  
2. 연속 문장 예측 기반의 **Skip-Thought 벡터**로 문장 임베딩을 학습해 책 문장 간 의미 유사도를 효과적으로 측정한다.  
3. DVS(Descriptive Video Service) 기반 영상-텍스트 임베딩을 확장해 영화 클립과 문장 유사도를 계산한다.  
4. 문장·샷 간 9가지 유사도(시각 임베딩, 문장 임베딩, BLEU₁–₅, TF–IDF, 사전 확률)를 맥락 인식 CNN으로 융합해 지역적 일치도를 학습한다.  
5. 선형 순서를 보존하되 융통성 있는 정렬을 위한 **pairwise CRF**를 도입해 전역 일관성을 확보했다.

***

## 1. 문제 정의  
영화와 책은 서로 보완적 지식을 담고 있으나 서로 다른 매체이다. 영화 샷과 자막 문장, 책 문장을 정확히 매핑한다면 “책 기반 시각 설명”이 가능하다. 도전 과제는  
- 책 문장은 매우 길고 다양한 문체·번역체가 섞여 있음  
- 영화와 책의 대사 불일치, 시퀀스 차이  
- 방대한 샷(약 1,800)과 문장(약 7,750)  

***

## 2. 제안 방법  

### 2.1 Skip-Thought 문장 임베딩  
주변 문장(sᵢ₋₁, sᵢ, sᵢ₊₁)을 입력으로, sᵢ를 인코딩한 뒤 양옆 문장을 디코딩하여 얻은 표현을 사용.  
- 인코더·디코더는 GRU 기반 RNN  
- 목표:  

$$
\max_\theta \sum_i \Bigl(\sum_t\log P(w_t^{i+1}\mid w_{ < t}^{i+1},h_i)+\sum_t\log P(w_t^{i-1}\mid w_{ < t}^{i-1},h_i)\Bigr)
$$  

- 내적으로 문장 유사도 측정  

### 2.2 비디오–텍스트 임베딩  
- DVS 음성 설명과 클립 프레임 특징(GoogLeNet, Hybrid-CNN) 평균 풀링  
- LSTM으로 문장 인코딩, 선형 변환으로 영상 임베딩  
- 코사인 유사도 기반 순위 학습:  

$$
\min_\theta \sum_{(m,v)}\Bigl[\max(0,\alpha - s(m,v) + s(m,v^-)) + \max(0,\alpha - s(v,m) + s(v,m^-))\Bigr]
$$  

### 2.3 맥락 인식 CNN  
샷 i와 책 문장 j에 대해 9채널 유사도 텐서 S(i,j,m)을 계산한 뒤, 커널 (I×J×M) CNN으로 지역 융합:  
- 층별 ReLU, 드롭아웃  
- 교차 엔트로피로 학습  

### 2.4 전역 CRF 정렬  
샷 순서(timeₛ)와 문장 순서(time_b) 차이를 고려한 쌍별 잠재 변수 CRF:  

$$
E(y) = \sum_i \omega_u\,\phi_u(y_i) + \sum_{i,j\in N(i)} \omega_p\,\psi_p(y_i,y_j)
$$  

$$
\psi_p(y_i,y_j)=\frac{(ds(y_i,y_j)-db(y_i,y_j))^2}{(ds(y_i,y_j)-db(y_i,y_j))^2+\sigma^2}
$$  

- 체인 구조 DP로 정확 추론  
- 일부 상태 공간 가지치기  

***

## 3. 성능 향상 및 한계  

### 성능 향상  
- 맥락 인식 CNN 깊이를 1→3층으로 늘리면 리콜 +14%, AP 2배 상승  
- Skip-Thought 임베딩 추가 시 리콜 +4%  
- DVS 임베딩 추가 시 리콜 +2%  
- CRF로 전역 일관성 반영 시 +2%  

### 한계  
- 대사와 책 문장의 변형(의역·축약) 민감도  
- 비주얼 묘사가 책 내장 텍스트에 희미히 나타나는 경우 탐지 어려움  
- BLEU, TF–IDF 계산에 상당한 시간 소요  
- 제한적 언어(영어) 및 장르  

***

## 4. 모델 일반화 성능 향상 가능성  
- **대규모 다국어 BookCorpus**로 Skip-Thought 학습 확대 → 다양한 문체·언어에 robust  
- **비주얼 임베딩 강화**: 자막 외 오디오·음향 이벤트도 융합  
- **컨텍스트 윈도우 동적 크기** 학습: 장르별 최적 윈도우 적용  
- **Transformer 기반 문장 임베딩**로 대체 시 더 강력한 문맥 이해  
- **Semi-supervised CRF 학습**: 희소 라벨 보완  

***

## 5. 향후 연구의 영향 및 고려 사항  
이 논문은 **크로스모달 이야기 정렬** 연구에 기폭제가 되었으며, 후속 연구에서  
- 영화·드라마·게임 스크립트 자동 요약, 스토리 구조 인식  
- **책→영상 추천**, **영화→책 검색** 응용  
- 대화형 AI의 **스토리텔링 에디터**  
- 멀티모달 **서사 생성 모델**  

연구 시에는 **라벨링 비용**, **언어·문화 차이**, **저작권 이슈**를 충분히 고려해야 한다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/32b001b2-5582-45e6-a562-7802aca1de66/1506.06724v1.pdf)
