# SpQR: Near-Lossless LLM Weight Compression

## 1. 핵심 주장 및 주요 기여
SpQR는 **LLM 가중치를 3–4비트로 양자화하면서도 16비트 기준 성능 대비 1% 이내의 손실**을 달성하는 희소-양자화(hybrid sparse-quantized) 포맷이다.  
주요 기여:
- **민감도 기반 아웃라이어 분리**: 전체 가중치 중 약 1% 정도의 고감도(outlier) 가중치를 16비트로 저장하고, 나머지를 저비트로 양자화  
- **이중 레벨 양자화(bilevel quantization)**: 작은 그룹(β₁≈8–32) 단위로 3–4비트 양자화한 뒤, 이들 그룹 통계(스케일·제로점)를 또 다른 작은 그룹(β₂≈16) 단위로 양자화  
- **효율적 GPU 해독 알고리즘**: CSR 유사 희소 행렬 곱과 저비트 양자화 매트릭스 곱의 결합으로 16비트 대비 20–30% 속도 향상  

## 2. 문제 정의·제안 기법·모델 구조·성능·한계

### 문제 정의
- 기존 3–4비트 양자화는 작은 LLM(1–10B)에서 **퍼플렉시티 및 일반화 성능 저하**가 심함.  
- 고감도 가중치 소수(≈1%)가 양자화 오차를 지배하여 전체 성능 악화를 유발  

### 제안 기법
1. **감도 민감도(sᵢⱼ) 정의**  

$$s_{ij} = \min_{W'} \|W X - W' X\|^2 \quad\text{s.t. } w'\_{ij}=\mathrm{quant}(w_{ij}) $$  
   
   — (W’의 나머지 가중치를 연속값으로 최적 보정)  
2. **아웃라이어 검출**  
   - 각 β₁ 그룹 내에서 sᵢⱼ가 임계값 τ 이상인 가중치를 16비트로 분리  
3. **이중 레벨 양자화**  
   - 1차: β₁ 크기 그룹마다 3–4비트 양자화(스케일·제로점 포함)  
   - 2차: β₂ 크기 그룹 단위로 스케일·제로점을 다시 3비트로 양자화  
4. **CSR 유사 희소 표현**  
   - 분리된 아웃라이어는 각 행별로 (컬럼 인덱스, 16비트 값) 쌍으로 저장  

### 모델 구조 및 구현
- 기존 LLaMA·Falcon 모델의 각 선형층을 SpQR 포맷으로 변환  
- GPU inference 커널: shared memory에 1차·2차 통계와 비아웃라이어 가중치 로드→16비트 복원→매트릭스 곱  
- 아웃라이어는 별도 sparse matmul 단계에서 처리  

### 성능 향상
| 모델  | 평균 비트 | WikiText2 퍼플렉시티 | Zero-shot 정확도 평균 | 속도 (Tokens/s) |
|------:|---------:|-------------------:|---------------------:|---------------:|
| 7B(SpQR) | 4.63 bit | 5.73 (≤1% 손실)     | 61.46%             | 57 (fp16 대비 +21%)  |
| 13B(SpQR)| 4.63 bit | 5.13               | 65.05%             | 44 (+19%)       |
| Falcon-7B | 4.44 bit | 6.64               | 63.26%             | —               |

### 한계
- **생성 품질(GPT-4-level 평가) 미검증**: perplexity와 zero-shot 정확도만 측정  
- Sparse·Dense 연산 융합 미구현으로 속도 향상 여지  
- τ, β₁, β₂ 등 하이퍼파라미터 튜닝 필요  

## 3. 일반화 성능 향상 전망
- 아웃라이어 분리로 **양자화 에러 누적 억제**, 미세한 언어 패턴 포착 유지  
- 소규모 그룹 단위 통계 양자화가 **호환성 높은 범용 표현 학습**에 기여  
- Zero-shot·few-shot 태스크에서 16비트 성능 근접 유지로 **도메인 전이 안정성** 확보  

## 4. 향후 연구 영향 및 고려 사항
- **퍼포먼스-메모리 트레이드오프 연구**: 다양한 하드웨어(모바일 CPU·GPU)별 최적 β₁·β₂·τ 설정  
- **생성 품질 정량 평가**: human-rated 평가·문체 일관성 측정  
- **Sparse-Dense 연산 융합** 통해 추가 속도·에너지 효율 개선  
- **아웃라이어 구조 분석**: attention head별·레이어별 민감도 차이 기반 Adaptive quantization  
- **활성화 양자화 확장**: weight와 activation 동시 저비트화 연구  

> SpQR는 “중간 규모” LLM의 메모리 제약 해소와 성능 유지라는 두 마리 토끼를 잡으며, 경량화 연구의 새로운 패러다임을 제시한다. 앞으로 하드웨어 최적화 및 생성 품질 검증을 병행한다면, 모바일·엣지 AI 시대 실용적 대규모 LLM 배포의 핵심 기술이 될 것이다.

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/87957edd-afee-49b5-8be3-0287abd09bad/2306.03078v1.pdf
