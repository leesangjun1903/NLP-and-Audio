# Deduplicating Training Data Mitigates Privacy Risks in Language Models

## 1. 핵심 주장 및 주요 기여  
이 논문은 **웹 스크래핑 기반 대규모 언어모델(LLM) 학습 데이터에 존재하는 시퀀스 수준의 중복**이 모델 개인정보 유출 공격 성공의 주요 원인임을 밝히고,  
데이터를 시퀀스 단위로 **정확히 중복 제거(deduplication)** 함으로써 모델이 훈련 데이터를 재생성·누출하는 빈도를 최대 20배까지 낮출 수 있음을 보인다.  

## 2. 문제 정의, 제안 방법, 모델 구조, 성능 개선 및 한계  

### 2.1 해결하고자 하는 문제  
- LLM이 훈련 데이터에서 반복된 시퀀스를 과도하게 암기(memorization)하여,  
  공격자가 무작위 생성 샘플을 통해 훈련 데이터를 복원(model inversion)·식별(membership inference)할 수 있음.  

### 2.2 제안하는 방법  
1. **시퀀스 단위 중복 탐지**  
   - 텍스트 데이터에서 길이 N(기본 N = 100자)인 **문자 시퀀스**별로 정확히 일치하는 복제 횟수 $$d$$를 카운트.  
2. **중복 제거**  
   - suffix array 기반 알고리즘으로, 동일한 N-문자 시퀀스가 2회 이상 등장하는 항목 중 하나만 유지.  
3. **효과 측정**  
   - 언어모델로부터 총량이 원본 훈련 데이터와 동등한 분량의 텍스트를 생성하여,  
     - 생성된 시퀀스별 복제 횟수 $$d$$ 대비 재생성 횟수를 측정  
     - 멤버십 추론 정확도(AUROC, TPR@FPR=0.1%)를 $$d$$에 따라 평가  

#### 핵심 수식  
- **완전 암기 모델(perfect memorization)** 은 훈련 데이터에서 빈도 $$d$$인 시퀀스를 $$d$$번 생성할 것으로 기대.  
- 실제 LLM의 기대 생성 횟수 $$G(d)$$는 로그-로그 스케일상 기울기 $$>1$$인 초선형(superlinear) 관계:  

$$
    G(d) \propto d^{\alpha}, \quad \alpha > 1
  $$  

- 멤버십 점수는 기준 모델(perplexity baseline) 대비 훈련 모델 perplexity 비율을 사용.  

### 2.3 모델 구조  
- Transformer 기반 LM:  
  - Mistral 117M, 345M 파라미터 모델  
  - West et al. 1.5B 파라미터 모델  
  - C4 데이터셋 및 C4 deduped 버전(1.5B 모델)  

### 2.4 성능 향상  
- **재생성 감소**: deduped 모델은 훈련 데이터 400자 시퀀스 재생성이 원모델 대비 약 20× 감소(1,427,212 → 68,090건)  
- **멤버십 추론 약화**:  
  - zlib 및 Lowercase 점수 AUROC이 각각 0.76→0.67, 0.86→0.68로 저하  
  - Reference Model은 0.88→0.87로 비교적 유지  

### 2.5 한계  
- 비정확 중복(near-duplication)이나 의미 중복(semantic duplication)은 미처리  
- 드물게 생성된 중복 제거 후의 시퀀스는 여전히 탐지 가능  
- 일부 태스크(예: closed-book QA)에서는 암기된 지식 유실 우려  

## 3. 일반화 성능 향상 관점  
- **과도한 중복 학습 억제**를 통해 모델이 희귀(pareto tail)·중복 없는 시퀀스를 더 효과적으로 학습할 여지  
- 중복 데이터를 제거해 **용량 낭비**를 줄이면, 동일 자원으로 더 다양한 예제를 학습 가능  
- 실제로 Lee et al.(2021)에서 언급된 것처럼, deduplication 후 **언어모델 퍼플렉서티(perplexity)**에 악영향이 없음을 확인  

## 4. 향후 연구에 미치는 영향 및 고려사항  
- **공격 평가 기준 재설정**: 모델 inversion·membership inference 실험 시 훈련 데이터 중복도를 변수로 고려  
- **근사 중복(near-duplicate) 탐지** 기법 개발 필요: 단어 순서·정형화 변형까지 방어 확장  
- **DP(차분 프라이버시) 결합**: 중복 제거와 DP 학습을 함께 적용해, 중복 누적 효과 방어  
- **비텍스트 도메인**(이미지·코드) 중복-프라이버시 관계 분석으로 일반화  

Deduplication은 **사전 비용**(전처리)만으로도 LLM 개인정보 유출 위험을 크게 낮출 수 있는 **효과적이고 실용적인 방어책**임을 보여준다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/0da6f2b8-3d59-4044-bf68-bf4800680f25/2202.06539v3.pdf)
