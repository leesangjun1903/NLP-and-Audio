# Evaluating Large Language Models Trained on Code

**핵심 주장 및 기여**  
OpenAI가 발표한 본 논문은 자연어 처리뿐 아니라 프로그래밍 언어 코드 생성을 전문화한 대규모 언어 모델 *Codex*를 제안 및 평가한다. GitHub의 공개 Python 코드로 미세조정(fine-tuning)한 결과, 기존 GPT-3 대비 함수 합성 정확도가 획기적으로 향상되었으며, 단일 샘플로 28.8% 정답률, 100개 샘플로 77.5% 정답률을 달성했다. 이로써 프로그래밍 보조 도구로서의 실용 가능성을 증명하고, **생성 모델의 규모·데이터·추론 샘플링**이 코드 합성 성능에 미치는 효과를 체계적으로 분석한 점이 주요 기여이다.

***

## 1. 해결하고자 하는 문제  
전통적 언어 모델의 코드 생성은 일치 기반(match-based) 평가에 의존해 왔으나, 이는 기능적 정확성(functional correctness)을 제대로 반영하지 못한다.  
- **문제**: 자연어(docstring) 조건 하에 파이썬 함수 본문을 자동 생성할 때, 정확한 동작(단위 테스트 통과 여부)을 보장하는 모델 설계 및 평가 체계 부재  
- **목표**: 문서 문자열(docstring)만으로 완전한, 기능적으로 정확한 파이썬 함수를 생성하는 모델 개발 및 측정

***

## 2. 제안 방법  
1) **HumanEval 데이터셋**  
   164개의 손수 작성된 함수 생성 과제와 각 7.7개 단위 테스트를 포함.  
2) **Codex 모델 학습**  
   - 기반: GPT-3 12B 모델  
   - 미세조정: GitHub 공개 Python 코드 159 GB  
   - 토크나이저: GPT-3 토크나이저 기반 + 공백별도 토큰 추가(30% 토큰 절감)  
3) **기능적 정확성(pass@k) 평가**  
   - 정의: k개의 샘플 중 하나라도 테스트 통과 시 함수 해결  
   - Unbiased estimator:

```math
       \mathrm{pass}@k \;=\; 1 - \mathbb{E}\!\Big[\tfrac{\binom{n-c}{k}}{\binom{n}{k}}\Big],\quad c = \#\text{통과 샘플},\,n\ge k
```

4) **샘플 다중생성 & 선택 전략**  
   - 온도 최적화: k↑일수록 다양성 위해 $$T^*\approx0.8$$  
   - 히어스틱: 평균 로그확률 최대 샘플 선택  
5) **모델 개선**  
   - **Codex-S**: 독립 함수+단위 테스트 예시 10 000건으로 추가 감독학습  
   - **Codex-D**: 코드 → docstring 역생성 모델로 코드 품질 신호 활용

***

## 3. 모델 구조 및 학습  
- Transformer 기반, 최대 12B 파라미터  
- 학습 세팅: Adam 옵티마이저(β₁=0.9,β₂=0.95,ϵ=10⁻⁸), 100B 토큰 fine-tuning  
- 입력: `header + signature + docstring` → 출력: 함수 본문  
- 생략 시퀀스: `'\nclass'`, `'\ndef'` 등

***

## 4. 성능 향상 및 일반화  
| 모델           | pass@1    | pass@100  |
|---------------|----------|----------|
| GPT-3 (기준)   | ~0%      | ~0%      |
| Codex-12B     | 28.8%    | 72.3%    |
| Codex-S-12B   | 37.7%    | 77.5%    |

- **샘플링 증가 효과**: 1→100 샘플 시 28.8→72.3%  
- **Codex-S**: 비슷한 파라미터 대역 Codex 대비 +8.9%↑(pass@1), +5.2%↑(pass@100)  
- **일반화 개선 전략**:  
  - △ 실전 함수 분포 학습(경진대회·CI 기반)  
  - △ 샘플 다중화 및 로그확률 기반 순위  
  - △ 역생성(docstring)으로 추가 품질 신호

***

## 5. 모델 한계  
- **체이닝 복잡도 한계**: docstring에 연쇄 연산 블록이 늘어날수록 성능 지수함수 감소  
- **바인딩 오류**: 변수 바인딩·스코프 처리 오류 잦음  
- **BLEU의 한계**: 기능적 정확성과 상관없이 BLEU 높은 오답 다수  
- **샘플 비효율**: 수백 샘플 필요  
- **보안·편향위험**: 부적절 암호 설정 제안, 편향·유해 주석 생성 가능

***

## 6. 일반화 성능 향상 방안  
- **데이터 다양화**: 감독예제·단위 테스트 패턴 확대  
- **RLHF**: 인간 피드백 기반 정렬(alignment) 학습  
- **정형분석 검증**: 자동 정적분석·포멀 기법으로 버그·취약점 필터링  
- **샘플 선택 히어스틱 개선**: 역생성(back-translation)·정적 코드 분석 점수 조합

***

## 7. 향후 영향 및 고려사항  
- **연구영역**: 코드생성 일반화, 정렬 기술, 기능적 평가 지표(pass@k 확장)  
- **응용**: 프로그래밍 보조툴, 교육·인터뷰 준비, 자동테스트 생성  
- **유의점**  
  - _안정성_: 생성 코드 리뷰·테스트 필수  
  - _윤리편향_: 자동화된 주석·분류 기능 편향·차별 위험  
  - _보안_: 암호·라이브러리 제안의 안전성 검증 필요  
  - _경제효과_: 생산성 향상 vs. 업무대체 균형 연구

**결론**: Codex는 docstring 기반 함수 합성에서 기능적 정확성을 크게 개선하며 코드 생성 모델의 새로운 가능성을 제시했다. 다만 샘플 효율성·정렬(alignment)·보안·편향 이슈가 남아 있어, 향후 연구는 이들 전방위적 과제 해결에 초점을 맞추어야 할 것이다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/7b1dedd7-87b1-4d65-8615-16aed3ff5281/2107.03374v2.pdf)
