# InCoder: A Generative Model for Code Infilling and Synthesis

**핵심 주장 및 주요 기여**  
InCoder는 기존의 좌→우(left-to-right) 생성 모델과 마스킹(masked) 언어 모델의 장점을 결합한 **인과적(causal) 마스킹** 학습 목표를 도입하여, 코드를 좌측·우측 양쪽 컨텍스트에 따라 자유롭게 인필(infill)·수정할 수 있는 단일(decoder-only) 생성 모델을 제안한다. 주요 기여는 다음과 같다.  
- **통합적 생성 및 편집**: 하나의 모델로 함수 합성(program synthesis)과 코드 편집(code editing)을 모두 수행.  
- **인과적 마스킹 목표**: 문서 내 임의 위치(span)를 마스킹 → 해당 영역을 문서 말미로 이동 → 전체 시퀀스를 우→좌 순서로 학습.  
- **광범위한 제로샷 태스크**: 타입 추론, 주석 생성, 변수명 재지정, 다중 라인 인필 등 실용적 과제를 별도 미세조정 없이 제로샷으로 해결.  
- **성능 우위**: HumanEval infilling에서 pass @1 기준 69.0%로 좌→우 단독(48.2%) 및 좌→우 재랭킹(54.9%)을 크게 상회.  

***

## 1. 해결 문제  
- 전통적 좌→우 생성 모델은 코드 인필이 불가능하고, 마스킹 모델은 문서의 15% 정도만 생성 가능.  
- 실무에서는 버그 수정, 주석 추가, 변수명 변경 등 **양방향 문맥**에 기반한 편집 기능이 필요.  

***

## 2. 제안 방법  
### 2.1. 인과적 마스킹 목표(Causal Masking)  
문서 $$D$$에서 임의 구간 $$\text{Span}=D_{i:j}$$을 샘플링하여  
1) 해당 영역을 특수 토큰 $$\langle\text{Mask:0}\rangle$$으로 대체  
2) $$\text{Span}$$을 문장 끝으로 이동  
3) 위치 표시 토큰(앞·뒤) 및 EOM(end-of-mask) 삽입  
를 거쳐 다음 로그 우도(log-likelihood)를 최대화:  

$$
\log P([D_{0:i};\langle\text{Mask:0}\rangle;D_{j:N};\langle\text{Mask:0}\rangle;\text{Span};\langle\text{EOM}\rangle]).
$$  

이로써 **양방향 컨텍스트**를 조건으로 인필이 가능해진다.  

### 2.2. 추론(Inference)  
- **좌→우 생성**: 마스크 없이 일반 생성  
- **인필**: 문맥에 $$\langle\text{Mask}\rangle$$ 삽입 → 문장 끝에서 토큰 샘플링 → $$\langle\text{EOM}\rangle$$ 도달 시 종료  

***

## 3. 모델 구조  
- **Transformer decoder-only**  
- INCODER-6.7B: 32-layer, 4K embed, 16K FFN, 32 heads, 최대 컨텍스트 2048토큰  
- 학습 데이터: 159 GB 코드 + 57 GB StackOverflow, 28개 언어, 비저작권(permissive) 오픈소스  
- 토크나이저: 바이트 레벨 BPE, 공백 횡단 토큰 허용  

***

## 4. 성능 향상  
|태스크|좌→우 단독|좌→우 재랭킹|인과적 인필|  
|:---|:---:|:---:|:---:|  
|HumanEval 단일행 infill pass@1|48.2%|54.9%|**69.0%**|  
|다중행 infill pass@1|24.9%|28.2%|**38.6%**|  
|Docstring BLEU|16.05|17.14|**18.27**|  
|타입 예측 정확도|12.0%|12.4%|**58.1%**|  

- **컨텍스트 의존성**: 우측 문맥이 많을수록 인필 성능 개선 폭 증가  
- **포괄성**: 코드 생성 능력 저하 없이 인필 기능 획득  

***

## 5. 한계 및 일반화 성능  
- **컨텍스트 규모 제약**: 최대 2048토큰, 더 긴 문서는 분할 필요  
- **생성 편향**: 토큰길이 편향 보정(sentinel token) 보완 필요  
- **데이터 라이선스 편향**: 비저작권·공개 데이터 중심, 상업용 코드 일반화 미검증  

→ **일반화 향상**을 위해  
- 컨텍스트 윈도우 확장(LLaMA·PaLM-Coder 등)  
- 다양한 라이선스·도메인 코드 추가  
- 파인튜닝·데이터 증강  

***

## 6. 향후 연구에 미치는 영향 및 고려사항  
- **통합 코드 에디팅**: 코드 리뷰·자동 수리·AI 보조 편집 워크플로우 간소화  
- **파인튜닝 및 피드백 루프**: 설명문·테스트 기반 세부 제어  
- **반복적 디코딩**: 자체 생성물 재수정(iterative refinement)  
- **대규모 학습**: 모델 크기·데이터·컴퓨트 확장에 따른 성능상승 검증  

**→** InCoder는 코드 생성·편집을 하나의 프레임워크로 결합해, **양방향 컨텍스트 활용** 연구 및 실용적 코드 어시스턴트 개발의 새로운 지평을 열었다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/71ee2ecf-bac1-40af-9d20-97be07eea976/2204.05999v3.pdf)
