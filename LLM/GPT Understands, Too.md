# GPT Understands, Too

## 1. 핵심 주장 및 주요 기여  
**핵심 주장**  
프롬프트 기반 적응(prompting)에서 수동으로 설계된 이산(discrete) 프롬프트는 작은 단어 변경에도 성능이 크게 흔들리는 불안정성을 지니지만, 연속(continuous) 프롬프트 임베딩을 도입하면 안정성과 성능을 동시에 개선할 수 있다.  

**주요 기여**  
- 이산 프롬프트의 불안정성 문제를 정량적으로 입증  
- 연속 프롬프트 임베딩 P-Tuning 기법 제안  
- LAMA(지식 프로빙)와 SuperGLUE(NLU) 전 범위 실험에서 성능 및 안정성 획기적 향상  

## 2. 문제 정의 및 제안 방법  

### 2.1 문제: 이산 프롬프트의 불안정성  
- 예시: “ $$X$$ is located in $$Y$$.” 문장에서 일부 단어만 바꿔도 LAMA 정확도가 31.3→19.8로 급락  
- 수동 및 자동 검색된 이산 프롬프트 모두 이러한 변동성을 해소하지 못함  

### 2.2 제안 방법: P-Tuning  
연속 프롬프트 임베딩을 이산 토큰 사이에 삽입하고, 역전파로 학습 가능한 파라미터로 취급  
- **템플릿**  
  T = { [P₀…Pᵢ], x, [Pᵢ₊₁…Pⱼ], y, [Pⱼ₊₁…Pₖ] }  
- **임베딩 매핑**  
  f: [Pᵢ] → hᵢ ∈ ℝᵈ  
- **학습 대상**  
  {P₀,…,Pₖ}를 미분 가능하게 최적화하여 downstream 손실 최소화  

#### 모델 구조  
- 사전학습 언어모델(GPT, BERT 등) 입력층 앞단에 연속 프롬프트 임베딩 추가  
- LSTM 또는 MLP 기반의 *프롬프트 인코더* fθ로 연속 임베딩 간 의존성 모델링  

#### 수식  
- 입력 임베딩:  

$$E = \{h_0, \dots, h_i, e(x), h_{i+1}, \dots, e(y), \dots, h_k\}$$  

- 목적함수:  

$$\min_{\theta, P} \mathcal{L}\_{task}(M_{\theta}(E), y)$$  

### 2.3 성능 향상 및 한계  
- **지식 프로빙(LAMA-34k)**: BERT-base 정확도 31.1→48.3 (+17.2pp)  
- **NLU 전반(SuperGLUE)**: few-shot 및 fully-supervised 설정에서 PET 및 일반 fine-tuning 대비 평균 1~2pp 개선  
- **안정성**: 패턴별 정확도 표준편차 10.1→0.46으로 대폭 감소  
- **한계**:  
  - 고자원 태스크(MultiRC 등)에는 상대적 이득 적음  
  - 연속 토큰 개수 및 삽입 위치 탐색 비용 발생  

## 3. 일반화 성능 향상 관점  
- 연속 프롬프트는 이산 패턴의 편향 없이 모델 입력 공간에 학습 가능 파라미터를 추가함으로써  
  - 다양한 문장 구조에 대응하여 **분포 변화에 강인한 일반화 성능** 확보  
  - few-shot 환경에서도 불안정한 샘플 순서·패턴 민감도를 완화  

## 4. 향후 연구 시 고려점 및 영향  
- **영향**: prompting 패러다임을 *하이브리드 continuous–discrete*로 확장하여, 사전학습 모델 재활용성 및 안전성 제고  
- **고려점**:  
  - 연속 토큰 수·위치 탐색 자동화를 위한 효율적 검색 기법 연구  
  - 더 큰 언어모델 및 다양한 언어·도메인에 대한 일반화 가능성 검증  
  - 적은 자원으로도 적용할 수 있는 경량화 프롬프트 인코더 설계(runtime·memory 최적화)

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/6b09812e-16ee-4a27-beb2-8574c1eddbd0/2103.10385v2.pdf)
