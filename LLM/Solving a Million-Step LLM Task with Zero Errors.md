
# Solving a Million-Step LLM Task with Zero Errors

## 1. 핵심 주장과 주요 기여 요약

이 논문은 **대규모 언어 모델(LLM)이 백만 개 이상의 단계를 필요로 하는 작업을 완벽하게 해결할 수 있다**는 혁신적인 주장을 제시합니다. 핵심은 전통적인 "더 크고 더 똑똑한 LLM 개발"이라는 확장 경로 대신, **대규모 분해된 에이전트 프로세스(MDAPs: Massively Decomposed Agentic Processes)**라는 직교적 확장 방식을 제안하는 것입니다.[1]

주요 기여는 다음과 같습니다:[1]

- **MAKER 시스템 개발**: 극단적 분해(Maximal Agentic Decomposition), 첫-k-선행 투표(First-to-ahead-by-k Voting), 그리고 빨간 깃발(Red-flagging)의 세 가지 핵심 요소로 구성
- **이론적 확장 법칙 도출**: 작업 단계 수와 분해 수준에 따른 성공 확률과 비용 변화를 정량화
- **실증적 검증**: Towers of Hanoi 문제(20개 디스크 = 1,048,575단계)를 완벽하게 해결하여 오류 0의 달성 가능성을 입증

***

## 2. 문제 정의, 제안 방법, 성능 및 한계

### 2.1 해결하고자 하는 문제

LLM의 근본적인 문제는 **작업 길이가 증가함에 따라 성능이 급격히 악화된다**는 것입니다. 예를 들어, 1% 오류율을 가진 LLM 시스템은 이론적으로 100 단계 후 완전히 실패합니다:[1]

$$P(\text{all correct}) = (0.99)^{100} \approx 0.37$$

백만 단계 작업에서는 거의 불가능합니다:[1]

$$P(\text{all correct}) = (0.99)^{1,000,000} \approx 0$$

### 2.2 제안 방법: 세 가지 핵심 요소

#### (1) 극단적 분해(Maximal Agentic Decomposition, MAD)

작업을 가능한 한 가장 작은 단계로 분해합니다. m단계마다 하나의 에이전트를 할당하는 일반적인 경우, MAD에서는 m=1입니다:[1]

$$r_{i+1} \sim M(\phi(x_i))$$

$$a_{i+1} = \psi_a(r_{i+1})$$

$$x_{i+1} = \psi_x(r_{i+1}) \quad \forall i = 0, \ldots, s-1$$

여기서:
- M: 기본 LLM
- ϕ: 입력과 부작업 사양을 프롬프트로 매핑하는 템플릿 함수
- ψₐ: LLM 출력에서 행동을 파싱하는 추출기
- ψₓ: 다음 부작업의 입력에 포함할 정보를 파싱하는 추출기

#### (2) 첫-k-선행 투표 및 확장 법칙

모든 부작업에 대해 k개 이상의 투표 차이가 날 때까지 여러 에이전트가 독립적으로 샘플링합니다. 올바른 후보(확률 p)가 대안(확률 1-p)과 경쟁할 때, 올바른 후보가 선택될 확률은:[1]

$$P(a_i = a_i^*) = \frac{1}{1 + \left(\frac{1-p}{p}\right)^k}$$

전체 작업 성공 확률(m=1일 때):[1]

$$P_{\text{full}} = \left[1 + \left(\frac{1-p}{p}\right)^k\right]^{-s/m} = \left[1 + \left(\frac{1-p}{p}\right)^k\right]^{-s}$$

이를 통해 목표 성공 확률 t를 달성하기 위한 최소 k 값을 구할 수 있습니다:[1]

$$k_{\min} = \left\lceil \frac{\ln(t^{-1/s} - 1)}{\ln\left(\frac{1-p}{p}\right)} \right\rceil = \Theta(\ln s)$$

#### (3) 비용 분석 및 확장성

m단계 부작업에서 한 표본의 비용을 $c_{\text{sample}} = cm$이라 하면, 전체 작업 완료 예상 비용은:[1]

$$E[\text{cost}] = \frac{cs k_{\min}}{p^{m-1}(2p-1)} = \Theta(p^{-m}cs \ln s)$$

**극단적 분해(m=1)에서의 log-선형 확장:**[1]

$$E[\text{cost; } m=1] = \Theta(p^{-1}cs \ln s) = \Theta(s \ln s)$$

**중간 분해(m>1)에서의 지수적 비용 증가:**[1]

$$E[\text{cost; } m>1] = \Theta(p^{-m}cs \ln s)$$

이는 분해 수준이 기하급수적 비용 효율 악화를 초래함을 보여줍니다.

#### (4) 빨간 깃발(Red-flagging)

LLM 응답이 다음 신호를 보일 때 폐기하고 재샘플링합니다:[1]

- 과도하게 긴 응답 (700토큰 이상): 모델이 혼동되어 순환적 자기 파괴에 빠진 신호
- 잘못된 형식 지정: 이전 추론 과정에서 혼동된 신호

유효한 응답의 확률을 v라 하면:[1]

$$E[\text{cost with red-flagging}] \approx \frac{cs k_{\min}}{v(2p-1)} = \Theta\left(\frac{cs \ln s}{vp}\right)$$

빨간 깃발은 개별 오류율 감소뿐 아니라 **상관 오류 감소**에 특히 효과적입니다.[1]

### 2.3 모델 구조: MAKER 구현

MAKER는 세 가지 알고리즘으로 구성됩니다:[1]

**알고리즘 1 - generate_solution:**
```
입력: 초기 상태 x₀, LLM M, 투표 임계값 k
반복: s 단계 동안
  투표 수행(x, M, k)에서 행동 a와 다음 상태 x 획득
  행동을 리스트에 추가
출력: 행동 리스트
```

**알고리즘 2 - do_voting:**
```
입력: 상태 x, LLM M, 임계값 k
투표 카운트 V ← 0
반복:
  get_vote(x, M)에서 투표 y 획득
  V[y] = V[y] + 1
  if V[y] ≥ k + max(V의 다른 항목들):
    y 반환 및 종료
```

**알고리즘 3 - get_vote:**
```
반복:
  r ∼ (M ∘ ϕ)(x)에서 샘플링
  if r에 빨간 깃발 없음:
    ψₐ(r), ψₓ(r) 반환
```

### 2.4 성능 향상

Towers of Hanoi 20-디스크 작업(1,048,575단계)에서:[1]

| 모델 | 비용/Mtoken | 오류율(1-p) | kₘᵢₙ | 예상 비용 |
|------|-----------|---------|------|--------|
| gpt-4.1-mini (τ=0.1) | $1.6 | 0.0022 | 3 | $3.5K |
| gpt-oss-20B | $0.2 | 0.0358 | 6 | $1.7K |
| o3-mini | $4.4 | 0.0018 | 3 | $9.4K |
| gpt-4.1-nano | $0.4 | 0.3571 | 29 | $41.9K |

**결과:**[1]
- 0 오류로 백만 단계 완료 (gpt-4.1-mini 사용)
- 투표 라운드 수: 최소 3에서 최대 18 (단 1 이상 단계)
- 지수 감소: 샘플링 라운드마다 미결정 단계 수가 지수적으로 감소

### 2.5 한계

논문이 명시적으로 제시한 한계:[1]

1. **작업 분해의 전제 조건**: 충분히 작고 단순한 단계로 분해 가능해야 함
2. **높은 오류율 단계 문제**: 일부 단계에서 설명 불가능한 높은 오류율 발생 (예: 단계 10241에서 18 투표 필요)
3. **상관 오류**: 특정 입력에 대해 LLM이 비정상적으로 높은 오류율을 보임
4. **Insight vs. Execution 분리**: 논문은 execution에만 집중하고 insight(창의적 아이디어 생성) 처리는 미래 과제
5. **자동 분해 발견**: 최적 분해를 자동으로 찾는 방법은 미해결 문제

***

## 3. 모델의 일반화 성능 향상 가능성

### 3.1 이론적 근거

MAKER는 여러 이유에서 일반화 성능이 향상될 가능성이 높습니다:[1]

**작업 길이 독립성:** 실험에서 단계 오류율이 디스크 수(작업 복잡도)가 증가해도 안정적으로 유지되었습니다. 이는 매우 고무적인 신호입니다:[1]

$$p(\text{single step}) = \text{stable across different } s$$

**맥락 범위 효과 제거:** 극단적 분해를 통해 각 에이전트의 맥락 길이가 최소화되어, 맥락 길이 증가에 따른 성능 저하("길이 저주")를 회피합니다.[1]

**더 작은 모델 충분성:** 20개 디스크 작업에서 gpt-4.1-mini (추론 특화 모델 없음)가 o3-mini (추론 특화)보다 비용 효율적이었습니다. 이는 마이크로 단계를 할당하면 고급 추론 능력이 불필요함을 시사합니다.[1]

### 3.2 상관 오류 감소의 중요성

Figure 9b에 따르면, 빨간 깃발링을 통해 처음 두 표본이 모두 틀린 단계(collision)가 현저히 감소합니다. 이는 상관 오류의 구조적 제거가 가능함을 보여줍니다.[1]

### 3.3 에러 분산 추정의 중요성

$$E[\text{total cost}] = \Theta(p^{-1}cs \ln s)$$

여기서 p가 0.001에서 0.01로 개선되면 비용이 10배 감소합니다. 즉, **미세한 오류율 개선이 극도로 큰 확장 이득을 가져옵니다.**[1]

### 3.4 미세 지도 조정 가능성

각 단계가 매우 작고 명확하므로, 최소 데이터로도 단계별 특화 미세 지도 조정이 가능합니다:[1]

- 단계별 오류 프로필 측정 용이
- 문제 단계에 대한 표적 개선
- 특정 단계 유형별 별도 모델 할당 가능

### 3.5 다중 에이전트 다양성

미래 작업에서 단계별로 다른 LLM을 할당하면 오류 상관을 더욱 감소시켜, 효율성을 획기적으로 개선할 수 있습니다.[1]

***

## 4. 향후 연구의 영향과 고려 사항

### 4.1 현재 연구 환경에서의 전망

**최신 전문가 의견:**

현대 LLM 연구 커뮤니티에서 MAKER 패러다임이 주목받는 이유는:[1]

1. **안전성 측면**: 각 마이크로 에이전트의 영향 범위가 제한되어 다중 에이전트 공모를 통한 악의적 행동이 어려워짐
2. **경제성**: 규모 있는 작업에서 소형 모델로도 충분하여 운영 비용 절감
3. **감사 가능성**: 각 단계가 명확하고 추적 가능해 투명성 증대

### 4.2 아키텍처 진화 방향

이 논문은 **다음 세대 에이전트 아키텍처 설계 원칙**을 제시합니다:[1]

| 기존 단일 에이전트 | MDAP 다중 마이크로 에이전트 |
|-----------------|----------------------|
| 모놀리식 설계 | 모듈화된 설계 |
| 광범위한 맥락 | 제한된 미시적 맥락 |
| 단일 오류점 | 다중 독립적 검증점 |
| 단계적 성능 저하 | 안정적 단계별 성능 |

### 4.3 향후 연구 과제

**자동 분해 발견:** 최적 분해 수준을 자동으로 결정하는 메타 추론 알고리즘 개발이 필수[1]

**Insight와 Execution 통합:** 다양한 유형의 에이전트(분해 에이전트, 판별 에이전트, 솔루션 에이전트)를 재귀적으로 활용하는 계층적 구조 개발 (부록 F의 곱셈 실험이 초기 증거)[1]

**상관 오류 이론:** 특정 입력에 대한 체계적 오류 진단 및 완화 방법론 확립[1]

**컨텍스트 기반 다양화:** 프롬프트 패러프레이징, 노이즈 추가 등으로 동일 단계의 다중 샘플 간 오류 상관 감소[1]

**마이크로서비스 병렬:** 마이크로서비스 아키텍처의 교훈을 에이전트 시스템에 적용 (독립 개발, 실시간 모니터링, 실패 허용 설계)[1]

### 4.4 현저한 연구 동향

최근 발전된 논문들이 보여주는 방향:[1]

1. **프롬프트 동적화**: 같은 질문을 다르게 표현하여 상관 오류 감소
2. **의미 일관성 샘플링**: 정확도가 더 높은 샘플을 선호하는 semantic density 활용
3. **점진적 미세 조정**: 단계별 전문화된 소형 모델 개발

### 4.5 실무 적용 고려사항

**안전이 중요한 분야에서의 적용:**[1]
- 의료 결정 지원: 각 진단 단계별 독립 검증
- 법률 문서 처리: 조항별 미세 분석
- 금융 거래: 단계별 컴플라이언스 확인

**경제성 분석:**[1]
$$\text{총 비용} = s \times k_{\min} \times \text{평균 단계 비용}$$

대규모 작업에서도 $\Theta(s \ln s)$ 확장으로 인해 실현 가능한 경제성 달성

***

## 결론

"Solving a Million-Step LLM Task with Zero Errors"는 **확장 가능한 LLM 기반 에이전트 시스템 설계의 패러다임 전환**을 제시합니다. 극단적 분해, 다중 투표 메커니즘, 그리고 정교한 오류 감지의 조합을 통해, 개별 LLM의 능력 개선이 아닌 **시스템 아키텍처 혁신**으로 백만 단계 규모의 완벽한 작업 수행을 달성했습니다. 이는 향후 AI 안전성, 경제성, 감시 가능성을 모두 고려한 다음 세대 에이전트 설계의 청사진이 될 것입니다.[1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/35a07820-71db-4560-a092-0067bed621b2/2511.09030v1.pdf)
