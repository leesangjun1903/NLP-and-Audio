# DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence

## 1. 핵심 주장과 주요 기여

DeepSeek-Coder-V2는 GPT-4 Turbo, Claude 3 Opus, Gemini 1.5 Pro와 같은 최고 수준의 폐쇄형 모델과 대등한 성능을 보이는 **최초의 오픈소스 코드 언어 모델**입니다. 이 논문의 핵심 기여는 다음과 같습니다.[1]

**주요 기여**[1]

DeepSeek-V2 기반의 Mixture-of-Experts (MoE) 아키텍처를 활용하여 16B(2.4B 활성 파라미터)와 236B(21B 활성 파라미터) 두 가지 버전을 개발했습니다. 이는 효율적인 연산으로 다양한 응용을 지원합니다.

338개 프로그래밍 언어를 지원하고(기존 86개에서 확장), 컨텍스트 길이를 16K에서 128K 토큰으로 확장하여 복잡하고 광범위한 코딩 작업을 처리할 수 있습니다.[1]

100억 개 이상의 파라미터를 가진 오픈소스 코드 모델 개발을 최초로 시도했으며, HumanEval 90.2%, MBPP+ 76.2%, MATH 75.7% 등 벤치마크에서 최고 수준의 성능을 달성했습니다.[1]

허용적 라이선스로 공개하여 연구 및 무제한 상업적 사용을 가능하게 했습니다.[1]

## 2. 문제, 방법, 모델 구조, 성능 및 한계

### 2.1 해결하고자 하는 문제

기존 오픈소스 코드 모델(StarCoder, CodeLlama, DeepSeek-Coder 등)은 꾸준히 발전해왔지만, GPT-4 Turbo, Claude 3 Opus, Gemini 1.5 Pro와 같은 최고 수준의 폐쇄형 모델과 비교하면 여전히 성능 격차가 존재했습니다. 이 논문은 이러한 격차를 해소하고 오픈소스 코드 모델의 발전을 촉진하는 것을 목표로 합니다.[1]

### 2.2 제안하는 방법

#### 2.2.1 데이터 구성 및 수집

**Pre-training 데이터 구성**[1]

전체 10.2T 토큰으로 학습했으며, 다음과 같이 구성됩니다:
- **60% 소스 코드**: GitHub와 CommonCrawl에서 수집한 1,170B 코드 관련 토큰
- **10% 수학 코퍼스**: CommonCrawl에서 수집한 221B 수학 관련 토큰 
- **30% 자연어 코퍼스**: DeepSeek-V2 학습 코퍼스에서 샘플링

DeepSeek-V2의 중간 체크포인트(4.2T 토큰 학습)에서 시작하여 추가로 6T 토큰으로 continued pre-training을 수행했습니다.[1]

**데이터 품질 검증**[1]

1B 파라미터 모델로 ablation study를 수행한 결과, 새로운 코드 코퍼스가 기존보다 우수함을 확인했습니다:
- HumanEval: 30.5% → 37.2% (6.7% 향상)
- MBPP: 44.6% → 54.0% (9.4% 향상)

#### 2.2.2 학습 전략 및 하이퍼파라미터

**Training Objectives**[1]

- **DeepSeek-Coder-V2 16B**: Next-Token-Prediction + Fill-In-Middle (FIM)
- **DeepSeek-Coder-V2 236B**: Next-Token-Prediction만 사용

**FIM (Fill-In-Middle) 방식**[1]

PSM (Prefix, Suffix, Middle) 모드를 사용하며, 0.5의 FIM 비율로 학습합니다:

```math
\langle \text{fim\_begin} \rangle \ f_{\text{pre}} \ \langle \text{fim\_hole} \rangle \ f_{\text{suf}} \ \langle \text{fim\_end} \rangle \ f_{\text{middle}} \ \langle \text{eos\_token} \rangle
```

**최적화 설정**[1]

AdamW 옵티마이저를 사용하며 다음과 같이 설정합니다:
- $$\beta_1 = 0.9$$, $$\beta_2 = 0.95$$
- Weight decay = 0.1
- Cosine decay 스케줄: 2000 warm-up steps, 최종적으로 초기 학습률의 10%까지 감소

#### 2.2.3 Long Context Extension

**YARN 기법 적용**[1]

128K 컨텍스트 길이로 확장하기 위해 YARN을 사용하며, 하이퍼파라미터는 다음과 같습니다:
- Scale $$s = 40$$
- $$\alpha = 1$$
- $$\beta = 32$$

**2단계 학습**[1]

1. **Stage 1**: 시퀀스 길이 32K, 배치 크기 1152로 1000 스텝 학습
2. **Stage 2**: 시퀀스 길이 128K, 배치 크기 288로 추가 1000 스텝 학습

Needle In A Haystack (NIAH) 테스트 결과, 128K까지의 모든 컨텍스트 길이에서 우수한 성능을 보였습니다.[1]

#### 2.2.4 Alignment (정렬)

**Supervised Fine-Tuning (SFT)**[1]

- 20k 코드 관련 instruction 데이터 (DeepSeek-Coder에서)
- 30k 수학 관련 데이터 (DeepSeek-Math에서)
- 일반 instruction 데이터 (DeepSeek-V2에서)
- 총 300M 토큰으로 구성, 학습률 $$5 \times 10^{-6}$$, 배치 크기 1M 토큰, 총 1B 토큰 학습

**Reinforcement Learning (강화학습)**[1]

**GRPO (Group Relative Policy Optimization)** 알고리즘을 사용합니다. 이는 PPO와 달리 추가적인 critic 모델이 필요 없어 비용이 적습니다.

**보상 모델링**[1]

수학 preference 데이터는 정답 레이블을 사용하고, 코드 preference 데이터는 컴파일러 피드백과 테스트 케이스를 활용하여 보상 모델을 학습합니다. 실험 결과, 원시 컴파일러 신호보다 보상 모델 신호를 사용하는 것이 일반화 성능이 더 우수함을 확인했습니다.[1]

### 2.3 모델 구조

**MoE (Mixture-of-Experts) 아키텍처**[1]

DeepSeek-V2의 아키텍처를 따르며, 다음과 같은 특징을 가집니다:
- **16B 모델**: 총 16B 파라미터, 2.4B 활성 파라미터
- **236B 모델**: 총 236B 파라미터, 21B 활성 파라미터

**정규화 기법 수정**[1]

학습 중 불안정성과 gradient 스파이크 문제가 발생하여, exponential normalization 대신 **conventional normalization** 방법으로 전환했습니다.

### 2.4 성능 향상

#### 2.4.1 코드 생성 (Code Generation)

**HumanEval & MBPP 벤치마크**[1]

| 모델 | Python | Java | C++ | MBPP+ | 평균 |
|------|--------|------|-----|-------|------|
| GPT-4o-0513 | 91.0% | 80.4% | 87.0% | 73.5% | 76.4% |
| **DeepSeek-Coder-V2** | **90.2%** | **82.3%** | **84.8%** | **76.2%** | **75.3%** |
| Claude 3 Opus | 84.2% | 78.5% | 81.4% | 72.0% | 70.8% |
| Gemini 1.5 Pro | 83.5% | 81.0% | 78.3% | 74.6% | 68.9% |

DeepSeek-Coder-V2는 오픈소스 모델 중 최고 성능을 달성하며, GPT-4o에 근접한 성능을 보입니다.[1]

**경쟁 프로그래밍 (Competitive Programming)**[1]

LiveCodeBench에서 43.4% 달성(GPT-4o와 동률), USACO에서 12.1% 달성하여 오픈소스 모델 중 최고 성능을 기록했습니다.[1]

#### 2.4.2 수학적 추론 (Mathematical Reasoning)

**수학 벤치마크 성능**[1]

| 벤치마크 | DeepSeek-Coder-V2 | GPT-4o-0513 | GPT-4 Turbo |
|----------|-------------------|-------------|-------------|
| GSM8K | 94.9% | 95.8% | 93.7% |
| MATH | **75.7%** | 76.6% | 73.4% |
| AIME 2024 | **4/30** | 2/30 | 3/30 |
| Math Odyssey | 53.7% | 53.2% | 46.8% |

MATH 벤치마크에서 75.7% 정확도로 GPT-4o의 76.6%에 근접했으며, AIME 2024에서는 다른 모델들보다 많은 문제를 해결했습니다.[1]

#### 2.4.3 코드 수정 (Code Fixing)

**Bug-fixing 벤치마크**[1]

| 벤치마크 | DeepSeek-Coder-V2 | GPT-4o-0513 | Claude 3 Opus |
|----------|-------------------|-------------|---------------|
| Defects4J | 21.0% | 26.1% | 25.5% |
| SWE-Bench | **12.7%** | 26.7% | 11.7% |
| Aider | **73.7%** | 72.9% | 68.4% |

특히 Aider 벤치마크에서 73.7%로 모든 모델(오픈소스 및 폐쇄형 포함) 중 최고 성능을 달성했습니다. SWE-Bench에서 10% 이상을 달성한 최초의 오픈소스 모델입니다.[1]

#### 2.4.4 일반 자연어 능력

**자연어 벤치마크 성능 비교**[1]

DeepSeek-V2와 비교 시:
- **추론 벤치마크 (BBH, Arena-Hard)**: DeepSeek-Coder-V2가 더 우수
  - BBH: 83.9% vs 79.7%
  - Arena-Hard: 65.00 vs 41.60
- **지식 집약적 벤치마크 (TriviaQA)**: DeepSeek-V2가 약간 우수
  - 이는 pre-training 시 웹 데이터 양의 차이 때문

### 2.5 한계 및 향후 연구 방향

#### 2.5.1 주요 한계

**Instruction-Following 능력 격차**[1]

GPT-4 Turbo와 같은 최고 수준 모델과 비교하면 instruction-following 능력에서 여전히 상당한 격차가 존재합니다. 이는 SWE-Bench와 같은 복잡한 시나리오에서 낮은 성능으로 이어집니다.[1]

**지식 집약적 작업 성능**[1]

TriviaQA, NaturalQuestions와 같은 지식 집약적 벤치마크에서는 웹 데이터의 상대적으로 적은 양으로 인해 일반 언어 모델에 비해 성능이 다소 낮습니다.[1]

**활성 파라미터 제약**[1]

21B 활성 파라미터는 GPT-4o와 같은 대형 폐쇄형 모델에 비해 상대적으로 적어, 코드 이해 및 추론 작업(CRUXEval)에서 성능 격차가 발생합니다.[1]

#### 2.5.2 향후 연구 방향

**Instruction-Following 능력 강화**[1]

실세계의 복잡한 프로그래밍 시나리오를 더 잘 처리하기 위해 모델의 instruction-following 능력 개선에 집중할 계획입니다. 강력한 코딩 능력뿐만 아니라 뛰어난 instruction-following 능력이 필요합니다.[1]

**개발 생산성 향상**[1]

실제 복잡한 프로그래밍 시나리오를 처리하고 개발 프로세스의 생산성을 높이는 것에 초점을 맞출 예정입니다.[1]

## 3. 일반화 성능 향상 메커니즘

### 3.1 데이터 다양성 증대

**338개 프로그래밍 언어 지원**[1]

기존 86개에서 338개 언어로 확장하여 다양한 프로그래밍 패러다임과 구문에 대한 일반화 능력을 향상시켰습니다.

**다중 소스 코퍼스**[1]

- GitHub 소스 코드
- CommonCrawl 웹 페이지 (코드 및 수학 관련)
- 자연어 텍스트

이러한 다양한 소스의 조합은 모델이 다양한 컨텍스트에서 코드를 이해하고 생성할 수 있게 합니다.

### 3.2 보상 모델 기반 강화학습

**일반화 성능 우수성**[1]

원시 컴파일러 신호 대신 보상 모델을 사용한 강화학습이 더 강건하고 우수한 일반화 능력을 보였습니다. LeetCode와 LeetCode-zh 테스트 세트에서 보상 모델 신호를 사용한 경우가 컴파일러 신호를 직접 사용한 경우보다 명확히 우수한 성능을 보였습니다.[1]

**메커니즘**

보상 모델은 제한된 테스트 케이스로 인한 노이즈를 완화하고, 더 포괄적인 피드백을 제공하여 모델이 보지 못한 테스트 케이스에 대해서도 잘 일반화할 수 있게 합니다.[1]

### 3.3 Long Context 능력

**128K 컨텍스트 윈도우**[1]

YARN 기법을 통해 128K 토큰까지 확장된 컨텍스트는 복잡한 프로젝트 수준의 코드 작업을 처리할 수 있게 하며, NIAH 테스트에서 모든 컨텍스트 길이에서 우수한 성능을 보였습니다.[1]

### 3.4 효율적인 MoE 아키텍처

**적은 활성 파라미터로 높은 성능**[1]

236B 총 파라미터 중 21B만 활성화하는 MoE 구조는 효율적인 계산으로 다양한 작업에 전문화된 experts를 활용할 수 있게 하여, 일반화 성능을 유지하면서도 추론 속도를 향상시킵니다.

**DeepSeek-Coder-V2-Lite의 효율성**[1]

2.4B 활성 파라미터만으로도 33B 모델과 비슷하거나 우수한 성능을 보여, 효율적인 아키텍처가 일반화에 기여함을 입증합니다.

## 4. 연구에 미치는 영향 및 고려사항

### 4.1 오픈소스 코드 모델의 새로운 기준

**폐쇄형 모델과의 격차 해소**[1]

DeepSeek-Coder-V2는 오픈소스 모델이 GPT-4 Turbo, Claude 3 Opus, Gemini 1.5 Pro와 같은 최고 수준의 폐쇄형 모델과 대등한 성능을 달성할 수 있음을 최초로 입증했습니다. 이는 오픈소스 커뮤니티에 새로운 기준점을 제시합니다.

**허용적 라이선스**[1]

연구 및 무제한 상업적 사용이 가능한 라이선스는 산업계와 학계 모두에서 활발한 활용과 발전을 촉진할 것입니다.

### 4.2 효율적인 대규모 모델 학습 전략

**Continued Pre-training 효과성**

기존에 학습된 강력한 일반 언어 모델(DeepSeek-V2)을 기반으로 도메인 특화 데이터로 continued pre-training을 수행하는 전략의 효과성을 입증했습니다. 이는 처음부터 학습하는 것보다 효율적입니다.[1]

**다중 소스 데이터 큐레이션**

코드, 수학, 자연어를 적절한 비율(60:10:30)로 혼합하는 전략은 코딩 능력을 강화하면서도 일반 언어 능력을 유지하는 효과적인 방법임을 보여줍니다.[1]

### 4.3 향후 연구 시 고려사항

#### 4.3.1 Instruction-Following 능력 강화 필요

**복잡한 실세계 작업**

벤치마크 성능이 우수하더라도 실제 복잡한 시나리오(SWE-Bench 등)에서는 instruction-following 능력이 중요하므로, 이를 강화하는 연구가 필요합니다.[1]

#### 4.3.2 데이터 품질 및 다양성

**고품질 코드 데이터 수집**

fastText 기반 반복적 데이터 수집 파이프라인은 효과적이지만, 더 정교한 필터링과 품질 평가 기준이 필요할 수 있습니다.[1]

**프로그래밍 언어 균형**

338개 언어를 지원하지만, 각 언어별 데이터 분포와 품질의 균형을 맞추는 것이 중요합니다.

#### 4.3.3 효율성과 성능의 균형

**MoE 아키텍처 최적화**

활성 파라미터를 줄이면서도 성능을 유지하는 MoE 전략은 추가 연구가 필요한 영역입니다. 특히 experts의 전문화와 라우팅 메커니즘 개선이 중요합니다.

#### 4.3.4 평가 및 벤치마킹

**실세계 작업 평가**

표준 벤치마크 외에도 실제 소프트웨어 개발 시나리오에서의 평가가 중요합니다. SWE-Bench와 같은 실세계 지향 벤치마크의 개발과 활용이 필요합니다.[1]

**다국어 코드 생성**

다양한 프로그래밍 언어에 대한 균형잡힌 평가와 벤치마크 개발이 필요합니다.

#### 4.3.5 윤리 및 안전성

**코드 보안 및 취약점**

생성된 코드의 보안 취약점, 버그, 잠재적 위험성에 대한 평가와 완화 전략이 필요합니다.

**편향성 및 공정성**

학습 데이터의 편향이 생성된 코드에 미치는 영향에 대한 연구가 필요합니다.

### 4.4 미래 연구 방향

**멀티모달 코드 이해**

코드와 문서, 다이어그램, 시각 자료를 함께 이해하는 멀티모달 코드 모델 개발이 중요한 방향이 될 것입니다.

**실시간 협업 코딩**

개발자와 실시간으로 협업하며 더 나은 컨텍스트 이해와 제안을 제공하는 시스템 개발이 필요합니다.

**도메인 특화 최적화**

특정 도메인(예: 임베디드 시스템, 데이터 과학, 웹 개발)에 특화된 모델 개발도 유망한 방향입니다.

---

DeepSeek-Coder-V2는 오픈소스 코드 모델이 최고 수준의 폐쇄형 모델과 경쟁할 수 있음을 입증하며, 효율적인 MoE 아키텍처, 다양한 데이터 소스, 강화학습 기반 정렬을 통해 우수한 코딩 및 수학적 추론 능력을 달성했습니다. 그러나 instruction-following 능력과 복잡한 실세계 시나리오 처리에서는 여전히 개선의 여지가 있으며, 이는 향후 연구의 중요한 방향이 될 것입니다.[1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/9dd9c575-1027-486c-9209-2571b79d4ad2/2406.11931v1.pdf)
