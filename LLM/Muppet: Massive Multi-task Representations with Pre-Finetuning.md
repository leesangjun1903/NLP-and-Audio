# Muppet: Massive Multi-task Representations with Pre-Finetuning

## 핵심 주장 및 주요 기여  
**MUPPET**은 프리트레이닝과 파인튜닝 사이에 *프리파인튜닝(pre-finetuning)* 단계를 도입해, **대규모 멀티태스크 학습**을 통해 범용적인 언어 표현을 강화할 수 있음을 보인다.[1]
1. **프리파인튜닝** 단계: 약 50개 데이터셋, 480만여 레이블 샘플을 활용한 대규모 멀티태스크 학습  
2. **새로운 학습 스킴**: 손실 스케일링(loss scaling)과 태스크 이질적 배치(task-heterogeneous batches)를 결합해 안정성과 성능 향상  
3. **스케일의 중요성**: 15개 이상의 태스크가 넘는 임계점에서부터 성능이 선형적으로 증가  
4. **샘플 효율성**: 적은 파인튜닝 데이터에서도 우수한 성능을 달성  

## 1. 문제 정의  
- 기존 프리트레이닝 모델(BERT, RoBERTa, BART 등)은 **자기 지도 학습**만으로 학습되어, 다양한 다운스트림 태스크로 일반화하는 데 한계가 있음.  
- **중간 단계**에서 어떤 레이블드 태스크를 활용해야 최적 전이 학습이 될지 사전에 선택하기 어려움.  

## 2. 제안 방법  
### 2.1 프리파인튜닝(pre-finetuning)  
- 대규모 멀티태스크 학습: 총 46개 데이터셋(분류, 요약, MRC, 상식추론)  
- 전체 손실은 태스크별 “예측 수 $$n(i)$$ ” 기반으로 정적 스케일링:  

$$
L_{\text{scaled}}(x_i,y_i;\theta) = \frac{L_i(x_i,y_i;\theta)}{\log n(i)}
$$  

- **태스크 이질적 배치**: GPU마다 서로 다른 태스크의 배치를 샘플링하여 그래디언트 업데이트 시 다양한 태스크 기여도 균형  

### 2.2 모델 구조  
- 프리트레이닝된 RoBERTa/BART를 초기화  
- 태스크별로 구분된 헤드(head) 사용  
  - 분류(Classification): Cross Entropy  
  - 요약(Summarization): Label-smoothed CE  
  - MRC: Span Prediction  
  - Commonsense: Sentence Ranking  

### 2.3 학습 스킴  
1. **다중태스크 배치 구성**: 64 GPU에서 각기 다른 태스크 배치의 그래디언트를 집계  
2. **R3F/R4F 정규화**: 입력 공간 작은 교란에도 일관된 표현 유지  
3. **태스크 수 확장**: 10→40개의 단계적 확장 실험을 통해 ‘임계점’ 확인  

## 3. 성능 향상 및 분석  
| 모델                | RTE (정확도) | HellaSWAG (정확도) | 샘플 효율성 (파인튜닝 데이터 절감) |
|---------------------|-------------|--------------------|-----------------------------------|
| RoBERTa-Base        | 78.7%       | 65.1%              | –                                 |
| + MUPPET            | **87.8%**   | **69.0%**          | 10–30% 데이터로 동일 성능 달성    |
| RoBERTa-Large       | 88.1%       | 83.4%              | –                                 |
| + MUPPET            | **92.8%**   | **86.4%**          |                                   |
| BART                | 87.0%       | 84.1%              |                                   |
| + MUPPET            | **92.4%**   | **86.9%**          |                                   |

- **임계점 분석**: 15개 미만 태스크 시 MTL이 성능 저하, 15~25개 시점 이후 선형 증가.[1]
- **배치 전략**: 태스크 이질적 배치가 동질적 배치 대비 전반적 성능 우위 확보  

## 4. 모델의 일반화 성능 향상  
- **다양한 도메인**(GLUE, MRC, Commonsense QA, 요약)에서 일관된 이득  
- **저자원 환경**: 파인튜닝 데이터 비율을 10–100%로 줄여 실험해도, MUPPET 모델이 소량 데이터로도 높은 성능 유지  
- **도메인 외 태스크**(ANLI, Hyperpartisan, PubMed, Penn Treebank 등)에서도 베이스 모델 대비 평균 2–5%p 상승  

## 5. 한계 및 고려 사항  
- **학습 비용**: 64 GPU×최대 4일의 대규모 연산 자원 요구  
- **태스크 선정 바이어스**: 포함된 46개 데이터셋 구성에 따라 최적 임계점 및 성능 편향 발생 가능  
- **실시간 적용**: 산업 환경에서 자주 변경되는 태스크에 대해 재학습 부담  

## 6. 향후 연구 영향 및 고려 사항  
- 대규모 멀티태스크 **스케일 확장**이 모델 일반화에 결정적임을 입증하여, 이후 연구에서 **다양성**과 **스케일**에 대한 중요성을 강조  
- **효율적 자원 사용법** 연구: 프리파인튜닝 자원 비용 절감·동적 태스크 추가 전략 필요  
- **태스크 간 연관성 분석**: 선택적 태스크 조합이 일반화에 미치는 영향 이해  
- **배치·스케줄링** 최적화: 이질적 배치 외 새로운 균형 전략 탐색  

***

 2101.11038v1.pdf[1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/c7ea1402-35ab-4911-88ae-c2eca1e266a1/2101.11038v1.pdf)
