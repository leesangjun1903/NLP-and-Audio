# Training Verifiers to Solve Math Word Problems

**핵심 주장 및 주요 기여**  
이 논문은 대형 언어 모델이 다단계 수학 문제에서 자주 범하는 계산 실수와 일관성 결여 문제를 해결하기 위해,  
문제 해설 생성 후 별도 **검증기(verifier)** 를 학습하여 최종 답안을 선별하는 방식을 제안한다.  
주요 기여는 다음과 같다:[1]
- **GSM8K 데이터셋 공개**: 8,500개의 고품질 초·중등 수학 문제와 자연어 해설로 구성된 벤치마크 제공  
- **검증기(Verifier) 학습 기법**: 생성된 여러 후보 답안 중 올바른 해설을 선택하는 랭킹 모델 도입  
- **스케일링 효율성**: 동일 모델 크기 대비, 30배 큰 모델이 얻는 성능 향상과 동등하거나 더 우수한 결과 달성  
- **드롭아웃 활용**: 잔차 경로에 드롭아웃을 적용하여 과적합 억제 및 일반화 성능 강화  

***

## 1. 해결하려는 문제  
대형 언어 모델은 다음과 같은 한계를 가진다:[1]
1. **계산 오류**: 연쇄 계산 과정에서 작은 실수가 누적되어 최종 답이 틀리는 경우 다수  
2. **자기 교정 부재**: 생성 과정 중 잘못된 경로로 이탈 시 복구 불가능  
3. **스케일링 한계**: 단순히 모델 및 데이터 규모를 늘려도 효율적인 성능 향상이 어려움  

이로 인해 **GSM8K** 수준의 초·중등 수학 문제(2~8단계 연산)에서도 175B 파라미터 모델이 80% 해결율에 도달하기 위해서는 상상할 수 없는 규모의 확장이 필요하다.

***

## 2. 제안 방법  
### 2.1. 모델 구조  
- **생성기(Generator)**: GPT-3 계열 모델(6B, 175B)  
- **검증기(Verifier)**: 동일 구조의 언어 모델 + 최종 토큰 정답 여부 예측 헤드  
- 토큰별(value function)로 예측하거나 해설 전체 후 예측하는 두 가지 방식을 비교  
- 언어 모델링 손실 $$L_{\mathrm{LM}}$$과 검증 손실 $$L_{\mathrm{ver}}$$의 **합**으로 공동 학습  

### 2.2. 학습 절차  
1. 생성기 2 epoch 미세조정  
2. 각 훈련 문제에 대해 $$N=100$$개의 해설 후보 샘플링  
3. 후보별 최종 답 정오(label)로 검증 데이터 구축  
4. 검증기 1 epoch 학습 (언어 모델링 + MSE 기반 검증 손실)  

### 2.3. 수식  
- 생성 손실:  

$$
L_{\mathrm{LM}} = -\sum_{t=1}^T \log p_{\theta}(x_t \mid x_{ < t})
$$

- 검증 손실 (MSE):  

$$
L_{\mathrm{ver}} = \frac{1}{NM}\sum_{i=1}^N\sum_{j=1}^M \bigl(v_{ij} - y_{ij}\bigr)^2
$$  
  
  - $$v_{ij}$$: 후보 $$i$$ 해설의 $$j$$번째 토큰 예측값  
  - $$y_{ij}\in\{0,1\}$$: 정답 여부 라벨  

테스트 시, $$N$$개의 후보를 검증기가 점수 매긴 뒤 **최고 점수 해설** 또는 상위 $$k$$개 다수결 투표 방식으로 최종 답 도출.[1]

***

## 3. 성능 향상 및 한계  
### 3.1. 성능 비교  
| 모델 크기 | 방법        | 훈련 데이터  | 테스트 해결율(%) |
|----------:|------------|-------------|-----------------|
| 6B        | Finetuning | 7.5K 문제   | 20.6            |
| 6B        | Verification (100↑샘플) | 7.5K 문제 | 41.3            |
| 175B      | Finetuning | 7.5K 문제   | 34.1            |
| 175B      | Verification (100↑샘플) | 7.5K 문제 | 44.6            |

- 6B 검증기는 175B 단일 샘플 성능을 넘어섬  
- 검증 방식은 데이터 규모 증가에 더욱 효율적으로 스케일링[1]

### 3.2. 일반화 성능  
- **Token-level 값 함수** 학습이 solution-level 대비 과적합 덜하고 후기 epoch에서도 성능 상승  
- **드롭아웃(0.2)** 적용 시, 모든 방법에서 과적합 억제 및 2~5%p 추가 성능 향상 관찰[1]

### 3.3. 한계  
- 계산 오류 및 논리적 오류가 혼합될 때(변수 바인딩 등) 검증기가 오도될 수 있음  
- 샘플 수 과다 시(>400) 오히려 검증기 속이는 적대적 해설 발견 확률 증가  
- 구조상 해설 자체가 왜 틀렸는지 심층 진단 기능 부재  

***

## 4. 향후 연구에 대한 영향 및 고려 사항  
- **스케일링 대체 전략**: 모델 크기 확장이 아닌 생성·검증 분리 접근의 유효성 입증  
- **검증기 정교화**: 변수 바인딩, 단위 일관성 등 논리 검사 모듈 통합 연구  
- **다양한 문제 분포**: 고등수학, 논리 퍼즐 등 난이도·도메인 확장 가능성 탐색  
- **적대적 해설 대응**: 검증기 내 adversarial training 기법 적용 여부  

이 논문은 *검증 기반 생성(verifier-augmented generation)* 패러다임을 제시하며, 수학적 추론 뿐 아니라 일반적 다단계 추론 과제에서도 **일반화 효율**을 극대화하는 새로운 연구 방향을 제시한다.[1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/6f91a41c-c807-489f-8dfd-7847b4a3e65b/2110.14168v2.pdf)
