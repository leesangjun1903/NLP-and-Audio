# A Survey on In-Context Learning

**핵심 주장**  
대규모 언어 모델(LLM)은 사전 학습된 파라미터를 고정한 채, 소수의 예시(데모)를 컨텍스트로 제공받아 새로운 태스크를 수행할 수 있는 *In-Context Learning*(ICL) 능력을 보인다. 이 논문은 ICL의 정의부터 발전 과정, 주요 기법, 응용 분야, 한계를 체계적으로 정리하여 분야 전반의 로드맵을 제시한다.[1]

**주요 기여**  
1. ICL의 **정의 및 수식화**  
   - 입력 쿼리 $$x$$와 후보 답집합 $$Y=\{y_j\}$$, 시연 세트 $$C=\{I, s(x_i,y_i)\}$$가 주어질 때,  

$$
       \hat y = \arg\max_{y_j\in Y} f_M(y_j,\,C,\,x),
     $$  
     
  으로 예측을 수행하는 프롬프트 기반 학습 패러다임을 제시.[1]
2. **사전학습(Pretraining)과 워밍업(Warmup)** 전략  
   - 사전학습 단계에서 데모 유사 컨텍스트 병합(meta-distillation 등)을 도입하여 ICL 능력 향상.[1]
   - 워밍업 단계로서, FLAN, OPT-IML 등 광범위한 태스크 지침 튜닝을 통해 파라미터 조정 후 ICL 성능을 추가 개선.[1]
3. **프롬프트 설계**  
   - **데모 조직화**: 유사도 기반 선택(kNN), 출력 확률 기반 정렬(votek, PPL), 지도학습 기반 선택(EPR, AdaICL)과 순서 민감도 완화 기법(GlobalE&LocalE, ICCL) 분석.[1]
   - **지침 형식화**: Chain-of-Thought, 자동 지침 생성(Self-Instruct, Instruction Induction)으로 복잡 추론 지원.[1]
4. **성능 분석과 메커니즘 탐구**  
   - ICL 성능에 영향을 주는 사전학습 데이터 다양성, 모델 크기·아키텍처, 데모 예시 특성(다양성·유사도·순서) 규명.[1]
   - ICL을 **베이지안 추론** 또는 **그래디언트 디센트 유사성** 관점에서 해석하는 이론적 연구 정리.[1]
5. **응용과 한계**  
   - 데이터 엔지니어링, 모델 보강, 지식 업데이트 외에 비전·멀티모달·음성 분야에서의 ICL 확장 사례 제시.[1]
   - 계산 효율성·확장성 문제 및 장기 컨텍스트 ICL의 성능 저하 한계 지적.[1]

# 문제 해결 목표 및 제안 기법 상세 설명

## 1. 해결하고자 하는 문제  
- **파라미터 업데이트 없이** 새로운 태스크에서 소수 샘플만으로 적응하는 범용 학습 패러다임 필요  
- 데모 수와 컨텍스트 길이 증가에 따른 **효율성·확장성 한계**  
- 데모 구성(선택·형식·순서)에 따른 **성능 민감도**  

## 2. 제안하는 방법  
### 2.1 정식 정의  
- 시연 세트 $$C=\{I,\,s(x_i,y_i)\}_{i=1}^k$$와 쿼리 $$x$$를 연결해 확률 점수 $$f_M(y_j,C,x)$$로 예측  
- $$\hat y=\arg\max_{y_j} f_M(y_j\mid C,x)$$  

### 2.2 모델 훈련 전략  
- **사전학습**:  
  - PICL, MEND: 관련 예시 묶음 학습으로 시연 간 연관성 강화  
  - 메타 증류(meta-distillation)로 데모 벡터 학습, ICL 효율 제고  
- **워밍업**:  
  - FLAN, OPT-IML: 1000+ 태스크 지침 튜닝으로 지침 준수 및 Few-Shot 성능 향상  
  - Symbol Tuning: 레이블을 기호화하여 입력-출력 맵핑 학습 강화  

### 2.3 데모 설계  
|구분|방법|핵심 기법|모델 예시|  
|---|---|---|---|  
|선택|비지도|kNN, PPL, MI|GPT-3, GPT-J|  
|선택|지도|EPR, UDR, AdaICL|GPT-3.5, GPT-Neo|  
|형식화|리포매팅|AutoICL, ICV|GPT-3.5-Turbo|  
|순서|정렬|GlobalE&LocalE, ICCL|LLaMA2|  

### 2.4 점수 함수  
- **Direct**: $$P(y_j\mid C,x)$$ 토큰 종단 제약  
- **PPL**: 전체 문장 Perplexity 기반, 템플릿 자유도↑  
- **Channel**: $$P(x\mid C,y_j)$$ 역방향 확률로 불균형 데이터 보정  

## 3. 모델 구조 요약  
- Transformer 기반 LLM(예: GPT, LLaMA, Qwen)  
- 사전학습→워밍업→ICL 추론의 **3단계 파이프라인**  
- 추론 시 데모 컨텍스트를 **Prompt**로 직접 결합  

## 4. 성능 향상  
- 워밍업 튜닝 후 ICL 정확도 5–15%p 향상(모델·태스크별 차등)[1]
- 지도·비지도 데모 선택 기법으로 최대 10%p 추가 개선  
- Chain-of-Thought 활용 시 복잡 추론 태스크에서 20%p 이상 상승  

## 5. 한계  
- **효율성**: 데모 수 증가에 따라 추론 지연(플러스 메모리)  
- **확장성**: 컨텍스트 길이 제약으로 적은 데모만 사용 가능  
- **민감도**: 무작위 순서·형식 변경에 취약  
- **장기 컨텍스트**: 데모 수가 늘어날수록 일관성 오히려 감소  

# 모델 일반화 성능 향상 가능성

- **사전학습 데이터 다양성**이 임의 태스크에서 일반화된 ICL 능력 발현을 유도하며, 도메인·태스크 수 종류가 확장될수록 초도 Few-Shot 성능 상향.[1]
- **지도형 데모 선택**을 통해 저자원 언어·드문 태스크에서도 유사 고자원 태스크 예시 활용으로 일반화 가능  
- **지침 튜닝**(Instruction Tuning) 단계에서 다양한 포맷·지시어를 학습함으로써, 공유된 지시어 해석 능력을 신규 태스크로 전이  
- **이론적 해석**: ICL을 암묵적 베이지안·그래디언트 디센트 과정으로 보면, 기존 학습 이론의 일반화 보장(bound) 기법을 응용 가능  

# 향후 연구 영향 및 고려 사항

- **효율성·확장성 연구**: 데모 요약(distillation), 메모리 경량화, sparse·지연 로딩 기법 적용  
- **장기 컨텍스트 ICL**: 수백∼수천 예시 처리 시 성능 저하 원인 규명 및 보완 전략 필요  
- **저자원·크로스도메인 일반화**: 고자원 예시와 저자원 태스크 간 전이 학습 메커니즘 연구  
- **안정성·민감도**: 데모 순서·형식 변화에 강건한 스코어 함수·정규화 기법 개발  
- **Multi-Modal ICL**: NLP 외 비전·음성 데이터 형식 맞춤 프롬프트 및 아키텍처 최적화  

–––

 A Survey on In-context Learning, Qingxiu Dong et al. (arXiv:2301.00234v6)[1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/69aed0c4-1b31-492a-a1c9-a32cdcf78e5f/2301.00234v6.pdf)
