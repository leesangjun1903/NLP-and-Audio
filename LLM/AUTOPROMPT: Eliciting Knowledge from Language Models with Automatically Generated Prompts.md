# AUTOPROMPT: Eliciting Knowledge from Language Models with Automatically Generated Prompts

## 1. 핵심 주장 및 주요 기여  
**AUTOPROMPT**는 사전학습된 마스크 언어 모델(MLM)에 최적화된 프롬프트를 **자동으로 생성**함으로써, 별도의 파인튜닝 없이도 모델이 이미 학습한 지식을 효과적으로 **탐색(probe)**하고 **활용**할 수 있음을 보여준다.  
- 수동 설계 프롬프트 대비 높은 분류·검색 성능  
- 다양한 NLP 과제(감성분석, 자연어추론, 사실 검색, 관계 추출)에 일관되게 적용 가능  
- 저자원(소량 데이터) 환경에서 파인튜닝 대비 안정적이고 경쟁력 있는 성능  

## 2. 해결하고자 하는 문제  
기존 프롬프트 기반 prob­ing 기법은  
1) **수작업 문맥 작성의 어려움**  
2) 작은 표현 차이가 성능에 큰 영향을 미치는 **민감도**  
3) 특정 과제에만 제한적으로 적용  
과 같은 한계를 갖는다.  

## 3. 제안 방법  
### 3.1 프롬프트 구성  
- 입력 문장 $$x_{\text{inp}}$$과 고정 개수의 **트리거 토큰** $$\{t_j\}$$을 템플릿 $$\lambda$$로 결합  
- 모델이 예측할 위치에 [MASK] 토큰 $$[P]$$ 삽입  

### 3.2 그래디언트 기반 트리거 검색  
매 반복마다 트리거 토큰 $$x^{(j)}_{\text{trig}}$$의 입력 임베딩에 대한 로그우도 기울기를 계산하여,  

```math
x^{(j)}_{\text{trig}} \leftarrow \arg\max_{w \in V_{\text{cand}}} \nabla_{x^{(j)}_{\text{trig}}} \log p(y \mid x_{\text{prompt}})
```

후보 토큰 $$V_{\text{cand}}$$를 k개 선정해 실제 우도를 평가하는 과정을 **그리디 서치**로 반복 수행.  

### 3.3 자동 레이블 토큰 선택  
클래스 레이블 $$y$$에 대응하는 토큰 집합 $$V_y$$를  
1) [MASK] 위치의 Transformer 은닉값 $$h$$로 로지스틱 회귀 학습  
2) 출력 임베딩 $$w_{\text{out}}$$와 회귀 가중치 간 점곱으로 점수 산출  

$$
s(y,w) \propto \exp\bigl(w_{\text{out}}\! \cdot y + \beta_y\bigr)
$$

3) 상위 k개 토큰을 $$V_y$$로 채택  

## 4. 모델 구조  
- 기반 모델: BERTBASE, RoBERTaLARGE  
- 추가 파라미터: 트리거 토큰 임베딩(학습), 로지스틱 회귀 가중치  
- 프롬프트 생성만 수행하며, 모델 파라미터 고정  

## 5. 성능 향상  
| 과제             | AUTOPROMPT vs. 파인튜닝 / 수동 프롬프트 성능 |
|------------------|---------------------------------------------|
| 감성분석 (SST-2) | RoBERTa 91.4% (수동 85.2%, 파인튜닝 96.7%)     |
| 자연어추론 (SICK-E, 2-way) | RoBERTa 95.6% (파인튜닝 95.6%)        |
| 사실 검색 (LAMA) | P@1 43.3% (수동 31.1%, LPAQA 34.1%)           |
| 관계 추출        | BERT P@1 90.7% (기존 RE 57.9%)               |

- **저자원 환경**: 10~1000개 샘플에서 프롬프트 방식이 파인튜닝 대비 *더 안정적*이며, 특히 NLI에서 소량 데이터 시 더 우수  
- **거대 모델 대비 토큰 수**: 파인튜닝 체크포인트 대신 소량의 트리거 토큰만 저장  

## 6. 한계  
- **레이블 데이터 필요**: 프롬프트 검색에 학습 데이터 요구  
- **해석 가능성 저하**: 수작업 대비 생성된 프롬프트의 문법·의미 해석 어려움  
- **불균형 학습 데이터**: 다수 클래스 편향 발생 가능  
- **탐욕적 서치**: 전역 최적보장 어렵고 서치 안정성 이슈  

## 7. 일반화 성능 향상 가능성  
AUTOPROMPT의 **프롬프트 최적화**는 모델 아키텍처나 파라미터 수정 없이 다양한 도메인과 과제에 빠르게 **적응**할 수 있음을 시사한다. 특히:  
- *Few-shot* 학습에서 **안정성**과 **견고성** 제공  
- 대형 사전학습 모델을 **공유**하면서도 과제별 특화된 입력만 추가로 설계  
- **도메인 이관** 시 최소한의 라벨 위험부담과 비용으로 일반화 가능  

## 8. 향후 연구 및 고려 사항  
- **효율적 탐색**: 트리거 서치 공간 축소 혹은 메타러닝 기반 가속화  
- **인터프리터블 프롬프트**: 해석가능성 강화 기법 연구  
- **데이터 불균형 대응**: 프롬프트 학습 시 클래스 균형 보장 전략  
- **다양한 모델·언어 적용**: 자율 언어 및 비영어권 모델 일반화 실험  
- **조합적 기법**: 파인튜닝·프롬프트 혼합형 프로빙 혹은 적응 기법 설계  

AUTOPROMPT는 프롬프트 기반 프로빙 및 실무 활용을 위한 **새로운 패러다임**을 제시하며, 입력 설계 자동화가 NLP 모델 일반화 성능을 **비약적으로** 끌어올릴 수 있음을 보여준다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/337021cb-5cf2-4f1c-a960-8f408d142f69/2010.15980v2.pdf)
