# Is GPT-3 a Good Data Annotator?

**Is GPT-3 a Good Data Annotator?** 논문은 GPT-3를 활용한 자동 데이터 라벨링의 타당성과 효용성을 검증합니다. 세 가지 접근법을 제안 및 비교하며, 소규모 예시(샷) 기반의 프롬프트 가이드 라벨링(PGDA), 데이터 생성(PGDG), 외부 지식베이스 보조 생성(DADG)을 통해 생성된 데이터로 BERTBASE 모델을 학습한 뒤, 손수 레이블링된 데이터와 성능·비용·시간 측면을 평가합니다.  
주요 기여:  
- GPT-3 기반 라벨링·생성 전략 세 가지 비교 분석  
- 소·중·대형 라벨 스페이스 과제(감정분석, 관계추출, NER, ASTE)에 대한 실험  
- 비용·시간 절감 효과 및 모델 성능 손실 최소화 성과 제시  

***

# 문제 정의 및 제안 방법

## 해결하고자 하는 문제  
현대 AI는 대량의 라벨된 데이터에 의존하지만, 소규모 연구실·기업은 어노테이션 비용·시간 부담이 큼. GPT-3를 자동 데이터 애노테이터로 활용하여 이 장벽을 낮추고자 함.

## 세 가지 접근법  

1. Prompt-Guided Unlabeled Data Annotation (PGDA)  
   - 소수의 인간 라벨 예시(ℓIOP)를 포함한 프롬프트로 GPT-3에 미라벨 데이터의 토큰·시퀀스에 직접 레이블 예측을 요청.  
   - $$y_i = \mathrm{GPT\text{-}3}(\ell\mathrm{IOP}, x_i)$$  

2. Prompt-Guided Training Data Generation (PGDG)  
   - GPT-3에 라벨 정의 없이도 대상(label)→스팬(span)→문장으로 이어지는 데이터 생성 유도.  
   - 예: 관계추출 시 ①관계별 엔티티 쌍 생성 ②해당 쌍을 포함한 문장 생성  

3. Dictionary-Assisted Training Data Generation (DADG)  
   - Wikidata 등 지식베이스에서 관계·엔티티 사전 확보 후 PGDG 방식으로 문장 생성.  
   - 외부 도메인 지식 활용 가능  

### 모델 구조  
- 학습한 데이터로 BERTBASE fine-tuning  
- 평가 데이터는 인간 라벨링된 SST2, FewRel, CrossNER(AI 도메인), ASTE(laptop)  

***

# 성능 향상·비교 및 한계

## 성능 요약  

| Task       | 접근법 | 샘플 수 | 비용(USD) | 정확도／F1 | 人 레이블 대비 격차 |
|------------|--------|---------|-----------|------------|---------------------|
| SST2 (감정)   | PGDA   | 3k      | 11.31     | 87.75%     | –0.72%             |
|            | PGDG   | 3k      | 0.91      | 73.81%     | –13.66%            |
|            | DADG   | 3k      | 7.18      | 68.04%     | –19.43%            |
| FewRel (관계) | PGDG   |12.8k    | 30.58     | 44.11      | +9.89              |
|            | DADG   |12.8k    | 17.16     | 40.02      | +5.77              |
| CrossNER (NER)| DADG   |3k      | 13.61     | 47.22%     | +5.22%             |
| ASTE (triplet)| PGDA   | 906     | 11.34     | 50.26      | –9.06              |

- **소규모 라벨 스페이스**(감정분석, ASTE): PGDA가 인간 레이블 대비 손실 최소화  
- **대규모 라벨 스페이스**(FewRel, CrossNER): PGDG/DADG가 PGDA 압도, 특히 PGDG가 다양성 높은 데이터 생성  

## 일반화 성능 관점  
- PGDA: 프롬프트 길이·샷 수 증가 시 성능 개선  
- PGDG/DADG: 샷 수 너무 많으면 ‘프롬프트 과적합’으로 문장 정보량 감소  
- 라벨 스페이스가 클수록 데이터 생성 방식이 일반화에 유리  

## 한계  
- GPT-3 블랙박스 특성으로 오류 원인 해석 어려움  
- 대규모 실험 예산 제약  
- 생성 데이터 편향·분포 불일치 문제  

***

# 일반화 성능 향상 가능성

- **샷 수 최적화**: 소규모 라벨 스페이스 PGDA에 유익, 대규모 PGDG엔 과적합 방지 위해 샷 수 조절  
- **혼합 방식**: PGDA로 기본 레이블링, PGDG로 드물게 등장하는 레이블 보강  
- **지식베이스 확대**: DADG에서 전문 도메인 KB 활용 시 도메인 일반화↑  
- **모델 앙상블**: GPT-3·ChatGPT·GPT-4 조합으로 각 모델 강점 상호 보완  

***

# 향후 영향 및 고려사항

- **AI 민주화**: 소규모 연구자·기업도 저비용 고품질 데이터 확보 가능  
- **메타 학습·프롬프트 튜닝**: 자동 애노테이터용 프롬프트 최적화 연구 활성화  
- **윤리·편향 검증**: 생성 데이터 편향 모니터링·교정 기법 필수  
- **LM 비교 연구**: GPT-3 외 ChatGPT·GPT-4·LLaMA 등 오픈소스 LLM과 성능·비용 비교 필요  

이 논문은 대형 언어모델을 활용한 자동 레이블링의 실용적 가능성을 제시하며, 앞으로 프롬프트 설계·혼합 애노테이션 전략·편향 보정 연구의 기반이 될 것입니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/642e8611-0eaf-44ec-bbcd-ce6fda53ca5c/2212.10450v2.pdf)
