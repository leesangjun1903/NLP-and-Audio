# Complexity-Based Prompting for Multi-Step Reasoning

## 1. 핵심 주장 및 주요 기여
**Complexity-Based Prompting**은 체인-오브-쏘트(Chain-of-Thought, CoT) 예시를 선택할 때, 복잡도(추론 단계 수)가 높은 사례를 골라 프롬프트로 사용하면 다단계 추론 성능이 현저히 향상된다는 점을 주장한다.  
- **입력(selection) 측면**: 단계 수가 많은 복잡한 CoT 예시 8개를 프롬프트로 제공하면, GPT-3·Codex 등의 대형 언어 모델이 단순 예시 대비 평균 +5.3∼+6.2%p 정확도 향상을 달성한다.[1]
- **출력(decoding) 측면**: 추론 결과로 N=50개 체인 샘플을 생성한 뒤, 최상위 K(≈30–40)개 복잡도 높은 체인에 대한 다수결 투표를 수행하면 추가 +0.5∼+8.6%p 성능 향상을 얻는다.[1]
- 수작업 튜닝·검색 기반 선택·랜덤 선택 대비 **최고 성능** 또는 유사 성능을 소수 예시(8개)만으로 달성하며, 표준 CoT 대비 최대 +18.0%p 개선을 보인다.[1]

## 2. 해결 과제 및 제안 방법
### 2.1 문제 정의  
기존 CoT 프롬프트에서 예시 선택은 수작업·유사도 기반·휴리스틱에 의존하며, 어떤 예시가 다단계 추론을 가장 잘 유도하는지 체계적 기준이 부족했다.

### 2.2 제안 방법  
1) **Complexity-Based Prompting**  
   - 각 예시의 복잡도를 **추론 단계 수**(라인 수)로 정의.  
   - 훈련셋에서 단계 수가 가장 많은 8개 사례를 프롬프트로 사용.  
2) **Complexity-Based Consistency**  
   - 디코딩 시 N개의 체인 샘플 생성, 각 체인의 단계 수를 기준으로 상위 K개 복잡 체인만 골라 다수결로 최종 답 도출.

#### 수식 표현  
- 프롬프트 예시 전체 단계 수:  

$$
S_{\text{total}} = \sum_{i=1}^{m} s_i,\quad m=8,\ s_i=\text{예시 }i\text{의 단계 수}
$$

- 출력 투표:  

$$
\hat{a} = \arg\max_{a} \sum_{j=1}^{K} \mathbb{I}\bigl(a_j=a\bigr),\quad K\le N
$$

### 2.3 모델 구조  
- 변경 없이 **GPT-3 text-davinci-002** 및 **Codex code-davinci-002**에 적용.  
- 프롬프트 앞에 “Let’s think step by step”를 추가하여 일관된 구조 유지.

## 3. 성능 향상 및 한계
### 3.1 성능 요약  
| 데이터셋         | GPT-3 기본 CoT | Complexity-Based (+ Prompt) | + Consistency 투표 |
|-----------------|---------------|------------------------------|-------------------|
| GSM8K (greedy)  | 48.1%         | 55.4% (+7.3)                | —                 |
| GSM8K (vote)    | 64.0%         | 71.5% (+7.5)                | 72.6% (+8.6)      |
| MultiArith      | 90.8%         | 94.2% (+3.4)                | 98.7% (+0.5)      |
| MathQA          | 30.1%         | 36.0% (+5.9)                | 50.2% (+6.4)      |

### 3.2 일반화 성능  
- **단순→복잡 전이**: 복잡 프롬프트가 *단순* 테스트 케이스에 더 큰 성능 향상을 주어, 복잡 사례에서 학습한 패턴이 단순 사례에도 일반화됨을 보인다.  
- **도메인·노이즈·이동 학습**: in-distribution, noisy-labeled, transfer prompt 세 조건 모두에서 복잡 프롬프트가 일관된 우위를 보임.[1]

### 3.3 한계  
- **모델 규모 의존성**: Curie(6.7B), Flan-T5(11B) 등 소형 모델에서는 복잡도 기반 선택 효과가 미미.[1]
- **프롬프트 길이 증대**: 단계 수 증가에 따른 토큰 비용·실행 속도 저하 고려 필요.  
- **예시 단계 주석 필요**: MultiArith처럼 CoT 주석이 없는 데이터셋은 질문 길이 등을 대체 지표로 활용해야 함.

## 4. 향후 영향 및 고려 사항
- **프롬프트 자동화 연구**: 추론 단계 수를 정량화하여 예시를 자동 선별하는 기법 발전.  
- **복잡도 정의 확장**: 단계 외 *수학식 길이*, *문장 길이* 등 다양한 복잡성 지표 평가.  
- **효율성 향상**: 토큰 비용과 성능 간 트레이드오프 최적화, 소형 모델로의 확장 가능성 연구 필요.  
- **자기일관성(Self-Consistency) 심화**: 단계 복잡도 외 *구조적 다양성*을 고려한 출력 집계 방안 탐색.

**주요 참고**  
- 성능 향상 근거: Complexity-Based Prompting.[1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/d426836c-5ca1-4582-b105-fa221b2892f0/2210.00720v2.pdf)
