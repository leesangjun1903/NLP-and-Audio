# Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models 

**핵심 주장 및 기여**  
“Beyond the Imitation Game” 논문은 대규모 언어 모델이 점차 확장됨에 따라 나타나는 **양적·질적 성능 변화를 정량적으로 분석**하고, 이를 바탕으로 미래 모델의 능력을 예측하기 위한 **BIG-bench(Beyond the Imitation Game benchmark)**를 제안한다. 주요 기여는 다음과 같다.

- 204개의 다양·난이도 높은 과제로 구성된 BIG-bench 정립  
- 모델 크기(수백만~수천억 매개변수)별 성능 평가 및 **인간 전문가와의 비교**  
- **정량화된 성능 지표(정규화된 선호 메트릭)** 도입으로 과제별·전체 성능 분석  
- **선형성(linearity)**·**돌파성(breakthroughness)** 지표로 스케일링 행태 분류  
- **BIG-bench Lite**: 24개 대표 JSON 과제로 경량 평가 세트 제공  

---  

## 1. 해결하고자 하는 문제  
기존 벤치마크들은 - 범위가 좁고 - 빠르게 포화되어 - 새로운 모델 능력 예측에 한계가 있었다.  
이에, 언어 모델의 **현재·미래 능력**, 특히 대규모 확장에 따른 **돌파적(aha 순간) 성능 향상**을 포착할 수 있는 **광범위·고난도 벤치마크**가 필요하다.  

## 2. 제안 방법  
### 2.1. BIG-bench 벤치마크  
- 204개 과제: JSON(80%)·프로그램(20%) 유형  
- 과제별 **선호 메트릭(preferred metric)**, 최대·최소 성능 지정  
- 정규화된 점수:  

$$\text{정규화 점수} =100\times\frac{\text{실제 점수}-\text{최저 값}}{\text{최고 값}-\text{최저 값}} $$  

### 2.2. 평가 대상 모델  
- Google BIG-G(밀집)·BIG-G sparse(희소)·OpenAI GPT-3 시리즈  
- 모델 크기: 10⁷~10¹¹ 매개변수  
- 무온도(temperature=0) 그리디 샘플링 기준 성능 측정  

### 2.3. 스케일링 행태 지표  
- **선형성(Linearity, L)**: 성능 변화의 일관성(평균 차이 기반)  
- **돌파성(Breakthroughness, B)**: 특정 규모 이상에서 급등 여부(중앙값 차이 기반)  
  
## 3. 모델 구조 및 성능 향상  
### 3.1. 모델 구조  
- BIG-G: LaMDA 계열 트랜스포머, 13개 크기  
- BIG-G sparse: MoE 기반 토큰별 상위 2개 전문가 라우팅  
- GPT-3: 125M~175B 규모  

### 3.2. 성능 요약  
- **모델 성능은 스케일에 따라 꾸준히 향상**되나, 최고 모델도 정규화 점수 &lt;20에 불과  
- **인간 전문가** 평균·최고 점수 50~100 대비 현저히 낮음  
- **희소 모델**은 같은 연산량 대비 2배 매개변수로 동급 성능 달성  
- **돌파 과제** 약 5%에서만 대규모에서만 갑작스런 성능 상승 관측  

### 3.3. 일반화 성능 관점  
- **서브태스크 분해** 시, 예컨대 ‘체스 합법 수(legal moves)’ 예측 능력은 스케일에 비례해 선형 상승  
- **로그 확률(log-likelihood)**과 같은 부드러운 메트릭도 스케일 증가에 따라 연속 증대  
- **입력 프롬프트 형식 취약성**: 동일 과제라도 제시 방식에 따라 일반화 성능 편차 큼  
- **최신 PaLM** 모델 등, 단순 스케일 로그선형 예측 범위를 넘어서는 성능 향상 관측  

## 4. 한계 및 향후 고려사항  
- 전통 벤치마크 대비 **저속도 성장**, **낮은 절대 성능**은 스케일만으로는 한계  
- **사회적 편향**은 스케일 증가 시 악화되는 과제 존재  
- **맥락 길이**, **순환적 계산** 등 구조적 한계 과제 여전  
- **다국어·저자원 언어** 성능 저조, 스케일로 극복 불가능  

## 5. 향후 연구 영향 및 고려점  
- **지속적 벤치 확장**: 멀티모달·실세계 과제 추가로 **거버넌스·안전성** 강화  
- **세분화된 메트릭** 개발: 돌파 지표만으로 포착되지 않는 **연속적 능력 향상** 추적  
- **프롬프트·파인튜닝 전략**: 제시 방식 의존성 최소화·편향 완화 기법 연구  
- **소규모 언어 처리**: 저자원 언어용 전용 데이터 수집·모델링 기법 마련  

***

**결론**: BIG-bench는 대규모 언어 모델의 **능력 분포와 확장 법칙**을 체계적으로 파악할 수 있는 강력한 평가틀을 제공한다. 향후 **다양한 과제·언어·편향** 문제를 반영하며 지속 확장함으로써, **더 안전·강건·포괄적**인 언어 모델 개발의 토대를 마련할 것이다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/93fa736d-8199-45dd-8779-10a9263974db/2206.04615v3.pdf)
