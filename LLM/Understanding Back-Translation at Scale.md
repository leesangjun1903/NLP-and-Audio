# Understanding Back-Translation at Scale

**핵심 주장 및 주요 기여**  
이 논문은 대규모 신경 기계 번역(NMT)에 있어, 단순히 MAP 추론(beam search, greedy)으로 생성한 백-트랜슬레이션(Back-Translation; BT) 문장보다 “샘플링” 또는 “노이즈를 더한 beam search” 방식으로 생성된 합성 소스 문장이 더욱 **강력한 학습 신호**를 제공함을 보인다. 주요 기여는 다음과 같다.[1]
- 백-트랜슬레이션을 통한 데이터 증강 시, 샘플링 및 노이즈 적용 기법이 MAP 기반 기법 대비 평균 1.7 BLEU 향상을 달성함.[1]
- 합성 데이터가 실제 비텍스트(bitext)의 최대 83% 성능을 재현하며, 도메인 적합성(domain match)에 따라 실 텍스트 대비 67–83% 성능을 확보함.[1]
- 226M 문장 규모 모노리니언 데이터로만 WMT’14 English→German에서 토크나이즈 BLEU 35.0을 달성하며, 상용 엔진 DeepL 대비 1.7 BLEU 우위 확보.[1]

***

## 1. 해결하고자 하는 문제  
기존 NMT는 **풍부한 병렬 말뭉치(bitext)** 없이 성능이 저하되며, 대규모 모노리니언 데이터 활용은 백-트랜슬레이션을 통해 이루어진다. 그러나 대부분 BT 연구는 합성 소스 생성에 beam search 또는 greedy 탐색(=MAP 추론)을 사용하여, **모델 분포의 다양성 부족**과 **학습 신호 약화** 문제가 있다.[1]

***

## 2. 제안 방법  
### 2.1 합성 소스 생성 기법  
- **Beam Search (MAP)**  
- **Greedy Search (MAP)**  
- **Unrestricted Sampling**: 매 토큰 예측 시 전체 어휘에서 샘플링  
- **Top-k Sampling**: 매 토큰 상위 k(k=10) 단어로 분포 재정규화 후 샘플링  
- **Beam+Noise**: Beam 결과에 단어 삭제(p=0.1), 토큰 대체(p=0.1), 인접 단어 스왑(noise) 적용[1]

### 2.2 수식적 정의  
합성 소스 $$x'$$ 생성은 원래 모델 $$\theta$$의 분포 $$p_\theta(x|y)$$에 따라 이루어지며,  
- MAP: $$x'=\arg\max_x p_\theta(x|y)$$  
- 샘플링: $$x'\sim p_\theta(x|y)$$  
- Top-k 샘플링:

```math
p_{\theta,k}(x|y)=\begin{cases}p_\theta(x|y)/Z,&x\in \text{Top-}k\\0, &\text{otherwise}\end{cases} 에서 x'\sim p_{\theta,k}
```

- Beam+Noise: $$x_{\text{beam}}$$에 노이즈 연산 $$\mathcal{N}(\cdot)$$ 적용하여 $$x'=\mathcal{N}(x_{\text{beam}})$$[1]

### 2.3 모델 구조 및 학습  
- **Transformer-Big** (6-layer 인코더·디코더, hidden 1024, FFN 4096, 16 heads, dropout=0.3)  
- Adam 옵티마이저, label smoothing(ε=0.1), 16-bit precision, Infiniband 분산학습  
- 합성 데이터 크기에 따라 학습 스텝 조정(5M bitext-only:30K 업데이트, 24M 합성:100K 업데이트)[1]

***

## 3. 성능 향상 및 한계  
### 3.1 성능 향상  
- **샘플링/노이즈** 방식이 beam/greedy 대비 0.8–1.1 BLEU 추가 향상.[1]
- 24M 합성 문장 추가 시, 샘플링은 베이스라인 대비 +2.6 BLEU, beam 대비 +1.7 BLEU.[1]
- 저자원(80K bitext) 환경에서는 샘플링이 과도한 노이즈를 유발해 MAP 방식이 더 유리; 고자원 환경에서만 샘플링 우세 확인.[1]
- 도메인 일치 시(뉴스→뉴스), 합성 데이터가 실제 bitext 대비 83% 성능을 달성; 도메인 불일치 시에도 67% 성능 유지.[1]

### 3.2 한계  
- **샘플링 과다노이즈**: 저자원 조건에서 모델 깨어짐.  
- **합성 오류**: 샘플링 시 원문과 무관한 토큰 삽입 위험(Table 3).[1]
- **도메인 의존성**: 출처 불일치시 성능 저하(도메인 적합성 필요).

***

## 4. 모델의 일반화 성능 향상 가능성  
샘플링 및 노이즈 방식은 **합성 문장의 다양성**과 **학습 시 어려운 사례**를 증가시켜, 모델이 보다 넓은 입력 분포에 견고해지도록 유도한다.  
- 학습 곡선에서 beam/greedy 합성 데이터는 빠르게 과적합(perplexity<2)을 보이나, 샘플링 데이터는 높은 퍼플렉서티 유지하며 **강한 정규화 효과** 제공.[1]
- 언어 모델 측정 시, beam 합성문이 저퍼플렉서티로 “단조로움”을 보이는 반면, 샘플링은 실제 인간 문장 수준의 다양성 유지.[1]
따라서 합성 데이터 다양성 증대로 **일반화 능력**을 실질적으로 향상시킬 수 있다.

***

## 5. 향후 연구에 미치는 영향 및 고려사항  
- **합성 데이터 최적화**: 합성 문장 품질과 다양성 간 균형을 찾기 위한 end-to-end 최적화 기법 연구 필요.  
- **적응적 노이즈 스케줄링**: 학습 단계별 노이즈 강도 조절로 저자원 환경에서도 샘플링 효과 유지 방안 모색.  
- **도메인 일반화**: 다중 도메인 모노리니언 데이터 활용 시 도메인 태그 기반 BT 기법 개발.  
- **인간 평가 연계**: 자동 BLEU 외 인간평가 중심 검증으로 합성 오류가 번역 품질에 미치는 실질적 영향 분석.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/1b9a6d18-79cb-4f5d-882f-c86fd31f5b4c/1808.09381v2.pdf)
