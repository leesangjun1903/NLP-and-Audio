# Autoformalizing Mathematical Statements by Symbolic Equivalence and Semantic Consistency

## 1. 논문의 핵심 주장과 주요 기여[1]

이 논문은 대규모 언어모델(LLM)에 의한 자동형식화 작업에서 **pass@1과 pass@k 사이의 성능 격차**를 관찰하고 이를 해결하기 위한 혁신적 프레임워크를 제안합니다. 핵심 주장은 다음과 같습니다.[1]

**주요 기여:**

1. LLM의 자동형식화 작업에서 pass@1(첫 번째 생성이 정확함)과 pass@k(k개 생성 중 하나가 정확함) 사이의 **상당한 성능 격차(19.5%-26.5%)를 식별**하고, 이를 bridging하기 위한 프레임워크 제안[1]

2. **두 가지 보완적 자기일관성 방법** 도입:
   - 기호적 동치성(Symbolic Equivalence, SymEq): 자동정리증명기를 활용한 논리적 동치성 검증
   - 의미론적 일관성(Semantic Consistency, SemCo): 재형식화(back-translation)와 임베딩 유사성을 통한 의미 보존 평가[1]

3. **상당한 성능 개선**: MATH 및 miniF2F 데이터셋에서 GPT-4 기준 **7.8%-10.7%의 절대 성능 향상 달성**, 상대 효율성 **8.4%-21.9%** 달성[1]

---

## 2. 문제 정의, 제안 방법, 모델 구조 및 성능[1]

### 2.1 문제 정의[1]

자동형식화는 자연언어 수학 진술을 Isabelle/HOL, Lean, Coq 같은 형식언어로 자동 변환하는 작업입니다. 주요 문제점:

- **신뢰성 부족**: GPT-4는 $0.\overline{6} \times 6 = 4$ 와 같은 단순한 계산도 종종 실패 (예: $0.\overline{6}$를 $2/3$ 로 정확히 매핑하지 못함)[1]

- **일관성 부족**: 변수 선언의 차이 (예: $(a,b)$ vs $(x,y)$ )로 인해 동일한 수학적 진술이 다르게 형식화[1]

- **평가 어려움**: 테스트 케이스가 없어 코드 생성의 자기일관성 기법을 직접 적용 불가[1]

### 2.2 제안 방법[1]

#### 2.2.1 기호적 동치성 (Symbolic Equivalence)[1]

**정의 1: 기호적 동치성**

두 형식 진술 $\Psi_1$, $\Psi_2$가 각각 $P_1 \rightarrow Q_1$, $P_2 \rightarrow Q_2$로 표현될 때, 다음 두 논리 동치가 성립하면 **기호적으로 동치**:

$$P_1 \equiv P_2 \text{ 그리고 } Q_1 \equiv Q_2$$

이는 자동정리증명기(ATP, Sledgehammer, Z3, CVC5)를 사용하여 검증됩니다.[1]

**변수 매칭 문제 해결:**

형식 진술 $P(x_1, \ldots, x_n) \rightarrow Q(x_1, \ldots, x_n)$를 표준화하기 위해 두 가지 경우를 다룹니다:[1]

**(경우 1)** 결론이 수치 관계 형태 $Q(x_1, \ldots, x_n) := f(x_1, \ldots, x_n) \triangleright\!\!\triangleleft 0$ (여기서 $\triangleright\!\!\triangleleft \in \{\leq, \geq, <, >, =, \neq\}$):

새 변수 $\alpha$를 도입하여 표준 형식으로:

$$\tilde{P}(\alpha; x_1, \ldots, x_n) \rightarrow \tilde{Q}(\alpha)$$

여기서:
$$\tilde{P}(\alpha; x_1, \ldots, x_n) := P(x_1, \ldots, x_n) \wedge (\alpha = f(x_1, \ldots, x_n))$$
$$\tilde{Q}(\alpha) := \alpha \triangleright\!\!\triangleleft 0$$

**(경우 2)** 비수치 경우  

```math
Q(x) := \text{is even}(x)
```

변수 정렬을 이분 매칭 문제로 변환하며, 그래프 간선 가중치는 문자열 편집거리(string edit distance)로 설정합니다.[1]

**기호 점수 계산:**

형식화 후보의 기호 점수 $s^{sym}_i$는 해당 동치류 크기의 비율로 설정됩니다.[1]

#### 2.2.2 의미론적 일관성 (Semantic Consistency)[1]

**정의 2: τ-의미론적 일관성**

원래 자연언어 진술 $\Phi$와 형식화 후보 $\Psi$에 대해, $\Psi$가 재형식화되어 $\tilde{\Psi}$가 될 때, 다음 조건 만족 시 **τ-의미론적으로 일관**:

$$\text{Sim}(\tilde{\Psi}, \Phi) \geq \tau$$

여기서 $\text{Sim}$은 BERT 임베딩을 사용한 코사인 유사도:[1]

$$\text{Sim}(x, y) = \frac{\mathbf{e}(x) \cdot \mathbf{e}(y)}{|\mathbf{e}(x)| \cdot |\mathbf{e}(y)|}$$

의미론적 일관성은 형식화-재형식화 과정에서의 오류를 측정하며, 재형식화(역번역)가 형식화보다 훨씬 쉽고 정확하므로, 주로 형식화 오류를 반영합니다.[1]

#### 2.2.3 두 점수의 결합[1]

정규화 후 (softmax): $\hat{s}^{sym}_i = s^{sym}_i / \sum^k\_{j=1} s^{sym}_j$, $\hat{s}^{sem}_i = s^{sem}_i / \sum^k\_{j=1} s^{sem}_j$

세 가지 결합 전략 제안:

**로그 결합:**
$$\hat{s}_i = \alpha \log \hat{s}^{sym}_i + (1-\alpha) \log \hat{s}^{sem}_i$$

**선형 결합:**
$$\hat{s}_i = \alpha \hat{s}^{sym}_i + (1-\alpha) \hat{s}^{sem}_i$$

**제곱 결합:**
$$\hat{s}_i = \alpha (\hat{s}^{sym}_i)^2 + (1-\alpha) (\hat{s}^{sem}_i)^2$$

여기서 $\alpha \in $은 두 방법 간 균형을 제어하는 하이퍼파라미터입니다.[1]

### 2.3 모델 구조[1]

프레임워크는 4단계로 구성:

1. **형식화 후보 생성**: LLM으로 k개의 형식화 후보 $\Psi_1, \ldots, \Psi_k$ 생성[1]

2. **기호적 동치성 계산**: ATP를 사용하여 각 형식화에 기호 점수 할당[1]

3. **의미론적 일관성 계산**: LLM으로 재형식화 후, BERT 임베딩 기반 유사도 계산으로 의미 점수 할당[1]

4. **점수 결합 및 선택**: 정규화된 점수 결합으로 최고 순위 형식화 결과 선택[1]

### 2.4 성능 향상[1]

**RQ1: 효능성** - 기호적 동치성(SymEq)의 우수성:

| 모델 | MATH (1@10) | miniF2F (1@10) |
|------|-------------|----------------|
| Mistral-7B | +8.6% | +6.9% |
| Llemma-34B | +7.7% | +10.7% |
| DeepSeek-v2 | +5.1% | +0.8% |
| Codex | +2.3% | +6.5% |
| GPT-4 | +4.5% | +8.2% |

**RQ2: 상승 효과** - 결합 전략의 추가 개선:

로그 결합(log-comb)으로 기호적 동치성 대비:
- Mistral-7B: +22.6% (MATH), +10.5% (miniF2F)
- GPT-4: +3.3% (MATH), +2.5% (miniF2F)[1]

**RQ3: 라벨링 효율성** - 평균 라벨링 비용 감소:

$$\sigma = \frac{\sum^{k-1}_{n=2} n \cdot (n@k - (n-1)@k) + (1-k@k)}{N}$$

상대 효율성 $E = 1 - \sigma/\tilde{\sigma}$에서 log-comb은 MATH에서 **17.7%-21.6%**, miniF2F에서 **8.4%-21.9%** 달성.[1]

### 2.5 한계[1]

논문에서 명시한 주요 한계:

1. **LLM의 형식 라이브러리 부재**: LLM이 기존 함수/정의를 모르면 정확한 형식화 생성 불가[1]

2. **형식화의 번역 이상**: 일부 수학 문제는 단순 매핑을 넘어 정의의 조합이나 변형 필요[1]

3. **ATP의 제한된 능력**: 현재 ATP는 고등학교 수준 문제도 증명하기 부족하며, 기호적 동치성 증명도 실패 가능[1]

4. **임베딩의 의미 미세성 부족**: BERT 임베딩이 수학 진술의 미세한 의미 차이(단일 표기법 변경도 의미 완전 변경 가능) 구분 불가[1]

5. **인간 평가 필요**: 이상적인 ATP와 임베딩도 사람의 최종 검증 필수[1]

---

## 3. 모델의 일반화 성능 향상 가능성[1]

### 3.1 현재 성능 분석[1]

**문제 난이도에 따른 성능 격차:**

| 난이도 | 문제 수 | Baseline | SymEq | SemCo | Log-comb |
|--------|--------|----------|-------|-------|----------|
| 1 | 37 | 64.8% | 67.5% | 64.8% | 75.6% |
| 2 | 70 | 44.2% | 47.1% | 47.1% | 52.8% |
| 3 | 91 | 48.3% | 57.1% | 47.2% | 53.8% |
| 4 | 91 | 26.3% | 34.0% | 31.8% | 40.6% |
| 5 | 111 | 24.3% | 24.3% | 26.1% | 27.0% |

난이도 1-3 (쉬운 문제)과 난이도 4-5 (어려운 문제) 간 **상당한 성능 격차** 관찰됨.[1]

### 3.2 일반화 성능 향상을 위한 분석[1]

**SymEq와 SemCo의 카테고리별 성능 차이:**

문제 카테고리에 따라 두 방법의 성능이 상이:
- **대수(Algebra)**: SymEq 57.8% < SemCo 59.8% → SemCo 우수
- **세기 및 확률(Counting)**: SymEq 36.9% > SemCo 30.3% → SymEq 우수  
- **기하학(Geometry)**: SymEq 28.1% < SemCo 25.1% (둘 다 저조)
- **수론(Number Theory)**: SymEq 33.3% < SemCo 38.0% → SemCo 우수
- **산전대수(Prealgebra)**: SymEq 51.6% > SemCo 40.3% → SymEq 우수[1]

이는 서로 다른 문제 유형의 요구사항이 다름을 의미하며, 결합 전략이 양쪽의 강점을 활용할 수 있음을 시사합니다.

### 3.3 일반화 성능 향상 전략[1]

**1. 강화된 LLM 활용**

더 강력한 LLM 사용 시 자동형식화 성능 향상:
- 문제 난이도와 자동형식화 정확도의 강한 상관관계[1]
- 더 나은 수학적 추론 능력을 가진 LLM (예: DeepSeekMath, InternLM-Math) 활용 가능

**2. 하이퍼파라미터 최적화**

로그 결합에서 $\alpha$ 값의 large sweet spot ($\alpha \in [0.32-0.6]$) 존재하므로, 검증 데이터셋 기반 최적화로 추가 개선 가능.[1]

**3. ATP 능력의 한계**

일반 ATP vs 제한된 ATP 성능 비교 결과, ATP 강화의 영향 미미:
- 일반 ATP: 문제당 평균 2.33개 동치성 증명 vs 제한 ATP: 2.13개
- 최종 성능에 미치는 영향: 1@k에서 거의 증진 없음[1]

이는 현재 성능 향상의 병목이 ATP 능력이 아니라 **LLM의 형식화 품질**임을 시사합니다.

### 3.4 도메인별 일반화 가능성[1]

**카테고리 특화 모델 개발:**

기하학 문제(SemCo 성능 저조)는 시각적 번역의 어려움으로 인해 의미 기반 방법 부족. 이를 위해:

- 기하학 특화 형식 라이브러리 활용
- 기하학 문제 특화 LLM 미세조정
- 시각적 정보 통합 방법 개발

***

## 4. 논문의 영향과 미래 연구 방향[1]

### 4.1 현재 연구에 미치는 영향[1]

**이론적 기여:**

1. **자기일관성 개념의 확장**: 기존 자기일관성 방법(최종 답변/실행 결과 비교)을 형식 수학으로 확대, 변수 매칭 문제 해결을 위한 이분 그래프 매칭 기법 도입[1]

2. **형식-비형식 간 루프 활용**: 재형식화를 통한 검증 메커니즘 도입으로, 형식화의 의미론적 정확성 검증 가능[1]

3. **ATP와 임베딩의 상호보완성 입증**: SymEq와 SemCo의 synergy 관계 발견으로 하이브리드 접근법의 효과 증명[1]

**실용적 기여:**

1. **인간 라벨링 비용 감축**: 상대 효율성 21.9%로 형식화 검증에 필요한 인간 개입 최소화[1]

2. **다양한 LLM에 대한 스케일 가능성**: 5개의 서로 다른 규모의 모델(7B~최신 LLM)에서 일관된 개선 달성[1]

### 4.2 미래 연구 방향[1]

**단기 개선 사항:**

1. **추가 정리증명기 지원**: Lean 4 등 더 많은 형식 언어에 확대

2. **고급 LLM 통합**: ProofGPT, MMA 같은 사전학습된 형식 수학 LLM과 결합

3. **고품질 데이터 합성**: 현재 프레임워크로 생성한 고품질 형식-비형식 정렬 데이터셋 구축

**중장기 개선 사항:**

1. **검색 기반 보강**: 형식 라이브러리의 관련 함수/정의를 동적으로 검색하는 검색 메커니즘 통합[1]

2. **미세조정 기반 개선**: 고품질 형식-비형식 쌍을 사용한 LLM 미세조정으로 기초 형식화 품질 향상[1]

3. **멀티모달 형식화**: 기하학 등 시각 정보 필요 분야를 위한 멀티모달 LLM 활용

4. **강화학습**: ATP 피드백을 보상 신호로 하는 강화학습으로 LLM 정책 직접 최적화[1]

### 4.3 최신 연구와의 연계 고려사항[1]

**현재 트렌드(2024-2025):**

1. **수학 특화 LLM의 발전**: DeepSeekMath, InternLM-Math 등 수학 추론 특화 모델 등장
   - 이들 모델과 SymEq/SemCo 결합으로 성능 향상 가능성 높음
   - 현재 실험 미포함으로 추후 실증 필요[1]

2. **형식 수학 라이브러리 확충**: Lean 4 생태계 성장, 새로운 형식 정의 지속 추가
   - 동적 라이브러리 검색 메커니즘의 중요성 증대

3. **자동 증명 기술 진화**: 뉴럴-기호적 결합 정리증명기 개발
   - 현재 ATP의 한계(고난이도 문제 증명 불가) 극복 가능

**연구 시 고려 사항:**

1. **벤치마크 확대**: MATH(400문제), miniF2F(488문제)를 넘어 더 규모 있는 벤치마크 필요
   - 통계적 유의성 검증 추가 필요[1]

2. **기울기 문제 해결**: 현재 기하학 문제 성능 저조 → 도메인 특화 방법론 개발 필요[1]

3. **임베딩 모델 개선**: BERT 외 최신 임베딩 모델(e.g., contrastive learning 기반)의 효과 검증

4. **증명 생성과의 통합**: 현재 형식화만 다루나, 증명 생성과 결합한 end-to-end 시스템 개발

***

## 결론

이 논문은 LLM 기반 자동형식화의 성능 격차를 해결하기 위해 **기호적 동치성**과 **의미론적 일관성**이라는 상호보완적 자기일관성 방법을 제안하여, **절대 7.8%-10.7% 성능 향상**을 달성했습니다. 특히 다양한 LLM과 문제 카테고리에서 일관된 효과를 보이며, 인간 라벨링 비용 감축에 기여합니다. 다만 형식 라이브러리 부족, ATP의 제한된 능력, 의미론적 미세성 인식 부족 등의 한계가 존재하므로, 앞으로는 **강화된 LLM 활용, 검색 기반 보강, 멀티모달 확대, 강화학습 적용** 등의 방향으로 연구가 진행되어야 합니다.[1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/cb4630da-1eee-46a6-8cb5-a2bf9779abe0/2410.20936v2.pdf)
