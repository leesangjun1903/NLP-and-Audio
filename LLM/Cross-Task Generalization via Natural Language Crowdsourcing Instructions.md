# Cross-Task Generalization via Natural Language Crowdsourcing Instructions

## 1. 핵심 주장 및 주요 기여  
**핵심 주장**  
인공지능 모델이 *새로운* NLP 과제를 풀기 위해서는 해당 과제의 **자연어 지침(instructions)** 만으로도 성능을 크게 향상시킬 수 있으며, 다양한 과제(Tasks)를 학습함으로써 전혀 보지 못한 과제에도 일반화할 수 있다는 점을 제시한다.

**주요 기여**  
1. **NATURAL INSTRUCTIONS 데이터셋 공개**  
   -  61개 서로 다른 NLP 과제와 193K개의 예시 인스턴스를 포함  
   -  기존 크라우드소싱 템플릿을 8가지 구성요소(제목·정의·피해야 할 점·주의사항·프롬프트·양성 예시·음성 예시·설명)로 체계화  
2. **크로스-태스크 일반화 설정 정식화**  
   -  훈련 시 본 적 없는 과제(Unseen tasks)에 대해 자연어 지침만으로 예측하는 *과제 수준 일반화(task-level generalization)* 정의  
3. **지침 활용 모델 성능 검증**  
   -  BART 기반 모델이 지침을 부여받으면 일반화 성능이 19%p 향상됨  
   -  지침을 주지 않은 경우에는 과제 수를 늘려도 성능 개선이 없음  
4. **지침 구성요소의 효과 분석**  
   -  정의(Definition)·양성 예시(Pos. Examples)·주의사항(Things to Avoid) 등 다양한 요소의 기여도 정량화  
   -  음성 예시(Neg. Examples)는 오히려 모델 성능 저해  

## 2. 문제 설정, 제안 방법, 모델 구조, 성능 및 한계

### 2.1 해결하고자 하는 문제  
- **인스턴스 수준 일반화(instance-level generalization)**: 동일 과제의 새로운 예시에만 성능을 보장  
- **과제 수준 일반화(task-level generalization)**: 전혀 학습된 적 없는 새로운 과제에도 자연어 지침만으로 성능을 확보하고자 함

### 2.2 제안 방법  
모델 입력으로 과제 지침 $$I_t$$과 인스턴스 $$x$$를 묶어 텍스트로 인코딩한 뒤, 디코더가 출력 $$y$$를 생성하도록 학습  

$$ M\bigl( \text{enc}(I_t, x)\bigr) = y $$  

- **enc**:  
  - 프롬프트, 정의, 피해야 할 점, 주의사항, 양성·음성 예시 등을 순차적으로 나열  
- 다양한 인코딩 대조 실험(예: 프롬프트만, 프롬프트+정의, 전체 지침 등)을 통해 요소별 기여도 평가  

### 2.3 모델 구조  
- **BART-base (140M 파라미터)**: 세밀한 지침 학습을 위해 파인튜닝  
- **GPT-3 (175B 파라미터)**: 파인튜닝 불가, few-shot 프롬프트만 활용  

### 2.4 성능 향상  
- **무지침 vs 전체 지침 (랜덤 분할)**  
  - BART: **13→32 ROUGE-L** (+19)  
  - GPT-3: 24 ROUGE-L  
- **지침 활용 시 과제 수 확대**  
  - 학습 과제 수 증가에도 **지침 없이는** 일반화 성능 정체  
  - **지침 있을 때만** 과제 수 증가에 따라 성능 선형 개선  

### 2.5 한계  
- 음성 예시(Neg. Examples) 학습 난이도 높아 성능 저해  
- 검증(Verification) 과제군에서 저조한 일반화 성능  
- 과제 특이적 상한(upper bound)인 과제별 파인튜닝 모델(66 ROUGE-L) 대비 여전히 크게 낮음  

## 3. 일반화 성능 향상 관점  
- **지침의 다양성 확대**: 더 많은 종류의 과제를 포함시킬수록 모델이 지침의 패턴을 폭넓게 학습  
- **지침 구성요소 최적화**: 정의·프롬프트·양성 예시 위주로 제공하고, 음성 예시는 과제 특성에 따라 선별  
- **모델 규모 vs 학습 방식**: BART(140M)가 GPT-3(175B)보다 적절한 파인튜닝으로 우수한 일반화 성능 달성  

## 4. 향후 연구 영향 및 고려 사항  
- **메타-학습 관점 확대**: 다양한 과제 지침을 수집·구조화하여 *진정한 범용 AI 시스템*으로 나아갈 수 있는 기반 제공  
- **지침 자동 생성/심화 연구**: 자연어로 된 지침을 자동 생성·요약하거나, 과제 간 유사도 기반 지침 추천 시스템 개발  
- **부정 예시 학습 전략**: 음성 예시의 부정적 영향 최소화를 위한 별도 학습 기법(대조 학습 등) 연구  
- **다양한 태스크로 스케일 업**: 시각·음성·멀티모달 과제로 확장하여 자연어 지침 일반화 범위 검증  

이 논문은 *지침만으로* 모델이 전혀 새로운 과제를 수행할 수 있음을 실증하며, **과제 지침의 체계적 수집·구조화**가 범용 AI로 나아가는 핵심 열쇠임을 제시한다. 앞으로 연구자는 지침의 **다양성·품질**을 높이고, **지침-모델 상호작용**을 심화하는 방향으로 주목해야 한다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/3b2e5c5b-6419-4314-8ff6-d11db1f0018b/2104.08773v4.pdf)
