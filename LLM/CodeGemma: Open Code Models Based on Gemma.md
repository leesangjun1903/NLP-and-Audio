# CodeGemma: Open Code Models Based on Gemma

**핵심 주장 및 주요 기여**  
CodeGemma는 Google DeepMind의 Gemma 모델을 기반으로, 주로 코드 생성·완성 및 자연어 처리 작업을 위한 세 가지 변형(2B-PT, 7B-PT, 7B-IT)을 공개한 연구이다.  
- CodeGemma 7B-PT/IT는 자연어 이해, 수학적 추론 능력이 뛰어나며, 다른 공개 코드 모델과 동등한 코드 성능을 달성한다.  
- CodeGemma 2B는 100% 코드 데이터로 학습된, 낮은 지연(latency) 환경에서 최적화된 코드 인필링(fill-in-the-middle) 특화 모델이다.[1]

***

## 1. 해결하고자 하는 문제  
대형 언어 모델이 자연어 이해 능력은 뛰어나나, 실제 코드 생성·완성 작업에서는 높은 지연과 일관성·논리적 정확도 문제를 겪는다. 또한, 개발 환경에서는 리포지토리 단위의 컨텍스트 처리와 실시간 응답 속도가 필수적이다. 이 논문은  
- 코드와 자연어 혼합 데이터 학습으로 모델의 다재다능성을 높이고,  
- Fill-in-the-Middle(FIM) 기법 개선 및 멀티파일 패킹을 통해 코드 완성 품질을 향상하며,  
- 규모별 모델(2B, 7B)을 효율적으로 최적화하여 지연-성능 균형을 달성하고자 한다.[1]

***

## 2. 제안 방법  
### 2.1 사전학습(Pretraining)  
- 7B 모델: 80% 코드·20% 자연어 혼합, 500B 토큰 학습  
- 2B v1.1 모델: 100% 코드, 1T 토큰 학습  
- **Fill-in-the-Middle(FIM)**: PSM/​SPM 모드 지원, 기본 FIM 비율 80%(2B v1.1은 90%)  
  - 구분 토큰: `<|fim_prefix|>`, `<|fim_middle|>`, `<|fim_suffix|>`[1]  
- **멀티파일 패킹**:  
  - 의존성 그래프 기반 패킹(파일 임포트 관계 추출 → 최단 경로 계산 → 위상정렬)  
  - 유닛 테스트 기반 렉시컬 패킹(테스트 파일을 구현 파일 옆에 병치)  

### 2.2 Instruct 튜닝  
- 수학 문제 데이터( MATH, GSM8K, MathQA, 합성 수학 데이터 )로 수학적 추론 능력 강화  
- 합성 코드 지시문 생성 후 필터링(SFT + RLHF)  
- 7B-IT v1.1: RLHF 알고리즘 및 합성 데이터 생성 파이프라인 개선  

### 2.3 모델 구조  
- Gemma와 동일한 트랜스포머 아키텍처  
- 파라미터 수: 2B·7B  
- 토크나이저·제어 토큰 일관성 유지  

***

## 3. 성능 향상 및 한계  
### 3.1 성능 향상  
- **코드 완성(HumanEval Infilling)**: 2B-PT 1.1이 37.8% 단일줄, 49.2% 다중줄 달성, 경쟁 모델 대비 유사 혹은 우수.[1]
- **Python 코딩(HumanEval, MBPP)**:  
  - 7B-PT 44.5%/56.2%, 7B-IT v1.1 60.4%/55.2%로 Gemma 7B 대비 대폭 향상.[1]
- **수학 추론(GSM8K, MATH)**:  
  - 7B-IT v1.1 GSM8K 47.3%, MATH 22.3% 기록, 동급 모델 중 최고 수준.[1]
- **지연 최적화**:  
  - 2B 모델이 7B급 대비 inference 속도 2배 이상 우수, IDE·로컬 환경 적용에 적합.[1]

### 3.2 한계  
- 7B 모델은 메모리 요구량이 커 호스팅 환경이 필요  
- FIM 과도 사용 시 코드 논리 일관성 저하 가능성  
- 멀티파일 패킹 시 의존성 추출 오류 발생 시 성능 감소 여지  

***

## 4. 일반화 성능 향상 가능성  
CodeGemma가 제시한 학습·튜닝 기법은 다른 도메인 모델에도 적용 가능하다.  
- FIM 기반 사전학습은 자연어 요약·편집 작업에 확장할 수 있으며,  
- 수학적 추론 강화 데이터셋 활용은 복잡한 논리·수치 예측 태스크로 일반화될 여지가 크다.  
- 멀티파일 패킹 방식은 대규모 문서·멀티모달 입력 처리에도 응용될 수 있다.  

***

## 5. 연구 향후 영향 및 고려사항  
앞으로 코드 생성 모델 연구는  
- **저지연·경량화**에 더해 **논리적 일관성 검증(verifier) 통합** 방향으로 발전할 것으로 보인다.  
- 외부 도메인(수학, 전기·전자 등) 추론 역량을 강화하여 다중 전문 분야 코드 생성 지원이 가능하다.  
- FIM·멀티파일 패킹의 자동화 파이프라인 정교화로 대규모 리포지토리 이해도를 높이는 연구가 필요하다.  

이상으로 CodeGemma의 핵심 기여와 연구 의의를 요약하였다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/14b637ac-11bb-4512-abc9-7417b886f82c/2406.11409v2.pdf)
