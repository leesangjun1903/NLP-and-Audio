# LIMA: Less Is More for Alignment

## 핵심 주장 및 주요 기여  
**주장:** 대규모 언어 모델의 지식과 능력은 사전학습(pretraining) 단계에서 거의 완전히 학습되며, 추가적인 정교한 정렬(alignment)에는 극히 적은 수(1,000개)의 고품질 예시만으로도 충분히 높은 성능을 달성할 수 있다.[1]
**주요 기여:**  
- 65B 파라미터 LLaMa 모델을 1,000개의 엄선된 데모로만 지도학습(fine-tuning)하여 GPT-4 대비 43%에서는 동등하거나 우수한 성능을 보임을 실험적으로 입증.[1]
- 대규모 RLHF나 수십만 개 이상의 예시 없이도 인간-선호도 기반 정렬 기법과 동등한 결과를 얻을 수 있음을 보임.  
- 데이터 **다양성(diversity)**와 **품질(quality)**의 중요성을 강조하고, 단순 예시 수(quantity) 증가만으로는 성능 향상에 한계가 있음을 제시.  
- 30개의 대화 예시만 추가해도 제로샷 대화 성능이 대폭 개선됨을 실증, 사전학습된 모델이 대화 능력을 이미 내재하고 있음을 시사.[1]

## 문제 정의  
- **정렬(alignment)의 비용 문제:** 기존 방식은 수백만~수천만 개 예시와 RLHF를 필요로 하여 막대한 계산·인력 비용이 소요됨.  
- **질보다 양:** 대규모 예시 수집·처리에 따른 효율성 한계 및 품질 관리 부담.  

## 제안 방법  
1. **데이터 수집:**  
   - 커뮤니티 Q&A(200 STEM, 200 기타 Stack Exchange; 200 wikiHow; 150 WritingPrompts) 및 저자 수작업 예시(250개) 등 총 1,000개 예시를 엄선.[1]
2. **모델 구조:**  
   - 기본 모델: 65B LLaMa  
   - 특수 종결 토큰(EOT) 도입으로 사용자/어시스턴트 구분  
3. **학습 설정:**  
   - 옵티마이저: AdamW(β₁=0.9, β₂=0.95, weight decay=0.1)  
   - 학습률: 1e⁻⁵ → 1e⁻⁶ linear decay  
   - 배치 크기: 32, 최대 토큰 길이: 2,048, 15 epoch fine-tuning  
   - Residual dropout: 하부 0.0 → 상부 0.3 선형 증가  
4. **평가:**  
   - 300개 테스트 프롬프트에 대해 GPT-4, Claude, Bard, DaVinci003, Alpaca와 비교한 인간 선호도 평가 수행.[1]

## 성능 향상 및 한계  
| 비교 대상    | LIMA 우세 비율 | 동등 비율 | LIMA 열위 비율 |
|-------------|---------------|----------|---------------|
| GPT-4       | 19%           | 15%      | 66%           |
| Claude      | 14%           | 23%      | 63%           |
| Bard        | 27%           | 26%      | 47%           |
| DaVinci003  | 54%           | 23%      | 23%           |
| Alpaca 65B  | 64%           | 19%      | 17%           |  

- **우수 응답 비율:** 절반 이상의 테스트에서 ‘우수(Excellent)’ 등급.[1]
- **데이터 양의 한계:** 동일한 소스에서 예시 수를 2,000 → 32,000개로 늘려도 성능 정체.[1]
- **데이터 다양성·품질의 효과:**  
  - 다양성 높은 Stack Exchange(필터링된) vs. 다양성 낮은 wikiHow: Stack Exchange가 유의미하게 우수.[1]
  - 필터링 전/후 비교: 품질 필터링된 데이터가 +0.5점 향상.[1]
- **한계:**  
  - 소규모 정렬 예시 기반이므로 제품 수준의 견고함에는 미치지 못함.  
  - 드문 확률적 생성 실패 및 adversarial prompt에 취약.  

## 일반화 성능 향상 가능성  
- **제로샷 대화 능력:** 1,000개 단일턴 예시만으로도 45% 수준의 ‘Excellent’ 대화 유지.[1]
- **소수 대화 예시 추가:** 30개의 다중턴 대화 예시로 ‘Excellent’ 비율 76%로 대폭 상승.[1]
- **아웃오브디스트리뷰션 일반화:** 학습 예시에 없는 구조(format)나 주제에서도 45% ‘Excellent’, 35% ‘Pass’로 양호한 성능 유지.[1]
- **구조 제약 대응력:** 포맷 요구(bullet, plan 등)에 대한 6개 추가 예시만으로 복잡 구조를 충족하는 답변 생성 가능.[1]

## 향후 연구 영향 및 고려사항  
- **영향:**  
  - 정렬 과정의 경제성을 혁신적으로 개선, 대형 모델 개발 비용·시간 절감 가능성.  
  - 소량의 고품질 예시로도 사용자 상호작용 스타일을 효과적으로 학습시키는 패러다임 제시.  
- **고려사항:**  
  - **데이터 설계 자동화:** 소수 고품질 예시를 효율적으로 생성하거나 증강하는 방법 연구 필요.  
  - **견고성 강화:** 소수 예시 기반 정렬의 불안정성을 완화하기 위한 안정화 기법(예: adversarial training) 개발.  
  - **윤리·안전성 확보:** 소수 안전 예시만으로는 일부 악의적 요청 차단 한계가 있으므로, 안전성 테스트 확대 및 정책적 보완 필요.[1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/283074f2-5168-4489-a896-39d2eaa180db/2305.11206v1.pdf)
