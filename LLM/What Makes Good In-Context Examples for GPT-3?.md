# What Makes Good In-Context Examples for GPT-3?

**핵심 주장 및 주요 기여**  
GPT-3의 성능은 *in-context* 예시 선택에 크게 의존하며, 무작위 샘플링보다 **테스트 샘플과 의미적으로 유사한** 예시를 선택할 때 성능이 일관되게 향상된다. 이 논문의 주요 기여는 다음과 같다:[1]
- **감도 분석**: 서로 다른 in-context 예시가 GPT-3 성능에 미치는 민감도를 최초로 체계적으로 분석  
- **KATE 알고리즘 제안**: k-최근접 이웃(kNN) 기반의 in-context 예시 선택 기법(KnN-augmented in-conText Example selection, KATE)  
- **Fine-tuned 임베딩 활용**: NLI/STSB 등 유관 태스크로 fine-tuning된 문장 인코더를 사용하면 추가 성능 향상  
- **광범위 검증**: 감정 분석, 테이블-텍스트 생성, 오픈도메인 QA 등 다양한 태스크에서 GPT-3의 few-shot 성능을 대폭 개선  

***

## 1. 해결하려는 문제  
GPT-3는 소수의 데모를 제공하는 *few-shot* 설정에서 강력하나, **어떤 예시를 선택하느냐에 따라** 결과가 크게 달라지는 불안정성이 있다.[1]
- 무작위 선택 시 성능 편차가 큼 (SST-2 감정분석 정확도: 86.9–95.8%)[1]
- 모든 조합을 탐색하는 브루트포스는 계산 비용상 비현실적  

***

## 2. 제안 방법: KATE  
### 2.1 절차 개요  
1. **문장 임베딩**: RoBERTa-large 또는 fine-tuned RoBERTa로 훈련/테스트 샘플을 벡터화  
2. **유사도 계산**: 테스트 벡터 $$v_{test}$$ 와 훈련 벡터 $$v_i$$ 간 유사도 $$s_i$$ 계산  

$$
     s_i = \cos(v_{test}, v_i)
   $$  

3. **kNN 선택**: 상위 $$k$$개 예시 $$\{(x_{\sigma(1)},y_{\sigma(1)}),…,(x_{\sigma(k)},y_{\sigma(k)})\}$$ 을 선별  
4. **컨텍스트 구성**:  

$$
     C = [x_{\sigma(1)},y_{\sigma(1)},…,x_{\sigma(k)},y_{\sigma(k)}]
   $$  

5. **GPT-3 예측**: $$\hat y = \text{GPT-3}([C; x_{\text{test}}])$$  

### 2.2 수식 요약  
- **조건부 생성 확률**  

$$
    p_{\text{LM}}(y \mid C, x)
    = \prod_{t=1}^{T} p(y_t \mid C, x, y_{ < t})
  $$  

- **유사도 기반 정렬**  

$$
    \text{예시 A가 B보다 유사도가 높으면, A가 B 앞에 위치}
  $$  

***

## 3. 모델 구조 및 임베딩  
- **기반 인코더**: RoBERTa-large  
- **Fine-tuning**:  
  - NLI (SNLI+MultiNLI) → KATE$$_{\text{nli}}$$  
  - NLI + STS-B → KATE$$_{\text{nli+sts}}$$  
  - SST-2 감정분석 → KATE$$_{\text{sst2}}$$  

이 중 **태스크 유사도**가 높은 SST-2 fine-tuned 임베딩이 감정분석에서 최고 성능을 보임.[1]

***

## 4. 성능 향상 및 한계  
| 태스크             | Random   | KATE$$_{\text{roberta}}$$ | KATE$$_{\text{nli+sts}}$$ | 최대 향상  |
|--------------------|---------:|-------------------------:|--------------------------:|-----------:|
| Sentiment (IMDB)   | 87.95%   | 91.99%                   | 90.20%                    | +5.48%     |
| Table-to-Text (BLEU)| 28.4     | 40.3                     | 38.1                      | +11.9      |
| QA (NQ EM)         | 28.6%    | 40.0%                    | 41.6%                     | +13.0%     |

- **일관된 개선**: 모든 태스크에서 무작위 대비 평균 10% 이상 향상  
- **Retrieval 크기 효과**: 훈련셋 크기 및 in-context 예시 수 증가 시 성능 지속 상승  
- **제한점**:  
  - **임베딩 품질 의존**: dissimilar 태스크로 fine-tune 시 오히려 성능 저하  
  - **순서 민감도**: 예시 나열 순서에 따라 소폭 변동 (데이터셋별 최적 순서 탐색 필요)  

***

## 5. 일반화 성능 향상 가능성  
- **유사도 기반 예시 선택**이 GPT-3의 **지식 전이 능력**을 극대화, 특히 out-of-domain 상황에서도 성능 유지  
- **태스크 간 전이 설정**(예: SST-2→IMDB)에서 fine-tuned 인코더 활용 시, 레이블이 다른 도메인에도 일반화 가능함을 확인  
- 더 높은 차원의 embedding space 탐색 및 **multi-hop retrieval** 확장으로 일반화 가능성 제고  

***

## 6. 향후 연구 영향 및 고려사항  
- **대규모 언어모델 활용 최적화**: in-context 예시 자동화 선택 모듈 연구 확대  
- **자기지도학습 결합**: retrieval 편향 보정 및 증강학습 기법 통합  
- **인코더 다변화**: 다중 임베딩 소스(대화, 요약 등) 활용으로 더욱 *robust* 한 예시 선택  
- **학습 효율**: 적은 예시 수에서도 최대 성능 달성하는 **샘플 효율성** 연구  

이 연구는 GPT-3뿐 아니라 향후 등장할 대규모 언어모델의 *few-shot* 학습 안정성과 일반화 성능 개선에 핵심 인사이트를 제공한다.[1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/497e5949-a30f-48ac-8717-5da54a5ccb93/2101.06804v1.pdf)
