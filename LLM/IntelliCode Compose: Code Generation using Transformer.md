# IntelliCode Compose: Code Generation using Transformer | 2020 · 677회 인용

## 1. 핵심 주장과 주요 기여

IntelliCode Compose는 전통적인 IDE의 메서드/API 완성 기능을 넘어서 **전체 코드 라인을 생성할 수 있는 범용 다국어 코드 완성 시스템**입니다. 이 논문의 핵심 기여는 다음과 같습니다:[1]

**GPT-C(Generative Pre-trained Transformer for Code) 모델 개발**: GPT-2의 변형으로, Python, C#, JavaScript, TypeScript 4개 언어로 구성된 12억 줄의 소스 코드에서 처음부터 사전 학습된 다층 생성 트랜스포머 모델입니다. 최고 성능 모델은 Python에서 평균 편집 유사도(edit similarity) 86.7%, 퍼플렉시티(perplexity) 1.82를 달성했습니다.[1]

**MultiGPT-C 다국어 모델**: 저자원(low-resource) 프로그래밍 언어가 인기 있는 언어의 혜택을 받을 수 있도록 하는 다국어 접근법을 제시했습니다. 특히 JavaScript와 TypeScript에서는 단일 언어 모델보다 모든 메트릭이 향상되었습니다.[1]

**프로덕션 배포를 위한 엔지니어링 최적화**: 클라이언트 측 트리 기반 캐싱, 병렬 빔 서치 디코더 구현, 컴퓨트 그래프 최적화를 통해 Visual Studio Code IDE에서 100ms 이내의 실시간 완성 요구사항을 충족했습니다.[1]

## 2. 해결하고자 하는 문제와 제안 방법

### 문제 정의

기존 코드 완성 시스템들은 메서드/API 호출이나 인자 완성에만 집중하며, 메서드 이름이 이미 입력된 상태에서만 작동합니다. 이는 개발자가 여전히 메서드 호출을 수동으로 완성해야 하는 한계를 가집니다. 또한 특정 토큰 타입에만 초점을 맞춰 주변 컨텍스트의 전체적인 이해가 부족합니다.[1]

### 제안 방법

**언어 모델링 접근법**: 통계적 언어 모델링을 기반으로, 기존 코드 컨텍스트 $$C$$와 어휘 $$V$$가 주어졌을 때 전체 소스 코드 토큰 라인을 예측하도록 신경망 모델을 학습시킵니다.[1]

**조건부 확률 모델링**: 개발자가 입력한 코드 스니펫 $$\{c_t\}, t=0...T$$가 주어졌을 때, 응답 토큰 시퀀스 $$M = \{m_t\}, t=0...N$$을 예측하기 위해 다음 조건부 확률 분포를 추정합니다:[1]

$$P(m_0, m_1, ..., m_N | c_0, ..., c_T) = \prod_{i=1}^{N} P(m_i | c_0, c_1, ..., c_T, m_0, ..., m_{i-1})$$

**자기회귀(Autoregressive) 목적 함수**: 다음의 로그 우도를 최대화합니다:[1]

$$L(M) = \sum_i \log P(m_i | c_0, c_1, ..., c_T, m_{i-k}, m_{i-k+1}, ..., m_{i-1}; \Theta)$$

여기서 $$k$$는 예측된 코드 시퀀스의 길이이고, 조건부 확률 $$P$$는 매개변수 $$\Theta$$를 가진 신경망으로 모델링됩니다.[1]

### 모델 구조

**Transformer 아키텍처**: GPT-C는 멀티헤드 셀프 어텐션과 위치별 피드포워드 레이어를 적용합니다:[1]

$$h_0 = W_e \cdot C + W_p$$

```math
h_l = \text{transformer\_block}(h_{l-1}), \forall l = 1...n
```

$$P(m_t) = y_t = \text{softmax}(h_n \cdot W_e^T), t = 0...N$$

여기서 $$W_e \in \mathbb{R}^{|V| \times d_x}$$는 토큰 임베딩 행렬, $$W_p \in \mathbb{R}^{N_{ctx} \times d_x}$$는 위치 임베딩 행렬입니다[1].

**Weight Tying**: 입력 토큰 임베딩 행렬을 출력 분류 행렬로 재사용하여 파라미터를 25% 감소시켰습니다. 투영 행렬 $$A \in \mathbb{R}^{d_{model} \times d_x}$$를 도입하여 예측된 토큰 임베딩 벡터를 다음과 같이 계산합니다:[1]

$$w_j^{pred} = \sum_i h_{ni}(T) a_{ij}$$

로짓은 다음과 같이 얻어집니다:[1]

$$y_k = \sum_j w_{kj} w_j^{pred} + b_k$$

**모델 하이퍼파라미터**: 최고 성능의 단일 언어 GPT-C 모델은 24개 레이어, 16개 헤드의 스케일드 닷 프로덕트 어텐션, BPE 어휘 크기 50,000을 사용합니다. 다국어 버전은 26개 트랜스포머 레이어, 16개 헤드, 어휘 크기 60,000 서브토큰을 사용합니다. 은닉 유닛은 레이어당 1024개, 코드 컨텍스트 길이 1024, 임베딩 차원 1024, 드롭아웃 확률 0.9를 적용했습니다.[1]

## 3. 일반화 성능 향상

### BPE 토큰화를 통한 어휘 문제 해결

폐쇄 어휘(closed vocabulary) 문제를 극복하기 위해 **Byte-Pair Encoding(BPE)** 서브토큰 레벨 어휘를 추출했습니다. 이는 각 토큰에 대한 표현을 학습하는 대신 서브토큰이나 유니코드 문자 조합에 대한 표현을 학습하여, 전체 어휘를 저장할 필요성을 줄이고 모델을 어휘 외 토큰에 더 견고하게 만듭니다. 이를 통해 이전에 보지 못한 메서드, API, 언어 식별자에 대해서도 일반화할 수 있으며, 여러 프로그래밍 언어에 대한 코드 완성 모델 학습이 가능합니다.[1]

### 다국어 모델을 통한 전이 학습

**언어별 제어 코드(Control Codes)**: 각 프로그래밍 언어에 대해 훈련 샘플 시작 부분에 토큰 시퀀스를 삽입하는 방식으로("lang * remaining token sequence"), 신경망에 특정 프로그래밍 언어 소속을 신호합니다. 이 접근법은 단일 언어 모델과 비슷한 결과를 얻었습니다.[1]

**멀티태스크 학습**: 언어 모델링과 프로그래밍 언어를 감지하는 다중 선택 분류를 결합한 이중 헤드(double heads) 접근법을 적용했습니다. MultiGPT-C는 퍼플렉시티 1.65, ROUGE-L 정밀도 0.66, 재현율 0.76, 편집 유사도 82.1%를 달성했습니다.[1]

**Zero-shot 전이**: Python으로 학습된 모델을 C#에 zero-shot으로 적용했을 때 편집 유사도 57.6%를 기록하여, 언어 간 전이 학습 가능성을 입증했습니다. 이는 WebText로 사전 학습된 HuggingFace GPT-2(34.6%)보다 훨씬 우수합니다.[1]

**JavaScript/TypeScript에서의 성능 향상**: 다국어 모델은 JavaScript와 TypeScript에서 단일 언어 모델 대비 모든 메트릭이 향상되었습니다(편집 유사도 84.1% → 87.6%, ROUGE-L 정밀도 0.58 → 0.68, 재현율 0.72 → 0.82). 이는 저자원 언어가 고자원 언어로부터 혜택을 받을 수 있음을 시사합니다.[1]

### 코드의 자연스러움(Naturalness) 활용

Python에서 최고의 성능을 달성한 이유를 "코드의 자연스러움" 개념으로 설명합니다. 개발자들이 관습적이고 관용적이며 익숙한 코드를 선호하기 때문에 코드 예측 가능성이 높아지며, Python이 가장 인기 있는 프로그래밍 언어로서 더 많은 코드 채택과 재사용이 이루어져 일반화 성능이 향상됩니다.[1]

## 4. 성능 향상 및 한계

### 성능 향상

**단일 언어 모델**: Python에서 편집 유사도 86.7%, 퍼플렉시티 1.82로 n-gram 베이스라인(5-gram: 59.7%)을 크게 상회합니다. C#에서는 편집 유사도 76.8%, JavaScript/TypeScript에서는 84.1%를 달성했습니다.[1]

**다국어 모델**: 다국어 접근법으로 JavaScript/TypeScript에서 87.6%의 편집 유사도를 달성하여 단일 언어 모델보다 3.5% 향상되었습니다.[1]

**구문 정확도**: Python에서 생성된 완성 제안의 93%가 구문적으로 올바르며, tree-sitter 파서로 검증되었습니다.[1]

**온라인 평가**: 내부 배포에서 surfacing rate(SR) 9.2%, click-through rate(CTR) 10%를 기록했으며, 이는 약 11글자마다 제안이 표시되고 사용자가 커밋함을 의미합니다.[1]

**지식 증류(Knowledge Distillation)**: 26레이어 모델을 12레이어로 증류하면 추론 속도가 2.7배 향상되며 편집 유사도는 6% 손실됩니다. 8레이어로 증류하면 4.5배 속도 향상에 8% 유사도 손실이 발생합니다.[1]

### 한계점

**C# 다국어 성능 저하**: MultiGPT-C는 C#에서 ROUGE-L 재현율이 단일 언어 모델보다 크게 낮습니다(0.79 → 0.66). 이는 다국어 학습이 모든 언어에서 균일하게 이익을 주지 않음을 보여줍니다.[1]

**낮은 CTR**: 10%의 CTR은 타이핑의 모멘텀 효과로 인해 개발자가 모든 키 입력 후 제안을 검토하지 않기 때문이라고 설명합니다. 전통적인 코드 완성 시나리오와 유사하게, 사용자는 원하는 제안을 커밋하기 전에 몇 글자를 더 입력하는 경향이 있습니다.[1]

**부분 문장 생성**: 라인 단위 완성이 부분 코드 문장을 나타낼 수 있으며, tree-sitter로 파싱에 실패한 제안의 약 절반이 부분 생성된 문장에 기인합니다.[1]

**구조적 정보 미활용**: AST, CST, 제어 흐름 그래프 같은 고수준 구조적 표현을 활용하지 않았습니다. 이는 추가적인 오버헤드와 의존성을 도입하여 추론 속도를 느리게 하고 커버리지를 감소시키기 때문이며, 대부분의 프로그래밍 언어에서 이러한 표현은 구문적으로 올바른 완전한 코드 스니펫에서만 정확하게 검색 가능하지만 코드 완성 시스템에서는 종종 사용할 수 없습니다.[1]

**민감 데이터 노출 위험**: 대규모 공개 데이터 수집 시 민감 정보가 포함될 수 있는 문제를 해결하기 위해 숫자/문자열 리터럴과 주석을 특수 토큰으로 정규화했으나, 식별자 이름은 컨텍스트 의존적 제안을 위해 남겨두었습니다.[1]

## 5. 향후 연구에 미치는 영향 및 고려 사항

### 연구에 미치는 영향

**대규모 사전 학습의 코드 도메인 적용**: NLP의 성공을 코드 이해 분야로 확장하여, GPT-2 같은 트랜스포머 모델이 구조적 제약과 어휘 정보, AST/CST 없이도 효과적으로 작동할 수 있음을 입증했습니다.[1]

**다국어 코드 모델링의 선구적 연구**: 4개 프로그래밍 언어에 대한 다국어 모델링 접근법을 체계적으로 비교하여, 제어 코드와 멀티태스크 학습이 효과적임을 보였습니다. 이는 저자원 프로그래밍 언어 지원을 위한 기반을 마련했습니다.[1]

**프로덕션 배포 실용성**: HPC 클러스터에서 중간 크기 트랜스포머 모델을 학습하고, 클라우드 기반 배포에서 100ms 이내 실시간 응답을 달성하는 실용적 도전 과제들을 문서화했습니다. 병렬 빔 서치와 클라이언트 측 캐싱 전략은 실시간 AI 시스템 설계에 참고 자료가 됩니다.[1]

### 향후 고려 사항

**완성 개인화(Personalization)**: 저자들은 향후 사용자 맞춤형 코드에 대한 파인튜닝을 통해 완성 개인화에 집중할 계획입니다.[1]

**자동 프로그램 수정(Automatic Program Repair)**: 대규모 비지도 언어 모델 사전 학습을 코드 검색, 자동 프로그램 수정 등 다른 자동화된 소프트웨어 엔지니어링 작업에 적용할 계획입니다.[1]

**AST/CST 통합 연구**: 구조적 표현을 활용하지 않은 것이 한계로 언급되므로, 추론 속도와 정확도 사이의 균형을 맞추면서 구문 트리 정보를 통합하는 하이브리드 접근법 연구가 필요합니다.

**컨텍스트 길이 확장**: 현재 1024 토큰의 컨텍스트 길이를 확장하여 더 긴 범위의 코드 의존성을 이해하면 성능이 향상될 수 있습니다.

**다중 모달 학습**: 코드와 함께 자연어 문서, 이슈 트래커, 코드 리뷰 등을 활용한 다중 모달 학습으로 일반화 성능을 더욱 향상시킨 수 있습니다.

**편향 및 공정성**: GitHub에서 수집된 대규모 데이터셋은 특정 코딩 스타일, 프레임워크, 커뮤니티 관습에 대한 편향을 포함할 수 있으므로, 모델의 공정성과 다양성을 확보하기 위한 연구가 필요합니다.

**효율적인 모델 압축**: 지식 증류 외에도 양자화, 프루닝, 희소 어텐션 등의 기법을 적용하여 엣지 디바이스나 로컬 IDE에서도 실행 가능한 경량 모델 개발이 중요합니다.

이 논문은 코드 생성 분야에서 트랜스포머 기반 접근법의 실용성을 입증하고, 다국어 학습과 프로덕션 배포의 실질적 과제들을 해결하여 향후 AI 지원 소프트웨어 개발 도구 연구에 중요한 기여를 했습니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/dfb794cc-8fa5-4cdc-8b98-e3b82c5fd2f9/2005.08025v2.pdf)
