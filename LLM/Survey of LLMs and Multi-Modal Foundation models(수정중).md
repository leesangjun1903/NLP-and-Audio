Source : https://wikidocs.net/237535

LLM(대형 언어 모델), ViT(비전 트랜스포머), 확산 및 LLM 기반 다중 모달 모델을 포함한 대규모 기반 모델은 교육부터 배포까지 전체 기계 학습 수명 주기를 혁신하고 있습니다.  
그러나 이러한 모델이 제공하는 다양성과 성능의 실질적인 향상은 하드웨어 리소스 측면에서 상당한 비용을 초래합니다.  
확장 가능하고 환경적으로 지속 가능한 방식으로 이러한 대규모 모델의 성장을 지원하기 위해 자원 효율적인 전략을 개발하는 데 상당한 초점이 맞춰져 왔습니다.  
이 설문 조사에서는 알고리즘 측면과 시스템 측면을 모두 조사하여 이러한 연구의 중요성을 자세히 조사합니다.  
최첨단 모델 아키텍처와 훈련/제공 알고리즘부터 실제 시스템 설계 및 구현에 이르기까지 광범위한 주제를 포괄하는 기존 문헌에서 수집한 포괄적인 분석과 귀중한 통찰력을 제공합니다.  
이 설문 조사의 목표는 현재 접근 방식이 대규모 기초 모델로 인해 발생하는 리소스 문제를 어떻게 다루고 있는지에 대한 포괄적인 이해를 제공하고 잠재적으로 이 분야의 미래 혁신에 영감을 주는 것입니다.

# Introduction
빠르게 진화하는 인공지능(AI) 분야에서는 패러다임의 전환이 진행되고 있습니다.  
우리는 전문화되고 단편화된 딥 러닝 모델에서 다용도의 단일 크기 기반 모델로의 전환을 목격하고 있습니다.  
이러한 고급 AI 시스템은 개방형 환경에서 작동할 수 있으며, 보이지 않는 AI 작업(예: 제로샷 능력)을 위해 개방형 어휘 및 이미지 픽셀과 상호 작용할 수 있습니다.  
그들은 다음과 같이 예시됩니다:  
(1) 거의 모든 NLP 작업을 프롬프트 형식으로 수집할 수 있는 GPT와 같은 LLM(대형 언어 모델);  
(2) 다양한 다운스트림 비전 작업을 처리할 수 있는 Masked Autoencoder와 같은 ViT(Vision Transformers Model);  
(3) 임의의 텍스트 기반 프롬프트로 고품질 이미지를 생성하는 Stable Diffusion과 같은 LDM(Latent Diffusion Model);  
(4) 서로 다른 모달 데이터를 동일한 잠재 공간에 매핑하고 이미지 검색/검색 및 시각적 질문 응답과 같은 교차 양식 작업을 위한 백본으로 널리 사용되는 CLIP 및 ImageBind와 같은 다중 모드 모델입니다.  
이러한 유연성과 일반성은 AI의 초기 시대로부터의 중요한 출발을 의미하며 AI가 세상과 인터페이스하는 방식에 대한 새로운 표준을 설정합니다.

이러한 기반 모델의 성공은 확장성에 뿌리를 두고 있습니다.  
이전 모델과 달리 이러한 모델의 정확성과 일반화 능력은 기본 단순 알고리즘 및 아키텍처를 변경하지 않고도 더 많은 데이터 또는 매개변수를 통해 지속적으로 확장될 수 있습니다.  
인상적인 증거는 확장 법칙입니다:  
이는 더 많은 모델 크기와 데이터 볼륨으로 트랜스포머 기반 모델의 성능이 어떻게 예측 가능하게 향상될 수 있는지 설명합니다.  
오늘날까지 스케일링 법칙은 여전히 유효합니다.  
이러한 확장성은 단지 모델 크기의 문제가 아닙니다.  
이는 점점 더 복잡해지는 작업을 처리하는 능력까지 확장되어 인공 일반 지능(AGI / artificial general intelligence)을 향한 여정의 초석이 됩니다.

![](https://wikidocs.net/images/page/236764/Fig_01.PNG)

그러나 확장성은 막대한 리소스 수요를 초래합니다. 기본 모델은 본질적으로 교육 및 배포에 리소스를 많이 사용합니다.  
이러한 리소스에는 GPU 및 TPU와 같은 컴퓨팅 프로세서뿐만 아니라 메모리, 에너지 및 네트워크 대역폭도 포함됩니다.  
Meta AI에 따르면 교육 외에도 데이터 처리, 실험 및 추론 단계에서는 이와 비슷하거나 더 많은 전력을 소비합니다.  
최근 분석에 따르면 AI 용량 및 채택에 대한 현재 추세의 지속을 충족하기 위해 NVIDIA는 2027년까지 연간 150만 대의 AI 서버 장치를 출시해야 합니다.  
전체 용량으로 실행되는 이러한 서버는 최소 85.4테라와트시를 소비합니다.  
연간 전력량은 그림 1에서 볼 수 있듯이 뉴질랜드 및 오스트리아와 같은 많은 국가에서 연간 사용하는 것보다 많습니다.  
기초 모델은 크기와 복잡성이 증가하기 때문에, 리소스 요구 사항이 기하급수적으로 증가하여 개발 및 배포에 심각한 문제를 야기하는 경우가 많습니다.  

대규모 기반 모델의 막대한 자원 발자국도 민주화를 방해합니다.  
2023년 말까지 최첨단 기반 모델을 훈련하고 배포할 수 있는 주요 플레이어는 소수에 불과하며, 이를 통해 대중에 대한 강력한 통제력을 갖고 잠재적으로 원하는 방식으로 조작할 수 있습니다.  
모델은 많은 경량 DNN처럼 장치 대신 클라우드에서 제공됩니다.  
이는 데이터 프라이버시 보호를 거의 불가능하게 만듭니다.  
최근 스마트폰 공급업체는 대규모 기반 모델을 로컬에서 실행하고 일부 선구적인 엔진이 온디바이스 LLM용으로 개발되었지만 시연된 모델은 상대적으로 작은 규모(예: <10B)로 제한되어 아직 실제 배포를 본 적이 없습니다.  

따라서 이러한 기초 모델의 효율성을 높이기 위해 상당한 양의 연구가 이루어졌습니다.  
이러한 노력은 알고리즘 최적화부터 시스템 수준 혁신까지 광범위한 접근 방식을 포괄하며 성능 저하 없이 이러한 모델의 리소스 공간을 줄이는 데 중점을 두고 있습니다.  
이 Survey의 목적은 이러한 연구 노력을 조사하고 기초 모델을 보다 자원 효율적으로 만들기 위해 사용된 다양한 전략을 탐색하는 것입니다.  
우리는 알고리즘 효율성, 시스템 최적화, 데이터 관리 기술 및 리소스 집약도가 낮은 새로운 아키텍처 개발의 발전을 검토할 것입니다.  
또한 Survey는 클라우드부터 엣지 및 장치까지 포괄하며, 대규모 기반 모델도 큰 주목을 받습니다.  
이러한 탐구를 통해 우리는 기초 모델 영역에서 자원 효율적인 알고리즘과 시스템의 현재 상태와 미래 방향에 대한 포괄적인 이해를 제공하는 것을 목표로 합니다.

## Scope and rationales. 
본 Survey의 범위는 주로 다음과 같은 측면으로 정의된다.  
(i) 우리는 알고리즘과 시스템 혁신만을 조사합니다. 우리는 똑같이 중요하지만 이미 잘 마무리된 하드웨어 설계의 엄청난 양의 작업을 제외합니다.  
(ii) 본 Survey에서 리소스의 정의는 주로 컴퓨팅, 메모리, 스토리지, 대역폭 등을 포함한 물리적 리소스로 제한됩니다. 리소스로 간주될 수 있는 훈련 데이터(라벨) 및 개인 정보 보호는 제외됩니다.  
(iii) 우리는 CSRankings에 포함된 상위 CS 컨퍼런스에 발표된 논문을 주로 조사합니다. 또한 arXiv에서 관련성이 있고 잠재적으로 영향력이 큰 논문을 수동으로 선택합니다.  
(iv) AI의 혁신이 빠르게 진행되고, 오래된 지식과 방법이 자주 뒤집히기 때문에 2020년 이후 발표된 논문을 주로 조사합니다.  

![](https://wikidocs.net/images/page/236764/Fig_03_a.PNG)
![](https://wikidocs.net/images/page/236764/Fig_03_b.PNG)

# Foundation Model Overview 

## Language Foundation Models  
### Transformer pipeline. 
Vaswani et al.은 대부분의 대형 FM 개발의 기본 요소인 어텐션 기반 트랜스포머 아키텍처를 소개했습니다.  
그림 3에 표시된 것처럼 프로세스는 임베딩 레이어를 통해 입력 단어를 고차원 벡터로 변환하여 시작됩니다.  
처리하는 동안 어텐션 메커니즘은 이러한 입력 벡터의 서로 다른 세그먼트에 다양한 가중치를 할당합니다.  
어텐션을 기울여 레이어 정규화가 출력에 적용되어 활성화의 안정화 및 표준화가 보장됩니다.  
그 후, 각 위치별 벡터는 피드포워드 네트워크를 통해 변환되어 비선형성을 도입하고 모델이 복잡한 데이터 패턴을 캡처할 수 있게 됩니다.  
트랜스포머는 이러한 구성 요소를 통합하는 여러 레이어를 통해 입력 데이터의 계층적 표현을 학습합니다.  
마지막 단계에서는 마지막 트랜스포머 레이어의 출력이 선형 레이어로 전달되어 최종 예측이 됩니다.  
다음과 같이 Large FM의 주요 구성 요소를 간략하게 설명합니다:

### Embedding. 
처음에 입력 단어는 토크나이저에 의해 일련의 토큰으로 변환됩니다.  
wordpiece 및 byte-pair encoding과 같이 일반적으로 사용되는 토크나이저가 이 프로세스에 자주 사용됩니다.  
토큰화 후에 학습된 임베딩 레이어는 이러한 토큰을 일련의 벡터로 변환합니다.  
이러한 순서에서는 단어의 순서가 의미에 필수적입니다.  
이 문제를 해결하기 위해 위치 인코딩이 임베딩에 통합되어 위치 정보를 주입합니다.  
이러한 추가는 입력의 순차적 특성을 캡처하여 모델이 단어 순서와 문맥을 정확하게 해석하도록 보장하는 데 중요합니다.

### Attention. 
어텐션 메커니즘은 순서대로 단어 간의 관계를 포착하는 데 중요한 역할을 합니다. 어텐션 계산은 다음과 같이 표현될 수 있습니다:

$A(Q,K,V) = \text{softmax} \left( \frac{QK^T}{\sqrt{d_k}} \right) V \tag{1}$

여기서 Q, K, V 는 쿼리, 키 및 값을 나타냅니다.  
각각은 입력 벡터에 개별 가중치 행렬을 곱하여 파생되며 $d_k$ 는 이러한 벡터의 차원을 나타냅니다.  
쿼리, 키 및 값이 모두 동일한 입력 시퀀스에서 발생하는 특정 형태의 어텐션인 셀프 어텐션을 통해 모델은 각 위치에 대한 입력의 서로 다른 세그먼트에 집중할 수 있습니다.  
대조적으로, self-attention의 변형인 multi-head attention은 서로 다른 위치에 있는 다양한 표현 하위 공간의 정보에 동시에 어텐션을 기울일 수 있게 해줍니다.  
희소 어텐션 및 다중 쿼리 어텐션과 같은 다른 변형은 효율성 또는 다양한 다운스트림 작업에 맞게 조정되었습니다. 

### Encoder-decoder architecture. 
표준 Transformer 아키텍처는 인코더와 디코더라는 두 가지 주요 구성 요소로 구성됩니다.  
인코더는 self-attention 메커니즘을 통해 입력 시퀀스를 처리하므로 모델은 상대적 중요도에 따라 입력 시퀀스의 여러 세그먼트에 다양한 가중치를 할당할 수 있습니다.  
이 특성은 입력 데이터 내에서 복잡한 패턴과 종속성을 식별하는 데 중요합니다. 대조적으로, 디코더는 출력 시퀀스 생성을 담당합니다.  
디코더는 self-attention 메커니즘을 활용하여 지금까지 생성된 출력 내의 관계를 이해합니다.  
또한 디코더는 교차 어텐션 메커니즘을 통합하여 입력 시퀀스에 초점을 맞춰 출력 시퀀스의 각 토큰에 대한 관련 정보를 추출합니다.  
아키텍처의 이 부분은 자동 회귀적이며 토큰을 순차적으로 생성합니다.  
각 토큰의 생산은 인코더의 병렬 처리 방식과 달리 이전에 생성된 토큰에 따라 달라집니다.

### Auto-regressive decoding and KV cache.
자동 회귀 디코딩에서 디코더 함수 $F_{Decoder}$ 는 입력 토큰 시퀀스 $X = \{ x_1, x_2, ..., x_i \}$ 에서 새로운 토큰 $x_{i+1}$를 추론합니다.  
이후 다음 추론 단계를 위해 $x_{i+1}$가 $X$에 추가되어 자동 회귀 디코딩을 구성합니다.  
KV(Key-Value) 캐시는 각 단계에서 어텐션 메커니즘의 중간 상태를 저장하여 효율성을 향상시킵니다.  
이 접근 방식은 이전 단계에서 처리된 토큰을 다시 계산하는 것을 방지합니다.  
재계산을 완화하는 동안 KV 캐시는 §2.1.3에 자세히 설명된 추가 스토리지 또는 메모리 오버헤드를 도입합니다.

## Representative Models and Downstream Tasks  
### Encoder-only FMs. 
BERT는 사전 훈련 중에 양방향 마스크 언어 모델링 접근 방식을 활용하는 인코더 전용 Transformer 모델입니다.  
이 접근 방식에서는 문장 내의 임의의 단어가 마스킹되고, 모델은 문맥상의 단서를 고려하여 이러한 마스킹된 단어를 예측하는 방법을 학습합니다.  
다양한 다운스트림 작업에 대해 BERT를 미세 조정하면 특히 감정 분석 및 텍스트 분류와 같은 식별 작업에서 SOTA 성능이 향상됩니다.  
DistilBERT는 BERT의 증류된 버전으로, 40% 더 작고 60% 더 빠르면서도 BERT의 언어 이해 능력의 97%를 유지합니다.  
RoBERTa는 훈련 기간 연장, 배치 크기 증가, 더 큰 데이터 코퍼스 등 강력한 최적화 기술을 통해 BERT의 효율성을 향상시킵니다.  
Sentence-BERT는 BERT를 수정하여 의미상 의미 있는 문장 임베딩을 생성합니다.  
샴(siamese) 및 삼중항(triplet) 네트워크 구조를 사용하면 이러한 임베딩을 코사인 유사성을 사용하여 직접 비교할 수 있습니다.  
이 모델은 문장 임베딩을 전문으로 하는 널리 사용되는 문장 트랜스포머 도구로 발전했습니다.

### Encoder-decoder FMs. 
T5는 인코더-디코더 아키텍처를 사용하고 자체 감독되며 C4 데이터 세트에 대한 사전 교육을 받습니다.  
이 모델은 다양한 텍스트 기반 언어 문제를 텍스트 대 텍스트 형식으로 변환하여 요약 및 질문 답변과 같은 작업에 적용할 수 있는 통합 프레임워크를 도입합니다.  
BART는 사전 훈련 단계에서 노이즈 제거 자동 인코더 역할을 하며 임의의 노이즈 기능을 통해 텍스트에 손상을 입힙니다. 주요 목표는 원본 텍스트의 재구성을 배우는 것입니다.

### Decoder-only FMs. 
GPT 제품군은 감독되지 않은 훈련을 위해 디코더 전용 아키텍처를 활용합니다.  
시리즈의 첫 번째 모델인 GPT-1은 1억 1,700만 개의 매개변수를 갖춘 트랜스포머 아키텍처를 특성으로 하며 다양한 인터넷 텍스트에 대한 사전 훈련의 효율성을 보여줍니다.  
GPT-1의 확장된 반복인 GPT-2는 수백만 개의 웹페이지를 포함하는 데이터 세트인 WebText에 대한 비지도 학습을 거칩니다.  
GPT-3는 1,750억 개의 매개변수로 모델 크기가 크게 증가하여 확장의 이점을 강조합니다.  
탁월한 제로샷 성능을 보여주었습니다.  
지시 튜닝은 인간의 피드백을 사용하여 지시를 정확하게 따르는 모델의 능력을 더욱 향상시켜 LLaMA를 포함한 여러 오픈 소스 기반 모델 생성에 기여합니다.  
GLM은 2D 위치 인코딩을 추가하고 임의의 순서로 범위를 예측할 수 있도록 하여 공백 채우기 사전 훈련을 개선합니다.  
이를 통해 NLU 작업에서 BERT 및 T5에 비해 성능이 향상됩니다.  
PaLM은 모델 규모가 소수 학습에 미치는 영향을 더 자세히 이해하기 위해 Pathways를 사용하여 6144 TPU v4 칩에서 교육을 받았습니다.  
또한 GPT-4, Claude2 및 PaLM 2를 포함하여 수많은 근접 소스 생성 대형 FM이 있습니다.

### Speech FMs. 
음성 대형 FM은 원시 오디오 신호에서 의미 있는 표현을 도출하도록 설계되었습니다.  
Wav2vec 2.0은 레이블이 지정되지 않은 데이터에서 강력한 음성 표현을 획득하면 후속 음성 관련 작업의 성능이 크게 향상될 수 있음을 처음으로 보여줍니다.  
이러한 모델은 일반적으로 컨벌루션 신경망을 사용하여 직렬 특성을 추출하고 트랜스포머를 사용하여 상황별 정보를 캡처합니다.  
이 접근 방식은 음성 인식 및 음성 언어 이해를 포함한 다양한 다운스트림 작업에 효과적입니다.  
예를 들어 HuBERT는 960시간 LibriSpeech 오디오 데이터 세트에서 훈련된 음성 표현의 자기 지도 학습을 위해 트랜스포머 기반 아키텍처를 활용합니다.  
Whisper는 웹에서 제공되는 680,000시간의 다국어 및 멀티태스킹 감독 데이터로 구성된 방대한 자료에 대해 훈련된 최첨단 오픈 소스 자동 음성 인식 시스템을 나타냅니다.

## Cost Analysis  
그림 4에 표시된 대로 대규모 FM의 주요 구성 요소와 관련된 계산 및 저장 비용을 분석합니다.  
임베딩 구성요소는 스토리지 비용의 상당 부분(전체 비용의 약 25%)을 차지합니다.  
그러나 추론 중에 임베딩은 조회 테이블로 기능하므로 최소한의 계산 비용이 발생합니다.  
FFN 계층은 주로 각 FFN 블록에 두 개의 완전히 연결된 계층이 있기 때문에 가장 계산 집약적인 구성 요소로 나타납니다.  
모델의 출력 레이어를 의미하는 lm head는 작업에 따라 달라집니다.  
BERT와 같은 판별 작업의 경우 소프트맥스 활성화 함수가 있는 분류 계층의 형태를 취하는 반면, GPT/T5와 같은 생성 작업의 경우 선형 계층으로 나타납니다.  
이 구성 요소의 크기는 어휘 크기에 정비례합니다.

![](https://wikidocs.net/images/page/236764/Fig_04.PNG)

## Cost Analysis Under Different Token Lengths. 
대규모 FM의 어텐션 메커니즘은 주로 2차 복잡성으로 인해 상당한 계산 bottleneck에 직면합니다.  
이러한 복잡성은 입력 시퀀스 내의 모든 위치 쌍에 대한 어텐션 점수를 계산하여 긴 시퀀스를 관리하는 데 어려움을 겪고 훈련 및 추론 효율성에 영향을 미치는 데서 비롯됩니다.  
또한 어텐션 메커니즘을 넘어서 FFN의 계산 복잡성은 입력 길이에 따라 선형적으로 확장되지만 모델의 차원에 따라 2차적으로 확장됩니다.  
그림 5에 설명된 것처럼 입력 시퀀스의 길이가 증가하면 어텐션 메커니즘의 2차 특성으로 인해 계산 요구가 크게 증가합니다.  

![](https://wikidocs.net/images/page/236764/Fig_05.PNG)

양적 측면에서, Attention의 계산 복잡도는 $O(T^2D)$ 인 반면 FFN의 계산 복잡도는 $O(TD^2)$ 입니다.  
여기서 T는 시퀀스 길이를 나타내고 D는 모델의 숨겨진 상태 차원을 나타냅니다.  
인코더의 어텐션 메커니즘과 유사한 디코더의 어텐션 메커니즘도 토큰 길이에 따라 2차 스케일링을 경험합니다.  
이러한 측면은 각 토큰의 생성이 이전 토큰에 의존하여 계산 요구 사항을 강화하는 자동 회귀 디코딩 작업에서 특히 중요합니다.  
디코더에서 KV 캐시를 구현하면 다양한 위치에서 키와 값 벡터를 재사용하여 계산 비용을 크게 줄일 수 있습니다.  
그러나 이로 인해 추가 메모리 요구 사항이 발생합니다.  
B가 배치 크기, S 시퀀스 길이, D 숨겨진 차원의 크기, L이 트랜스포머 디코더의 레이어 수라고 가정하면, KV 캐시를 단정밀도 형식으로 저장하는 데 필요한 메모리는 $(B × S × D × L × 2 × 4)$ 바이트로 계산할 수 있습니다.  
이 공식은 배치, 시퀀스 및 숨겨진 레이어의 크기와 디코더의 레이어 수를 고려합니다.  
캐시의 키와 값을 나타내는 인수 2와 단정밀도 부동 소수점 표현의 바이트 크기를 설명하는 인수 4로 구성됩니다.

## Speech-specific Considerations. 
음성 처리 애플리케이션에서 CNN 인코더 블록은 계산 복잡성에서 중요한 역할을 합니다.  
CNN 블록의 초기 레이어에는 훨씬 더 많은 컴퓨팅 성능이 필요하며, 종종 각 개별 트랜스포머 레이어의 컴퓨팅 성능을 한 단계 더 초과합니다.  
요구 사항이 증가한 이유는 각 입력 토큰에 대해 많은 계산을 수행해야 하는 CNN 블록 고유의 컨벌루션 작업 때문입니다.  
예를 들어, 트랜스포머에 19× 더 많은 매개변수가 있음에도 불구하고 wav2vec 2.0 모델은 CNN 블록에 비해 1.8× 더 많은 계산 부하만 발생시킵니다.

# Vision Foundation Models
## Model Architecture
### Vision Transformer pipeline. 
ViT(Vision Transformer)는 가장 고전적인 트랜스포머 기반 비전 모델입니다.  
이는 인코더 전용인 BERT와 같은 자가 감독 사전 학습 NLP 모델의 증가 추세에서 영감을 받았습니다.  
입력 이미지가 주어지면 ViT는 먼저 컨벌루션 임베딩 레이어를 통해 이미지를 고정 크기 패치(즉, 토큰)로 분할합니다.  
예를 들어 표준 크기 RGB 이미지 입력(예: 3×224×224)은 16×16 픽셀의 14×14 패치로 분할됩니다.  
이 임베딩 오버헤드는 다음과 같은 계산 집약적인 트랜스포머 인코더에 비해 거의 무시할 수 있습니다(예: 5% 미만).  
또한 분류를 수행하기 위해 추가 학습 가능한 분류 토큰([CLS])이 토큰 시퀀스에 추가됩니다.  
그런 다음 위치 임베딩이 각 토큰에 추가되고 토큰은 그림 3 및 §2.1에 설명된 표준 트랜스포머 인코더에 공급됩니다.  
특정 다운스트림 작업에 따라 트랜스포머 인코더에서 생성된 숨겨진 상태는 분류, 감지, 분할 등과 같은 다양한 헤드에 최종적으로 입력됩니다.

## Representative Models and Downstream Tasks
### Encoder-only. 
대부분의 시각적 기반 모델은 인코더 전용 아키텍처입니다.  
ViT는 매개변수 양 측면에서 BERT에 맞춰 ImageNet에서 트랜스포머 인코더를 성공적으로 교육한 최초의 작업입니다.  
대규모 ImageNet-22k 데이터세트에 대해 감독 및 자체 감독 사전 학습을 모두 수행합니다.  
경쟁력 있는 정확도와 확장성을 보여주지만 기존 CNN에 비해 훈련 데이터에 대한 수요는 여전히 장애물입니다.  
이를 위해 DeiT는 많은 영향력을 가지고 제안되었습니다.  
DeiT는 ViT 훈련의 데이터 효율성을 향상시키는 증류 기반 사전 훈련을 수행합니다.

또 다른 스토리라인은 자기 감독 ViT 사전 훈련의 한계를 뛰어넘는 것입니다.  
BEiT은 손상된 이미지 패치를 기반으로 원래의 시각적 토큰을 복구하는 사전 훈련 목표를 전환합니다.  
저자는 BEiT가 "CV의 BERT 순간으로 가는 길"이라고 주장합니다.  
MAE는 마스킹된 패치를 재구성하기 위한 인코더 교육에 경량 디코더를 도입합니다.  
MAE는 대부분의 패치를 효과적으로 마스킹할 수 있습니다(80%까지).  
따라서 인코더 교육은 매우 비용 효율적일 수 있으며 사전 교육된 대규모 비전 모델을 위한 기반을 마련합니다.

YOLOS는 ViT 위에 구축된 객체 감지 모델입니다.  
이는 중형 ImageNet-1k에서 사전 훈련된 바닐라 ViT를 보다 까다로운 COCO 객체 감지 벤치마크로 이전할 수 있음을 보여줍니다.  
ViTDet은 일반 비계층적 ViT를 통해 개체 감지를 위한 백본 네트워크 역할을 할 수 있습니다.  
ViTDet을 사용하면 MAE 스타일 사전 학습을 위해 계층적 백본을 재설계할 필요 없이 객체 감지를 위해 원래 ViT 아키텍처를 미세 조정할 수 있습니다.  
스윈 트랜스포머(Swin Transformer)는 어텐션 메커니즘을 최적화한 대표적인 작업이다.  
이 모델은 이동된 창을 사용하여 표현이 계산되는 계층적 ViT입니다.  
DINOv2는 10억 개의 매개변수가 있는 ViT 모델에 대한 교육을 수행한 다음 이미지와 픽셀 수준 모두에서 대부분의 벤치마크에서 OpenCLIP과 같은 주요 다목적 특성보다 성능이 뛰어난 더 작은 모델 세트로 이를 추출합니다.

### Encoder-decoder. 
DETR은 트랜스포머를 사용하여 엔드투엔드 탐지 파이프라인을 구축하려는 초기 노력입니다.  
DETR의 아키텍처는 계단식으로 구성됩니다.  
CNN 백본과 인코더-디코더 트랜스포머로 구성됩니다.  
DETR은 지도 학습을 통해 객체 감지, 인스턴스 분할 및 팬옵틱 분할을 지원합니다.  
DETR의 매개변수 양은 약 40M 매개변수를 갖는 Faster-RCNN과 일치합니다.  
SegFormer는 트랜스포머를 경량 MLP(다층 인식) 디코더와 통합하는 의미론적 분할 모델입니다.  
LVM은 언어적 데이터가 필요 없이 이미지 시퀀스 모델링을 통해 순수한 시각적 접근 방식을 사용하여 시각적 정보의 효과적인 학습을 달성했습니다.

## Cost Analysis
ViT 아키텍처와 BERT의 정렬로 인해 리소스 소비도 유사합니다.  
그러나 BERT와 같은 언어 모델과 달리 시각적 모델은 일반적으로 고정 길이 입력을 갖습니다.  
14×14 패치 또는 16×16 패치와 같은 표준 이미지 입력의 경우 계산 bottleneck은 FFN 및 어텐션의 완전히 연결된 레이어에 있습니다.  

# Multimodal Foundation Models
다중 모드(Multimodality)은 현재 FM 연구에서 뜨거운 연구 방향입니다.  
대규모 FM은 종종 교차 모달 이해, 번역 및 생성 분야에서 강력한 능력을 보여줍니다.

일반적으로 다중 모드 FM에 대한 연구에는 두 가지 라인이 있습니다.  
하나는 주로 트랜스포머 인코더를 채택하여 서로 다른 양식의 데이터를 동일한 잠재 공간으로 인코딩하는 것입니다.  
다른 하나는 종종 트랜스포머 디코더를 사용하여 다양한 양식으로 데이터를 생성하는 것입니다.  
특히, 멀티모달 세대는 주로 텍스트 기반 이미지 생성을 중심으로 하며, 이는 최근 몇 년 동안 크게 발전한 도전적이고 현실적인 ML 작업입니다.  
두 가지 연구 계열에는 다중 모드에서 다중 모드(또는 임의 대 임의) 생성과 같은 융합이 있습니다.

## Key Architectures
다중 모달 입력 데이터를 수집하고 정렬하기 위해 기존 모델 아키텍처는 일반적으로 여러 인코더로 구성되며 각 양식에는 자체 트랜스포머 인코더 세트가 있습니다.  
특히, 이러한 인코더는 일반적으로 정렬된 양식 및 현재 양식과 쌍을 이루는 데이터를 활용하여 처음부터 훈련됩니다.  
다양한 양식으로부터 입력을 받으면 처음에는 이 데이터를 정규화된 고정 차원 임베딩으로 인코딩합니다.  
연구자들은 이러한 임베딩을 고차원 공간에 매핑하고 손실 함수를 설계함으로써 공동 의미 공간에서 다양한 양식 간의 거리를 최소화하는 것을 목표로 합니다.  
이 접근 방식은 다양한 양식을 정렬하고 표현의 일관성을 향상시킵니다.

다중 모드 데이터가 정렬된 기존 연구는  
(i) 순수 텍스트 말뭉치에서 훈련된 LLM을 재사용하여 텍스트를 생성합니다.  
(ii) 또는 확산 모델을 사용하여 고품질 이미지 픽셀을 생성합니다.  

첫 번째 경우, LLM 모듈은 텍스트 형식에 맞춰 정렬된 입력 데이터를 기반으로 이해하고 추론하고 출력을 생성하도록 설계되었습니다.  
이 모듈은 일반적으로 디코더 전용 아키텍처를 채택합니다.  
수많은 대규모 코퍼스 데이터세트에 대한 광범위한 사전 학습으로 인해 LLM에는 풍부한 의미론적 지식이 부여됩니다.  
이를 통해 텍스트 양식에 포함된 데이터를 효과적으로 이해하고 특정 작업을 수행할 때 자동 회귀 방식으로 텍스트 기반 출력을 생성할 수 있습니다.  

두 번째 경우, 확산 모듈은 입력 이미지에 존재하는 중복된 노이즈를 제거하여 고품질 이미지를 생성하는 것을 목표로 합니다.
훈련 단계에서 모델은 이미지에 노이즈를 도입하여 이미지를 무작위 상태로 변환합니다.  
반면 추론 단계에서는 이 과정이 역전되어 점차적으로 노이즈가 제거됩니다.  
이러한 노이즈 제거 프로세스는 이미지 선명도를 향상시켜 고해상도와 상세한 선명도를 갖춘 이미지를 얻는 데 필수적입니다.  
안정적인 확산 모델은 이 기술을 크게 발전시켜 특정 텍스트 및 그림 설명에 맞게 맞춤화된 고품질 이미지를 생성하는 독특한 능력을 보여줍니다.  
다중 모드 임베딩 입력 외에도 확산 모듈은 주로 이미지 인코더/디코더와 잡음 제거 네트워크라는 두 가지 구성 요소로 구성됩니다.

### Image Encoder/Decoder. 
확산 모델은 텍스트-이미지 생성을 위한 최첨단 접근 방식입니다.  
인코더는 입력 이미지를 가져와 이를 저차원 잠재 표현으로 압축합니다.  
이러한 압축은 계산 부하를 줄이고 모델의 효율성을 높이는 데 필수적입니다.  
디코더는 반대로 작동하여 잠재 표현을 가져와 다시 고해상도 이미지로 재구성합니다.  
이 프로세스는 상세한 시각적 콘텐츠를 생성하는 모델의 능력에 매우 중요합니다.  
VAE(Variational Autoencoder)는 이미지의 잠재 공간을 학습하는 데 사용되는 생성 모델입니다.  
VAE는 인코더와 디코더로 구성됩니다.  
인코더는 이미지를 잠재 공간에 매핑하는 역할을 담당하고 디코더는 잠재 공간을 이미지 공간에 매핑하는 역할을 합니다.  
인코더와 디코더 네트워크는 모두 컨벌루션 신경층으로 구축되는 경우가 많습니다.  
VAE는 재구성 손실과 KL 발산 손실을 최소화하여 훈련됩니다.  
재구성 손실은 디코더에서 생성된 이미지가 원본 이미지와 유사하다는 것을 보장하는 역할을 하고, KL 발산 손실은 잠재 공간이 표준 정규 분포와 유사하다는 것을 보장하는 역할을 합니다.  
VAE는 이미지의 잠재 공간을 학습하기 위해 확산 모델에 사용됩니다.  
확산 작업에 자주 사용되는 VAE 모델의 또 다른 변형은 벡터 양자화 레이어를 통해 이미지의 잠재 공간을 학습하는 VQ-VAE입니다.  
벡터 양자화 계층은 벡터 양자화 기술을 적용하여 이미지의 각 픽셀을 가장 가까운 코드북 벡터로 양자화합니다.  
이러한 방식으로 VQ-VAE 모델은 보다 효율적인 방식으로 이미지를 인코딩하고 디코딩할 수 있습니다.

### Denoising Network. 
노이즈 제거 네트워크는 노이즈 분포를 예측하고 DDPM 및 DDIM과 같은 샘플링 알고리즘을 통해 노이즈를 제거함으로써 인코딩된 이미지에서 노이즈를 점진적으로 제거합니다.  
처음에는 훈련 단계에서 모델이 이미지에 노이즈를 추가하여 점차적으로 순수한 무작위 상태로 만듭니다.  
그러면 잡음 제거 네트워크는 추론 단계에서 이 잡음 추가를 역전시키는 방법을 단계별로 학습합니다.  
이러한 점진적인 노이즈 제거는 최종 이미지 출력의 선명도와 품질을 향상시키는 데 중요합니다.  
U-Net은 수축 경로와 확장 경로로 구성된 합성곱 신경망 모델인 확산 모델에서 잡음 예측 네트워크로 자주 사용됩니다.  
축소 경로는 이미지를 고차원 공간에 매핑하여 이미지의 컨텍스트 정보를 캡처하는 역할을 하는 반면, 확장 경로는 업샘플링을 통해 정확한 위치 파악을 용이하게 합니다.  
수축 경로에 대한 정보를 유지하기 위해 확장 경로는 건너뛰기 연결을 통해 수축 경로에 연결됩니다.  
U-Net 모델은 이미지 분할 작업에 널리 사용되는 선택이며 이미지 내의 노이즈를 예측하기 위해 확산 모델에도 사용됩니다.

### Fusion decoder (FD). 
또한 FD 모듈은 이미지 자체와 관련 이미지 프롬프트를 기반으로 이미지에 대한 이해를 높이는 것을 목표로 하며 작업 요구 사항에 따라 출력을 생성합니다.  
이 모듈에는 일반적으로 퓨전 디코더 설계가 포함되며 이미지와 텍스트 데이터 세트 모두에 대해 사전 학습되어 이미지와 텍스트 표현을 공동으로 처리할 수 있습니다.  
이 모듈은 일반적으로 퓨전 디코더의 설계를 포함하며 이미지 및 텍스트 데이터 세트 모두에 대한 사전 학습을 거칩니다.  
이 모듈을 사용하면 이미지와 텍스트 표현을 종합적으로 처리할 수 있습니다.

## Representative Models and Downstream Tasks
### Multi-Encoder FMs: 
CLIP, ALBEF 및 ALIGN은 이미지와 텍스트 간의 연결을 설정하여 텍스트에서 보다 풍부한 이미지 표현을 학습하는 것을 목표로 하는 교차 모달 정렬을 제안하는 초기 작업입니다.  
이러한 모델은 초기에 다중 양식의 잠재력을 입증했지만 이미지 및 텍스트 인코더의 능력은 물론 이미지-텍스트 쌍 데이터의 양과 품질로 인해 성능이 제한되었습니다.  
이러한 모델은 처음에 다중 양식의 잠재력을 보여 주었지만 이미지 및 텍스트 인코더의 능력은 물론 이미지-텍스트 쌍 데이터의 양과 품질로 인해 성능이 제한되었습니다.  
ImageBind 및 LanguageBind와 같은 후속 작업에서는 모달 정렬이 더욱 확장되었습니다.  
이러한 모델은 다양한 중간 양식을 정렬된 모달로 사용하여 다양한 소스의 표현을 중간 모달의 특성 공간에 효과적으로 매핑함으로써 조인트 벡터 공간 내에서 모달 간 변환을 촉진합니다.  
그러나 주로 인코더 능력의 한계로 인해 다중 모드 표현을 중간 양식 표현과 정렬하는 데 심각한 문제가 발생합니다.  
이러한 제한은 결국 모델의 전반적인 성능에 영향을 미칩니다.

### Encoder-Decoder FMs
modality conversion에 임베딩 모듈을 활용하여 변환된 모달리티가 generator와 호환되도록 합니다.

### Encoder-Large FMs
PandaGPT는 여러 단일 모달 인코더를 활용하여 입력을 중간 양식에 정렬합니다.  
PandaGPT는 생성을 위해 중간 양식을 대형 FM에 공급한 다음 대상 양식의 디코더를 통해 추가 변환을 수행합니다.  
또한 BLIP-2 및 MiniGPT-4는 이미지 모달 인코더를 설계하고 Q-Former를 사용하여 이러한 이미지 양식을 텍스트 양식과 융합한 후 교차 모달 생성을 위한 다중 모달 대형 FM에 공급함으로써 텍스트 및 이미지의 교차 모달 생성에 중점을 둡니다.  
한편 mPLUG와 LLaVA는 생성된 결과의 가용성과 신뢰성을 향상시키기 위해 양식 변환 능력을 향상시키는 데 중점을 둡니다.  
또한 Flamingo와 LLaMA-Adapter는 저렴한 비용으로 다중 모드 대형 FM을 튜닝하여 고품질 다중 모드 출력을 생성하는 방법을 탐색합니다.  
PaLM-E 및 HuggingGPT는 대규모 FM을 중앙 구성 요소로 사용하여 Embodied 데이터를 다중 모드 입력에 통합함으로써 Embodied Intelligence에 중점을 둡니다.  
이러한 모델은 작업을 분해하고 생성 능력을 활용하여 복잡한 작업을 수행하도록 에이전트를 추가로 설계합니다.

### Encoder-Diffusion FMs
안정적인 확산은 학습된 프로세스를 통해 이미지의 노이즈를 점진적으로 제거하여 선명하고 상세한 시각적 출력을 제공함으로써 고품질 이미지를 생성할 수 있습니다.  
이 모델은 텍스트 설명에서 세부 이미지 생성(텍스트-이미지 생성), 이미지 일부 복원 또는 완성(이미지 인페인팅), 기존 이미지의 특정 측면 수정(이미지 편집), 이미지 해상도 향상(이미지 초해상도)과 같은 다양한 다운스트림 작업에 적용됩니다.  
이러한 영역에서 안정적인 확산의 적응성은 이미지 처리 및 생성 분야에서 귀중한 도구가 됩니다.  
일관성 모델은 고품질 이미지, 오디오 및 비디오를 생성할 때 확산 모델의 효율성을 향상시키기 위해 개발되었습니다.  
이러한 모델은 빠른 단일 단계 생성을 촉진하여 기존 확산 모델과 관련된 느린 샘플링 속도를 극복합니다.  
이러한 작업을 위한 특정 교육 없이도 이미지 인페인팅, 색상화, 초해상도 등 제로샷 데이터 편집 작업을 수행할 수 있는 능력을 보여줍니다.  
DALL-E는 주로 이미지 생성에 사용되며 텍스트 설명을 기반으로 다양하고 복잡한 이미지를 생성하는 능력을 보여줍니다.  
이 모델은 자연어 이해와 컴퓨터 비전의 요소를 통합하여 간단한 설명부터 복잡한 시나리오에 이르기까지 광범위한 텍스트 프롬프트를 충실하게 표현하는 이미지를 생성할 수 있습니다.

안정적인 확산 외에도 다양한 유형의 입력을 광범위한 출력으로 변환하도록 설계된 "any-to-any" 생성 모델이 눈에 띄게 강조됩니다.  
CoDi는 다양한 입력 조합에서 언어, 이미지, 비디오 또는 오디오와 같은 다양한 출력 형식을 생성하도록 설계되었습니다.  
그 독창성은 특정 입력 유형에 제한되지 않고 여러 양식을 동시에 생성할 수 있는 능력에 있습니다.  
CoDi는 입력 공간과 출력 공간의 양식을 정렬하여 훈련 데이터에 없는 조합의 생성을 촉진합니다.  
NExTGPT는 텍스트, 이미지, 비디오 및 오디오를 포함한 다양한 양식에 걸쳐 입력을 인식하고 출력을 생성하는 능력을 보여줍니다.  
NExT-GPT는 대규모 FM을 다중 모드 어댑터 및 확산 모델과 통합합니다.  
시스템은 최소한의 매개변수 변경으로 미세 조정을 거쳐 비용 효율적인 훈련과 간단한 양식 확장을 촉진합니다.  
NExT-GPT는 모달리티 전환 명령 튜닝을 채택하고 특별히 선별된 데이터 세트를 활용하여 보편적인 모달리티 모델링을 목표로 크로스 모달 콘텐츠 생성 및 이해를 향상시킵니다.

### Encoder-FD FMs 
UNITER는 다양한 설정에서 이미지와 텍스트의 보편적인 융합을 제안한 최초의 작업 중 하나입니다. 트랜스포머를 통해 이미지와 텍스트 특성을 결합하여 결합 특성을 얻는 것을 목표로 합니다. 이를 바탕으로 FLAVA, CoCa 및 GLIP과 같은 후속 작업에서는 디코더를 사용하여 이미지와 텍스트 표현을 더 잘 융합하고 정렬하여 다중 모드 추론을 향상시키는 방법을 더 깊이 탐구합니다. 또한 SAM은 디코더를 활용하여 이미지에 해당하는 프롬프트 임베딩을 융합함으로써 한 단계 더 발전하여 텍스트 프롬프트에만 기반한 이미지의 제로샷 자동 분할을 가능하게 합니다.

 2.3.3. Cost Analysis
Resouce-Efficient Architectures
3.1. Efficient Attention
 3.1.1. Sparse Attention
 3.1.2. Approximate Attention
 3.1.3. Attention-Free Approaches
3.2. Dynamic Neural Network
 3.2.1. Mixture of Experts
 3.2.2. Early Exiting
3.3. Diffusion-specific Optimization
 3.3.1. Efficient Sampling
 3.3.2. Diffusion in Latent Space
 3.3.3. Diffusion Architecture Variants
3.4. ViT-specific Optimizations
Resouce-Efficient Algorithms
4.1. Pre-training Algorithms
 4.1.1. Training Data Reduction
 4.1.2. Neural Architecture Search
 4.1.3. Progressive Learning
 4.1.4. Mixed Precision Training
4.2. Finetuning Algorithms
 4.2.1. Additive Tuning
 4.2.2. Selective Tuning
 4.2.3. Re-parameter Tuning
4.3. Inference Algorithms
 4.3.1. Opportunistic Decoding
 4.3.2. Input Filtering and Compression
 4.3.3. Key-Value Cache
 4.3.4. Long Context
4.4. Model Compression
 4.4.1. Pruning
 4.4.2. Knowledge Distillation
 4.4.3. Quantization
 4.4.4. Low-Rank Decomposition
Resouce-Efficient Systems
5.1. Distributed Training
5.2. Federated Learning
 5.2.1. Frameworks & Benchmarks
 5.2.2. PEFT-based Approaches
 5.2.3. Model Decomposition
 5.2.4. Backprop-free Approaches
5.3. Serving on Cloud
 5.3.1. Inference Accelerating
 5.3.2. Memory Saving
 5.3.3. Emerging Platforms
5.4. Serving on Edge
Conclusion and Future Directions
