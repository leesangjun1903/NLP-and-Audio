# Minerva: Solving Quantitative Reasoning Problems with Language Models

## 1. 핵심 주장 및 주요 기여
대규모 언어 모델(Large Language Model)이 자연어 이해에는 우수한 성능을 보이나, 수학·과학·공학 등 **정량적 추론** 문제에서는 한계가 있었다.  
이 논문은 다음을 제안·증명한다:
- **Minerva**: PaLM 기반 언어 모델을 과학·수학 논문(arXiv)과 수학 표현 웹페이지로 구성된 38.5B 토큰 규모 기술 데이터셋으로 추가 학습(finetuning)하여 정량적 추론 능력을 대폭 향상시킴.
- 외부 도구 없이 순수 언어 모델만으로 수학·물리·화학·공학 난제에 대해 **체인-오브-생각(chain-of-thought)** 형태의 해설과 정확한 LaTeX 수식 출력을 수행.
- MATH, GSM8k, MMLU-STEM, OCWCourses 등 다양한 벤치마크에서 최첨단 성능 달성.

## 2. 해결 과제, 제안 방법, 모델 구조, 성능 및 한계

### 2.1 해결하고자 하는 문제
- 자연어로 서술된 고등수학·물리·공학 문제를 **정확한 계산·상징(symbolic) 조작**과 논리적 추론만으로 해결하고 그 과정을 인간 수준으로 설명하는 능력 부재.

### 2.2 제안 방법
1. **데이터 수집 및 전처리**  
   - arXiv 논문 1.2M편(LATEX 원문), MathJax/TeX 수식 포함 웹페이지를 필터링해 38.5B 토큰 구성.  
   - 수식 기호·LaTeX 구문 손실 없이 보존.

2. **모델 구조**  
   - PaLM 기반 8B, 62B, 540B 파라미터 디코더 전용 트랜스포머.
   - 컨텍스트 길이 2048 토큰.

3. **추가 학습(finetuning)**  
   - 일반 자연어 사전학습(pretraining) 이후, 기술 데이터셋으로 **비지도 추가학습(continued pretraining)** 수행.
   - 학습률: reciprocal square-root decay, 배치크기 128 (540B는 32).

4. **추론 기법**  
   - **Greedy decoding** (pass@1)와 **다중 샘플링(nucleus sampling, T=0.6)** 후 **최다득표(Majority Voting)**(maj1@k) 사용.  
   - 식:  

```math
       \mathrm{maj1}@k: \quad \underset{a}{\mathrm{argmax}}\;\#\{\,i: \text{output}_i = a\}
```

### 2.3 성능 향상
| 데이터셋       | PaLM 540B | Minerva 540B maj1@k |
|----------------|----------:|--------------------:|
| MATH           | 8.8%      | **50.3%**           |
| GSM8k          | 56.5%     | **78.5%**           |
| MMLU-STEM      | 58.7%     | **75.0%**           |
| OCWCourses     | 7.1%      | **30.8%**           |

- 기존 SOTA 대비 MATH에서 7배 이상, STEM 전반에서 10–20%p 대폭 향상.  
- Majority voting은 k≈64에서 성능 포화, pass@k는 완만히 상승.  

### 2.4 한계
1. **정답 검증**: 모델의 해설(chain-of-thought)은 자동 검증 불가 → 잘못된 추론에도 올바른 최종답을 낼 수 있음(false positive).  
2. **수치 계산 한계**: 외부 계산기·Python 인터프리터 미사용 → 높은 정밀도·대규모 행렬 연산 어려움.  
3. **능력 획득 제어 어려움**: 대규모 언어 데이터로부터 학습되므로 특정 기능·사고 과정을 세밀히 설계·강화 불가.

## 3. 일반화 성능 향상 가능성

- **다양한 수식 도메인 확장**: 공학·통계·금융 등 비유클리드 수학·전문 분야 공식 데이터를 추가하면 적용 범위 확장.  
- **외부 툴 통합**: 계산기, 심볼릭 연산 라이브러리, 증명 보조기법(예: Lean, Coq) 연동으로 정확도·신뢰성↑.  
- **메모리 강화**: 롱폼 컨텍스트·증분 검색(RAG) 기법으로 참조 자료 불러오기 → 복잡한 논문·교과서 수준 문제 해결.  
- **추론 검증 모듈**: 해설 단계별 증명 어시스턴트(정리 자동 검증기) 접목으로 false positive 완화.

## 4. 향후 연구에 미치는 영향 및 고려 사항

- **AI 기반 튜터링**: 맞춤형 수학·과학 학습 도구 개발에 활용 가능.  
- **융합 연구 지원**: 수리적 추론 자동화는 물리학·화학 컴퓨테이션 연구 加速.  
- **윤리·신뢰성**: 잘못된 체인-오브-생각 설명이 학생·연구자 오도 가능 → 추론 검증·불확실성 추정 강화 필요.  
- **데이터 편향 해소**: 특정 수학 분야·언어에 치우친 데이터로 인한 일반화 한계 → 균형 잡힌 학습셋 확보 중요.  

---  
**결론**: Minerva는 순수 언어 모델만으로 정량적 추론 역량을 획기적으로 개선했으나, 추론 검증과 외부 계산력 통합을 통해 더욱 강력하고 신뢰할 수 있는 차세대 지능 시스템 구축이 요구된다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/92af99d6-7309-4327-b885-f1da89fe7be5/2206.14858v2.pdf)
