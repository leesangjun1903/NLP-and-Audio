# Reasoning with Language Model Prompting: A Survey

## 1. 핵심 주장과 주요 기여

이 논문은 **언어 모델 프롬프팅을 통한 추론**에 대한 최초의 포괄적 서베이를 제공합니다. 주요 기여는 다음과 같습니다:

**핵심 주장:**
- 대규모 언어 모델의 스케일 증가는 다양한 추론 능력(산술, 상식, 기호, 논리적 추론)을 발현시킴
- Chain-of-Thought (CoT) 프롬프팅과 같은 전략이 인간-기계 지능 격차를 극적으로 줄임
- 추론 능력은 모델 크기뿐만 아니라 사전 훈련 데이터의 품질에도 의존함

**주요 기여:**
- 추론 방법론의 체계적 분류 체계 제시
- 300개 이상의 관련 연구에 대한 종합적 비교 분석
- 벤치마크 및 리소스 정리
- 미래 연구 방향 제시

## 2. 문제 정의와 제안 방법

### 해결하고자 하는 문제
현대 신경망은 주어진 정보나 기존 지식으로부터 추론하는 능력이 부족합니다. 이 논문은 언어 모델 프롬프팅을 통해 이러한 추론 능력을 향상시키는 방법들을 체계화합니다.

### 수학적 정의
표준 프롬프팅의 경우, 추론 질문 Q, 프롬프트 T, 매개변수화된 확률 모델 p_LM이 주어졌을 때, 답 A의 가능도를 최대화:

$$ p(A | T, Q) = \prod_{i=1}^{|A|} p_{LM}(a_i | T, Q, a_{ < i}) $$

CoT 접근법의 경우, 추론 단계 C를 추가하여:

$$ p(A | T, Q) = \sum_C p(A | T, Q, C) \cdot p(C | T, Q) $$

여기서:

$$ p(C | T, Q) = \prod_{i=1}^{|C|} p_{LM}(c_i | T, Q, c_{ < i}) $$

$$ p(A | T, Q, C) = \prod_{j=1}^{|A|} p_{LM}(a_j | T, Q, C, a_{ < j}) $$

### 분류 체계

논문은 추론 방법을 두 주요 카테고리로 분류합니다:

**1. 전략 강화 추론 (Strategy Enhanced Reasoning)**
- **프롬프트 엔지니어링**: Single-stage와 Multi-stage 방법
- **프로세스 최적화**: Self-optimization, Ensemble-optimization, Iterative-optimization
- **외부 엔진**: 물리 시뮬레이터, 코드 인터프리터, 도구 학습

**2. 지식 강화 추론 (Knowledge Enhanced Reasoning)**
- **암시적 지식**: 모델 내부의 "modeledge" 활용
- **명시적 지식**: 외부 리소스에서 검색된 지식 활용

## 3. 성능 향상 및 모델 특성

### 스케일과 성능의 관계
- **임계 크기**: 100B 매개변수 미만에서는 CoT 프롬프팅이 효과가 제한적이거나 해로울 수 있음
- **emergent ability**: 대규모 모델에서만 나타나는 창발적 추론 능력
- **코드 사전 훈련의 효과**: Codex가 동일한 크기의 GPT-3보다 우수한 성능 보임

### 성능 향상 사례
GSM8K 데이터셋에서:
- GPT-3 fine-tuning: ~17%
- PaLM-540B with CoT: ~58%
- 모델 크기 증가에 따른 성능 향상이 뚜렷함

## 4. 일반화 성능 향상 가능성

### 현재의 한계
- **길이 일반화**: 훈련 시보다 긴 추론 체인에 대한 처리 능력 부족
- **도메인 외 일반화**: 훈련 중 보지 못한 유사한 추론 작업에 대한 일반화 제한
- **진정한 추론**: 단순한 패턴 매칭을 넘어선 실제 추론 능력의 한계

### 개선 방향
논문은 다음과 같은 방향을 제시합니다:
- **이론적 원리 탐구**: 추론 능력의 근본적 메커니즘 이해
- **효율적 추론**: 작은 모델에서도 추론 능력 구현
- **견고하고 신실한 추론**: 편향과 독성 완화
- **다중 모달 추론**: 텍스트를 넘어선 통합적 추론
- **일반화 가능한 진정한 추론**: 아날로지, 인과관계, 구성적 추론 통합

## 5. 주요 한계

### 방법론적 한계
- **대규모 모델 의존성**: 높은 계산 비용과 에너지 소비
- **프롬프트 민감성**: 작은 변화도 큰 성능 차이 야기
- **환각 문제**: 사실과 다른 정보 생성 경향

### 평가의 한계
- **벤치마크 한계**: 실제 추론 능력 vs 패턴 매칭 구분 어려움
- **일반화 측정**: 진정한 일반화 능력 평가 방법 부족

## 6. 미래 연구에 미치는 영향과 고려사항

### 연구에 미치는 영향
1. **체계적 접근**: 추론 연구의 표준화된 분류 체계 제공
2. **벤치마크 표준화**: 다양한 추론 작업에 대한 평가 기준 정립
3. **리소스 통합**: ThoughtSource, LangChain 등 오픈소스 리소스 활용 촉진

### 향후 연구 고려사항

**이론적 측면:**
- 추론 능력의 창발 메커니즘 규명
- 인컨텍스트 학습의 근본 원리 이해
- 코드 사전 훈련이 추론에 미치는 영향 분석

**실용적 측면:**
- 효율적인 소형 모델 개발
- 멀티모달 추론 시스템 구축
- 견고성과 신뢰성 향상

**평가 측면:**
- 진정한 추론 능력 측정 방법 개발
- 일반화 성능 평가 기준 정립
- 편향과 독성 측정 도구 개선

이 논문은 언어 모델의 추론 능력 연구에 대한 포괄적 로드맵을 제공하며, 향후 AGI(Artificial General Intelligence) 달성을 위한 중요한 기초 자료로 활용될 것으로 전망됩니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/c3c3057a-debc-44d1-8ddb-bcefd69eb0c9/2212.09597v8.pdf)
