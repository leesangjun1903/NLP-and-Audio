# TAPAS: Weakly Supervised Table Parsing via Pre-training

**핵심 주장 및 주요 기여 요약**  
TAPAS는 자연어 질문에 대해 논리 형태를 생성하지 않고 테이블 셀 선택 및 선택된 셀에 대한 집계 연산을 통해 직접 답변을 예측하는 새로운 방식의 테이블 질의 응답 모델이다. 대규모 위키피디아 테이블과 관련 텍스트를 활용한 *테이블-텍스트 공동 사전학습*을 도입하여, 약한 지도학습(denotation만 제공) 환경에서도 end-to-end로 학습 가능함을 보였다.[1]

## 1. 해결하고자 하는 문제  
기존 테이블 질의 응답은 질문을 논리적 실행 형태(logical form)로 변환한 후에 실행하여 답을 얻는다. 그러나  
TAPAS가 해결하는 과제는  
- 논리적 형태를 주석화하기 위한 고비용 레이블링 부담  
- *스퓨리어스 프로그램*(spurious program)의 과다 생성 및 보상 희소성  
- 복잡한 디코딩 제약 및 라벨 바이어스 문제  
등이다.[1]

## 2. 제안하는 방법  
TAPAS는 BERT 기반 인코더를 확장하여 테이블 구조를 직접 인코딩하고, 질문과 테이블을 하나의 시퀀스로 결합한다. 학습 및 추론 과정은 다음과 같다.[1]

### 2.1 입력 인코딩  
- 질문 + `[SEP]` + 평탄화(flattened)된 테이블 셀 시퀀스를 WordPiece 토큰화  
- **추가 위치 임베딩**  
  - Segment ID: 질문(0) vs. 테이블(1)  
  - Column/Row ID: 각 토큰이 속한 열·행 인덱스  
  - Rank ID: 숫자 및 날짜 값의 정렬 순위  
  - Previous Answer ID: 대화형 설정 시 이전 답변 셀 표시  

### 2.2 모델 구조  
1. BERT 인코더 출력  
2. **셀 선택 레이어**: 각 셀에 대한 Bernoulli 확률 $$p_c$$ 예측  
3. **열 선택 레이어**: 전체 열 중 선택된 열 예측, 다른 열의 셀 확률을 0으로 마스킹  
4. **집계 연산 레이어**: CLS 토큰 벡터에 선형+softmax를 적용해 $$\mathrm{NONE},\mathrm{COUNT},\mathrm{SUM},\mathrm{AVERAGE}$$ 중 선택  

### 2.3 학습 목표 함수  
- **셀 선택 손실**: 선택된 셀에 대한 이진 크로스엔트로피  
- **집계 연산 손실**: NONE 클래스에 대한 음의 로그확률  
- **스칼라 정답 손실**: Huber loss를 통해 예측된 연산 결과 $$\hat{s}=\sum_{\mathrm{op}}p_{\mathrm{op}}\mathrm{compute}_{\mathrm{op}}(p, T)$$과 실제 정답 $$s$$ 비교  

$$
\hat{s} = \sum_{op \in \{\mathrm{COUNT,SUM,AVG}\}} p_{op} \cdot \mathrm{compute}_{op}(p_c, T)
$$  

$$
\mathcal{L}_{scalar} = \begin{cases}
0.5(s - \hat{s})^2 & \text{if } |s - \hat{s}| < \delta,\\
\delta|s - \hat{s}| - 0.5\delta^2 & \text{otherwise}
\end{cases}
$$  

전체 손실은 셀 선택, 집계 연산, 스칼라 정답 손실을 가중합하여 최적화한다.[1]

## 3. 성능 향상 및 한계  
- **SQA**: 55.1 → 67.2 (전체 질문 정확도)  
- **WikiSQL**: 83.9(기존) → 85.1  
- **WikiTableQuestions**: 44.1 → 48.7 (전이학습 효과)  
  
사전학습, 열·행 임베딩 및 집계 손실이 성능에 크게 기여함을 보였으며, 특히 테이블 사전학습은 없을 때 대비 최대 12.5포인트 하락을 초래했다.[1]
한계로는 단일 테이블만 처리하고, 다중 집계 및 복잡 연산(예: 조건부 필터링 후 집계)에는 확장되지 않는다는 점이 있다.[1]

## 4. 일반화 성능 향상 관점  
- 방대한 위키피디아 테이블-텍스트 쌍으로 사전학습함으로써 다양한 도메인의 테이블 구조 및 용어를 학습  
- 숫자와 날짜 정렬 순위 임베딩을 도입해 새로운 값에 대한 *순위 기반 일반화* 지원  
- 대화형 이전 답변 임베딩으로 문맥추적 능력 강화  
이들 요소가 다양한 데이터셋 간 전이학습에서 높은 일반화 성능을 입증했다.[1]

## 5. 미래 연구에 미치는 영향 및 고려사항  
TAPAS는 테이블 QA에서 논리 형태를 배제하고 대규모 사전학습을 활용하는 방향을 제시했다.  
향후 연구 시 고려할 점은  
- **다중 테이블·데이터베이스**: 대규모 및 분산 테이블 컨텍스트 처리  
- **복합 연산**: 조건부 필터링, 그룹별 다중 집계 지원을 위한 확장된 추론 레이어  
- **효율성**: 512 토큰 한계를 극복하기 위한 동적 테이블 압축 기법  
- **다국어·도메인 특수화**: 영어 외 언어 및 전문 도메인을 위한 추가 사전학습 전략  

이와 같은 발전은 테이블 기반 정보 검색 및 의사결정 지원 시스템 분야를 크게 확장할 것으로 기대된다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/f49b5160-16da-4b92-945f-70e394f1278e/2004.02349v2.pdf)
