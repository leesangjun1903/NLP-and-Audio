# DeepSpeed: System Optimizations Enable Training Deep Learning Models with Over 100 Billion Parameters

**핵심 주장 및 주요 기여**  
Microsoft의 DeepSpeed는 ZeRO(Zero Redundancy Optimizer) 메모리 최적화를 중심으로 대규모 분산 딥러닝 학습의 비용, 속도, 자원 효율성 문제를 해소함으로써 1000억 개 이상의 파라미터 모델 훈련을 가능케 한다.  
- ZeRO를 통해 모델 파라미터, 옵티마이저 상태, 그라디언트의 중복 저장을 제거하여 메모리 사용량을 3~5배 절감하고, 이를 통해 단일 GPU와 멀티 GPU 환경 모두에서 수조 개 파라미터 모델 훈련에 도달할 수 있는 확장성을 제시한다.  
- 최적화된 트랜스포머 커널과 mixed precision(혼합 정밀도) 지원을 결합하여 BERT 사전학습을 44분에 완료하는 세계 최고 기록을 달성했다.  

***

## 1. 해결하고자 하는 문제  
- **대규모 모델 학습의 자원 제약**: 모델 파라미터가 증가함에 따라 GPU 메모리 한계로 인해 분산 학습 시 파라미터·그라디언트·옵티마이저 상태를 여러 GPU에 복제해야 하는 중복 오버헤드가 급증.  
- **소프트웨어 효율성 부족**: 하드웨어 성능을 충분히 활용하지 못하는 최적화되지 않은 커널과 정밀도 설정.  

***

## 2. 제안 방법  
### 2.1 ZeRO(Zero Redundancy Optimizer)  
ZeRO는 파라미터 $$w$$, 옵티마이저 상태 $$s$$, 그라디언트 $$g$$를 각기 다른 GPU에 분산 저장해 중복을 제거한다.  
- 파라미터 샤딩: $$w$$를 $$N$$개 GPU에 균등 분할  
- 옵티마이저 상태 샤딩: $$s$$ 역시 GPU 간 분할  
- 그라디언트 샤딩: 역전파 시 생성되는 $$g$$ 분산 저장  

이로써 각 GPU의 메모리 사용량은  

$$
\frac{|w| + |s| + |g|}{N}
$$  

에서  

$$
\frac{|w|}{N} + \frac{|s|}{N} + \frac{|g|}{N}
$$  

로 줄어든다.

### 2.2 최적화된 트랜스포머 커널  
- NVIDIA Volta 아키텍처의 텐서 코어 활용  
- 연산 병목 해소를 위해 커스텀 CUDA 확장 적용  

### 2.3 Mixed Precision 지원  
- FP16 연산과 FP32 스케일링을 조합하여 메모리 사용량과 연산량을 절감하며, 수렴 안정성을 위해 loss scaling 기법 적용  

***

## 3. 모델 구조 및 성능 향상  
- **적용 모델**: BERT base (110M 파라미터)부터 대규모 Turing-NLG (17B)까지  
- **속도**: 1024 V100 GPU에서 BERT 사전학습 44분 달성 (기존 67분 대비 34% 개선)  
- **메모리 확장**: 100~200B 파라미터 모델을 단일 클러스터에서 실험적 학습 가능  
- **하드웨어 활용률**: 단일 GPU당 64 TFLOPS(하드웨어 peak의 50% 이상)  

***

## 4. 일반화 성능 향상 가능성  
- **샤딩 기반 옵티마이저의 통산 이점**: 모델 파라미터와 옵티마이저 상태를 분산 처리하는 과정에서 통신 동기화 비용이 낮아져 더 큰 배치 크기와 학습률 스케줄 실험이 가능  
- **Mixed Precision 도입 효과**: 더 넉넉해진 메모리로 활성화 함수와 드롭아웃 등 정규화 기법을 다양하게 적용할 수 있어 과적합 감소  
- **커널 최적화**로 훈련 속도를 높이면 더 많은 에포크, 다양한 데이터 증강을 시도할 시간 확보 → 일반화 성능 상승  

***

## 5. 한계 및 앞으로의 고려 사항  
- **통신 병목**: ZeRO 샤딩 간 AllGather/AllReduce 통신 비용이 대규모 노드에서 여전히 증가  
- **정밀도 한계**: FP16 수렴 안정성을 위한 추가 메커니즘 필요  
- **청크 크기 조율**: 샤딩 단위 크기(hyperchunk) 결정이 모델·하드웨어별로 최적값 탐색이 필요  
- **운영 복잡성**: 사용자 코드 변경이 최소화됐으나 여전히 분산 환경 설정의 난이도 존재  

***

## 6. 향후 연구에 미치는 영향 및 고려 사항  
DeepSpeed는 **수조 파라미터 모델 훈련의 실현 가능성**을 보여주며, 다음 연구에 다음 사항을 고려토록 이끈다:  
- 통신 효율화를 위한 **내결함성 통신 프레임워크**  
- **차등 및 동적 샤딩** 전략 연구  
- **자동 mixed precision 튜닝** 및 **정밀도 하이브리드** 알고리즘  
- 대규모 모델의 **지속가능성(친환경 문제)**과 비용 최적화  

이를 통해 연구자들은 더 거대하고 복잡한 모델 실험을 시스템적으로 지원할 수 있는 새로운 퍼포먼스-스케일 트레이드오프를 탐색하게 될 것이다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/240f549f-835c-4a99-a86c-6e48ba95f1ba/3394486.3406703.pdf)
