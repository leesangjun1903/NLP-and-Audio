# Chain-of-Thought Prompting Elicits Reasoning in Large Language Models

## 1. 핵심 주장 및 주요 기여
대규모 언어 모델은 단순 입력–출력 예시만으로는 어려운 다단계 추론 과제를 제대로 해결하지 못하지만, 모델에 “추론의 중간 단계를 자연어로 표현한 사슬(chain of thought)” 예시를 제공하면 복잡한 산술, 상식, 기호적 문제에서 성능이 획기적으로 개선된다. 특히  
- 약 10<sup>11</sup>개 이상의 매개변수를 가진 모델에서만 **추론 능력이 ‘비약적(emergent)’으로 발현**된다.  
- PaLM 540B와 GPT-3 175B를 ‘사슬’ 프롬프트로 사용했을 때, GSM8K·SVAMP·MAWPS 등의 벤치마크에서 **최신 지도학습 모델을 능가하거나 동등한 수준의 성능**을 달성했다.  

## 2. 문제 정의, 제안 방법, 모델 구조, 성능 향상 및 한계

### 2.1 해결하고자 하는 문제
- 표준 몇-샷(few-shot) 프롬프트 방식은 단일 단계 추론 또는 단순 질의응답에는 유용하나, 다중 중간 논리 단계를 필요로 하는 복잡한 수학·상식·기호적 과제에서는 성능이 매우 낮음.

### 2.2 제안 방법: Chain-of-Thought Prompting
- Few-shot 예시를 ⟨입력, 중간 추론 단계(Chain of Thought), 출력⟩ 형태의 **삼중 트리플**로 구성.  
- 모델이 자연어로 된 중간 단계를 생성하도록 유도해, 복잡한 과제를 단계별로 분해해 해결하게 함.  

수식 예시 (GSM8K 문제):  

$$
\begin{aligned}
&\text{“카페테리아에 사과가 23개 있었다. 20개를 사용하고 6개를 더 샀다면, 총 몇 개인가?”}\\
&\text{Chain of Thought: }23-20=3,3+6=9\Rightarrow9.
\end{aligned}
$$

### 2.3 모델 구조
- **사전 학습된(off-the-shelf) 대형 언어 모델**을 그대로 사용하며, 파라미터 업데이트(미세조정)는 전혀 수행하지 않음.
- 적용 모델: GPT-3 (Ada–Davinci 시리즈), LaMDA(137B), PaLM(8B, 62B, 540B), UL2(20B), Codex(175B).

### 2.4 성능 향상
- **Emergent Ability**: 10<sup>11</sup>개 이상 매개변수에서만 사슬 프롬프트가 유의미한 성능 향상을 제공하며, 소형 모델에서는 오히려 성능 저하.  
- **Arithmetic Reasoning**: PaLM 540B가 GSM8K에서 표준 프롬프트 대비 두 배 이상의 정확도 달성, 기존 SOTA 초과.  
- **Commonsense Reasoning**: StrategyQA·Sports Understanding 등에서 기준 모델 대비 6–15%p 향상.  
- **Symbolic Reasoning**: 동형(in-domain) 문제 거의 완전 정답, 더 긴 시퀀스(OOD)에도 일반화 성능 대폭 향상.  

### 2.5 한계
- **추론의 정확성 보장 불가**: 때때로 잘못된 추론 경로가 정답을 우연히 맞추거나, 반대로 올바른 경로 없이 오답을 출력.  
- **고비용**: 10<sup>11</sup>개 이상 모델만 가능, 실시간 애플리케이션에 적용 어려움.  
- **프롬프트 민감도**: 예시 스타일·순서·수에 따라 성능 변동 발생.  
- **사슬 생성 오류**: 약 54%의 오답은 의미 이해 오류나 논리 불일치에서 비롯됨.

## 3. 일반화 성능 향상 가능성
- **OOD(length) 일반화**: 기호적 과제에서 ‘사슬’ 방식이 더 긴 입력에도 논리적 절차 반복학습을 통해 확장 가능함을 시연.  
- **모델 스케일**: 62B→540B로 확장 시, 의미 이해 오류·단계 누락 오류가 대폭 감소, 대형 모델이 더 복잡한 추론 패턴 학습.  
- **추가적 개선**: 외부 계산기 연동(post-hoc calculator)으로 산술 오류 보완, 다수의 사슬 후보 생성 후 검증(verifier) 적용으로 정확성·일관성 강화 가능.

## 4. 향후 연구에 미치는 영향 및 고려 사항
- **추론형 NLP 발전**: 단일 체크포인트로 다양한 추론 과제에 대응하는 ‘통합적(reasoning-capable)’ 모델 연구 촉진.  
- **프롬프트 자동화**: 사슬 예시 자동 생성·검증 기법 개발 필요.  
- **소형화 연구**: 사슬 능력을 유지·전달하는 경량화 모델·지식 증류 기법 탐색.  
- **신뢰성 개선**: 체계적 오류 분석·사슬 신뢰도 측정·다중 사슬 간 합의(self-consistency) 알고리즘 강화로 사실성 강화.  
- **안전성·책임성**: 잘못된 추론 유출을 방지하기 위한 검증·감독 체계 구축.  

이 논문은 “자연어 사슬”을 통해 대규모 언어 모델의 다단계 추론 능력을 획기적으로 확장했으며, 향후 NLP에서 추론, 검증, 자동화된 프롬프트 설계 연구의 새로운 전기를 마련했다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/2890ad72-6317-4024-889e-ee2d41d3d239/2201.11903v6.pdf)
