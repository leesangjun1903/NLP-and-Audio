# Gold-medalist Performance in Solving Olympiad Geometry with AlphaGeometry2

**핵심 주장 및 주요 기여**  
AlphaGeometry2(AG2)는 국제수학올림피아드(IMO) 기하 문제(2000–2024년)에서 84% 해답률을 달성하여 평균 금메달리스트를 능가한다.  
1. 도메인 언어 확장: 움직이는 도형, 각·거리·비율의 선형 방정식, 비구성적 문제까지 포괄  
2. 상징적 추론 엔진 최적화: 중복점 처리, 알고리즘 개선, C++ 구현으로 1,180s→3.4s 단축  
3. 대규모 신경언어모델: Gemini 기반 MoE 구조, 300M→수억 예제 합성 데이터 학습  
4. 신규 탐색 알고리즘(SKEST): 서로 다른 탐색 트리 간 지식 공유로 보조구성점 탐색 효율화  
5. 자동 문제 형식화·도식화: Gemini로 33/44 IMO 문제 자동 형식화, 비구성적 문제 순차적 수치 최적화로 43/44 도식 자동 생성  

## 1. 해결하고자 한 문제  
- **한계**: AG1은 전체 IMO 기하 문제의 66%만 형식화·추론 가능, 54% 해답률  
- **목표**: 모든 구성·비구성 문제에 대해 형식화→도식화→추론 과정을 완전 자동화하고 해답률 80% 이상 달성  

## 2. 제안 방법

### 2.1. 확장된 도메인 언어  
-  보조 변수 찾기를 위한 질의(predicate) 종류를 9→30개로 확대  
  - acompute, rcompute: “각도 x 찾기”, “비율 x 찾기”  
  - distmeq, distseq, angeq: 선형 결합 로그거리·거리·각 방정식  
  - locus형 질의 11종(Table 2), “점이 움직일 궤적” 표현  
  - overlap·sameclock 등 위상·비퇴화 조건 명시  

### 2.2. 자동 형식화 및 도식화  
- **자동 형식화**: Gemini 모델 few-shot prompting으로 자연어→AG 언어, 44문제 중 33문제 자동 변환  
- **도식화**:  
  1) 3가지 초기화(random, 순차·휴리스틱)로 점 좌표 샘플링  
  2) 제약 함수를 quadratic loss로 정의 → ADAM→Levenberg–Marquardt 최적화  
  3) 44문제 중 43문제 1시간 내 자동 도식 생성  

### 2.3. 강화된 상징적 엔진(DDAR2)  
- **중복점 처리**: 두 다른 이름의 동일점 사용 허용  
- **알고리즘 최적화**:  
  - 유사 삼각형 탐색 O(N³)→해시 기법  
  - 순환사변형 탐색 해시 기법  
- **C++ 구현**: pybind11 연동, 300배 속도 향상  
  평균 처리시간: 1,179.6s→3.45s  

### 2.4. 소설 탐색 알고리즘 (SKEST)  
```
Shared Knowledge Ensemble of Search Trees
```
- 서로 다른 LM 설정(단일/다중 보조점, 얕게 넓게 vs 깊게 좁게)으로 병렬 트리 탐색  
- 각 노드 실패 시 증명한 사실(shared facts) 공유→전체 탐색 효율화  

### 2.5. 대규모 합성 데이터 및 언어모델  
- **데이터**: 무작위 도식→DDAR로 완전 추론→역추적 minimal proof, locus 정리 포함 →300M→수억 예제  
- **모델**: Gemini 기반 sparse Mixture-of-Experts, 매개변수 수백M~수십B  
  - Natural‐language vs AG‐language 토크나이저 실험, 성능 유사  
  - 수학 특화 사전학습 모델→AG 데이터 fine-tuning 상호 보완  

## 3. 성능 및 한계  
- **IMO-AG-50**(2000–2024) 문제 50개 중 **42개** 해결(84%) → 평균 금메달리스트 40.9문제 상회  
- **DDAR 단독**: 16개, TongGeometry: 30개  
- **미해결**: 2개 형식화 가능하나 DDAR 확장 필요(역투영·사영·근축 등), 6개 형식화 불가(부등식·비선형·n 변수)  
- **학습 곡선**: 200M 토큰만으로 27문제 해결 가능  

## 4. 일반화 성능 향상 관점  
- **도메인 언어 독립성**: 토크나이저·언어 설계 제약 없이 자연어 학습만으로 동일 성능  
- **모델 앙상블 효과**: 사전학습 vs scratch vs multi‐modal 모델 간 보조점 제안 상이 → 지식 공유로 향상  
- **합성 데이터 확장성**: 무작위 도식 기반으로 새로운 정리·문제 유형 자동 생성 가능  
- **SKEST 구조**: 다양한 탐색 전략 조합으로 novel subproblem 탐색 가능성 확대  

## 5. 향후 연구 영향 및 고려사항  
- **영향**  
  - 기호추론·합성데이터·LM의 결합으로 복잡 수리추론의 새로운 패러다임 확립  
  - 자연어 입력→정형화→추론→검증 전 과정 자동화 가능성 제시  
- **고려사항**  
  - 비선형·부등식·가변점 명세 언어 확장  
  - DDAR에 역투영·프로젝티브 기하·radical axis 추가  
  - 강화학습으로 탐색 정책 최적화, subproblem 분할 전략 연구  
  - auto-formalization 정확도 향상을 위한 교사강화(fine-tuning)  
  
AlphaGeometry2의 성과는 AI 기반 수학추론 연구에 큰 전기를 마련했으며, 도메인 언어 설계·합성 데이터·탐색 알고리즘 설계가 상호보완적으로 작용해 복잡 문제 해결 역량을 극대화할 수 있음을 보여준다. 앞으로 비구성적·비유클리드 기하로의 확장 및 탐색 정책 강화는 다음 과제다.

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/7b3ea691-f254-4b77-bb91-b7db23451053/2502.03544v2.pdf
