# TABERT: Pretraining for Joint Understanding of Textual and Tabular Data

**핵심 주장 및 주요 기여**  
TABERT는 자연어 문장과 준(半)구조화된 표 데이터를 동시에 표현할 수 있는 사전학습 언어 모델이다.  
-  텍스트 전용 BERT를 확장해, 표 스키마(컬럼 이름·타입)와 표 내용(셀 값)을 함께 인코딩하도록 설계했다.  
-  2600만 개의 웹표(위키피디아·CommonCrawl)와 주변 문장으로 학습해, 텍스트와 표 간 정렬 정보를 사전학습 단계에서 습득한다.  
-  “콘텐츠 스냅샷”을 통해 입력문과 가장 유관한 행을 선택해 인코딩하고, 수직(self-aligned) 어텐션으로 행 간 정보를 융합한다.  

***

## 1. 해결하고자 하는 문제  
기존 대형 언어 모델(LM)은 자유형 텍스트에 최적화되어 있어,  
-  표의 구조적 속성(컬럼 스키마·셀 값)과 자연어 질문 간 연관성을 학습하지 못하고  
-  전체 행을 Transformer로 인코딩하기엔 계산량이 과도하다.  
따라서 텍스트+표 복합 질의(예: Text-to-SQL, WikiTableQuestions)에서 충분한 표현력을 내지 못한다.

***

## 2. 제안 방법

### 2.1 표 인코딩 전략  
1. **콘텐츠 스냅샷(content snapshot)**  
   -  입력 질문과 3-그램 겹침 비율이 높은 상위 K개 행(또는 K=1일 때 합성 행)만 선택  
2. **행 선형화(row linearization)**  
   -  각 행을 `[CLS] 질문 SEP (컬럼명｜타입｜셀값) SEP …` 형식으로 변환  
3. **수직(self-aligned) 어텐션**  
   -  기본 BERT 층으로 각 행별 토큰·셀 인코딩 → 행별 출력 벡터 생성  
   -  같은 컬럼(또는 같은 질문 토큰)에 대응하는 벡터들끼리 수직 어텐션 레이어 V회 반복  

### 2.2 사전학습 목적함수  
- MLM(Masked Language Modeling): 질문 문장 토큰 예측  
- MCP(Masked Column Prediction): 20개 컬럼 이름·타입 예측  
- CVR(Cell Value Recovery): MCP로 마스킹된 컬럼의 셀 값 복원  

***

## 3. 모델 구조  
TABERTBase & TABERTLarge (BERTBase/Large 초기화)  
-  K=1(합성 행) vs. K=3(실제 행) 옵션  
-  수직 어텐션 레이어: K=3 일 때 V=3, K=1 일 때 생략  
-  출력: 질문 토큰 표현, 컬럼 표현(셀 벡터 풀링), 표 전체 표현([CLS])  

***

## 4. 성능 향상 및 한계

### 4.1 Text-to-SQL (SPIDER)  
-  BERTBase → TABERTLarge(K=3)로 교체 시, Exact-Match 61.8% → 65.2% (+3.4%) 상승.[1]
-  콘텐츠 스냅샷 사용 시 컬럼 선택 정확도 86.4% → 87.4%로 개선.  

### 4.2 약지도 학습 (WikiTableQuestions)  
-  MAPO 기반 모델에 적용 시 Execution Accuracy 49.4% → 52.3%로 대폭 향상.  
-  기존 앙상블 최고 46.9%를 단일 모델로 능가.  

### 4.3 한계  
- 사전학습 데이터 품질: 웹표 노이즈가 높아 전처리 제약 발생  
- 큰 표 처리: K가 커질수록 추가 계산 부담  
- 다국어 확장: 현재 영어 중심, 타 언어 질문-스키마 매칭 추가 필요  

***

## 5. 일반화 성능 향상 가능성  
- **콘텐츠 스냅샷**은 입력 질문과의 핵심 정보 정렬을 강화해, 도메인 전환 시에도 관련 행만 추출 가능  
- **수직 어텐션**을 통해 표 내부의 구조적 관계를 모델 내부에서 학습, 다양한 스키마 변형에도 견고  
- 사전학습 시 대규모 표-텍스트 병렬 데이터 확보가 일반화 성능의 핵심  

***

## 6. 향후 연구 및 고려사항  
1. **다국어·크로스 도메인**: 비영어 질문 및 혼합 언어 스키마 대응  
2. **표-텍스트 상호작용 과제**: 테이블 검색, 테이블-텍스트 생성, 테이블 기반 QA 등 확장  
3. **노이즈 정제 및 증강**: 웹표 전처리 품질 개선, 유사도 기반 데이터 증강  
4. **경량화·효율화**: K 값 자동 최적화, 저비용 어텐션 구조 연구  

***

**참고 문헌**  
 SPIDER Text-to-SQL 공개 개발셋 성능 비교.[1]
 WikiTableQuestions 실행정확도 비교.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/99109303-573b-4bcd-8a9e-7cdbcaf6d1c1/2005.08314v1.pdf)
