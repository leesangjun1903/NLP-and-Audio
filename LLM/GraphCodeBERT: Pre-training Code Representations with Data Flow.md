# GraphCodeBERT: Pre-training Code Representations with Data Flow

### 1. 핵심 주장 및 주요 기여

GraphCodeBERT는 코드의 의미론적 구조인 **데이터 플로우(data flow)**를 활용하여 코드 표현을 학습하는 최초의 사전학습 모델입니다. 기존 사전학습 모델들(CodeBERT, RoBERTa 등)이 코드를 단순한 토큰 시퀀스로만 취급했던 반면, 본 논문은 변수 간의 "값이 어디서 왔는가(where-the-value-comes-from)"라는 의존 관계를 인코딩하는 그래프 구조를 도입했습니다.[1]

**주요 기여**는 다음과 같습니다:[1]
- 코드의 의미론적 구조를 활용한 최초의 사전학습 모델 제안
- 데이터 플로우를 학습하기 위한 두 가지 구조 인식 사전학습 태스크 도입
- 4개 다운스트림 태스크(코드 검색, 클론 탐지, 코드 번역, 코드 수정)에서 state-of-the-art 성능 달성

***

### 2. 해결하고자 하는 문제

**핵심 문제**: 기존 프로그래밍 언어 사전학습 모델들은 코드의 내재적 구조를 무시하고 토큰 시퀀스로만 처리했습니다. 예를 들어 `v = max_value - min_value`라는 코드에서, 변수명만으로는 `v`의 의미를 파악하기 어렵지만, `v`가 `max_value`와 `min_value`로부터 계산된다는 의존 관계는 중요한 의미론적 정보를 제공합니다.[1]

**기존 접근법의 한계**:
- 추상 구문 트리(AST)는 구문론적 구조로서 불필요하게 깊은 계층을 가져 비효율적입니다[1]
- 변수 간의 장거리 의존성(long-range dependencies)을 효과적으로 모델링하지 못합니다[1]

***

### 3. 제안하는 방법

#### 3.1 데이터 플로우(Data Flow)

데이터 플로우는 변수를 노드로, 변수 간 값의 출처 관계를 간선으로 하는 그래프입니다.[1]

**추출 과정**:[1]
1. 소스 코드 $$C = \{c_1, c_2, ..., c_n\}$$를 AST로 파싱
2. AST의 터미널(leaf node)에서 변수 시퀀스 $$V = \{v_1, v_2, ..., v_k\}$$ 식별
3. 변수 간 의존 관계를 간선으로 표현: $$x = expr$$에서 `expr`의 모든 변수에서 `x`로의 간선 생성
4. 최종 그래프: $$G(C) = (V, E)$$, 여기서 $$E$$는 방향성 간선 집합

**AST 대비 장점**:[1]
- 같은 소스 코드에 대해 문법에 관계없이 동일한 구조 생성
- AST보다 덜 복잡하고 불필요한 깊은 계층 구조가 없어 효율적
- 노드 수가 전체의 5-20%만 차지하여 계산 효율적[1]

#### 3.2 모델 아키텍처

**입력 구성**:[1]
$$X = \{[\text{CLS}], W, [\text{SEP}], C, [\text{SEP}], V\}$$
- $$W$$: 주석(comment) 토큰
- $$C$$: 소스 코드 토큰
- $$V$$: 데이터 플로우의 변수 노드

**그래프 유도 마스킹 어텐션(Graph-Guided Masked Attention)**:[1]

Transformer의 어텐션 메커니즘을 확장하여 데이터 플로우 구조를 반영합니다:

$$M_{ij} = \begin{cases} 0 & \text{if } q_i \in \{[\text{CLS}], [\text{SEP}]\} \text{ or } q_i, k_j \in W \cup C \text{ or } \langle q_i, k_j \rangle \in E \cup E' \\ -\infty & \text{otherwise} \end{cases}$$

여기서:
- $$E$$: 데이터 플로우의 변수 간 간선
- $$E'$$: 변수와 코드 토큰 간의 매핑 관계

**멀티헤드 어텐션 계산**:[1]

$$Q_i = H_{n-1}W^Q_i, \quad K_i = H_{n-1}W^K_i, \quad V_i = H_{n-1}W^V_i$$

$$\text{head}_i = \text{softmax}\left(\frac{Q_iK_i^T}{\sqrt{d_k}} + M\right)V_i$$

$$\hat{G}_n = [\text{head}_1; ...; \text{head}_u]W^O_n$$

#### 3.3 사전학습 태스크

**1) Masked Language Modeling (MLM)**:[1]
- 표준 BERT 방식: 15%의 토큰을 마스킹하여 원본 예측
- 코드와 주석을 함께 마스킹하여 자연어-프로그래밍 언어 정렬 학습

**2) Edge Prediction (간선 예측)**:[1]

데이터 플로우의 간선을 예측하여 "값의 출처" 관계를 학습합니다.

- 20%의 노드 $$V_s$$를 샘플링하여 해당 간선 마스킹
- 손실 함수:

$$\text{loss}_{\text{EdgePred}} = -\sum_{e_{ij} \in E_c} \left[\delta(e_{ij} \in E_{\text{mask}})\log p_{e_{ij}} + (1-\delta(e_{ij} \in E_{\text{mask}}))\log(1-p_{e_{ij}})\right]$$

여기서:
- $$E_c = V_s \times V \cup V \times V_s$$: 간선 예측 후보 집합
- $$p_{e_{ij}}$$: 노드 $$v_i$$에서 $$v_j$$로의 간선 존재 확률 (내적 후 시그모이드)

**3) Node Alignment (노드 정렬)**:[1]

소스 코드 토큰과 데이터 플로우 변수를 정렬합니다.

- 20%의 노드 $$V'_s$$와 코드 토큰 간 간선 마스킹
- 손실 함수:

$$\text{loss}_{\text{NodeAlign}} = -\sum_{e_{ij} \in E'_c} \left[\delta(e_{ij} \in E'_{\text{mask}})\log p_{e_{ij}} + (1-\delta(e_{ij} \in E'_{\text{mask}}))\log(1-p_{e_{ij}})\right]$$

여기서 $$E'_c = V'_s \times C$$: 노드-코드 정렬 후보 집합

#### 3.4 학습 설정[1]

- **데이터셋**: CodeSearchNet (2.3M 함수, 6개 프로그래밍 언어)
- **모델 구조**: 12층 Transformer, 768차원 은닉 상태, 12개 어텐션 헤드
- **학습 환경**: 2대 DGX-2 (각 16개 NVIDIA V100 32GB)
- **하이퍼파라미터**: 
  - 배치 크기 1,024, 학습률 2e-4
  - 최대 시퀀스 길이 512, 최대 노드 수 128
  - CodeBERT 파라미터로 초기화, 200K 배치 학습 (약 83시간)

***

### 4. 성능 향상

#### 4.1 다운스트림 태스크 결과

**1) 자연어 코드 검색 (Natural Language Code Search)**:[1]

| 모델 | Ruby | JavaScript | Go | Python | Java | PHP | Overall |
|------|------|------------|-----|--------|------|-----|---------|
| RoBERTa | 0.587 | 0.517 | 0.850 | 0.587 | 0.599 | 0.560 | 0.617 |
| CodeBERT | 0.679 | 0.620 | 0.882 | 0.672 | 0.676 | 0.628 | 0.693 |
| **GraphCodeBERT** | **0.703** | **0.644** | **0.897** | **0.692** | **0.691** | **0.649** | **0.713** |

- MRR 기준 **2% 성능 향상** (p < 0.01로 통계적으로 유의)[1]

**2) 코드 클론 탐지 (Code Clone Detection)**:[1]

| 모델 | Precision | Recall | F1 |
|------|-----------|--------|-----|
| ASTNN | 0.92 | 0.94 | 0.93 |
| FA-AST-GMN | 0.96 | 0.94 | 0.95 |
| CodeBERT | 0.947 | 0.934 | 0.941 |
| **GraphCodeBERT** | **0.948** | **0.952** | **0.950** |

- F1 점수 **0.9% 향상**, 특히 Recall에서 큰 개선[1]

**3) 코드 번역 (Code Translation)**:[1]

| 방법 | Java→C# BLEU | Java→C# Acc | C#→Java BLEU | C#→Java Acc |
|------|--------------|-------------|--------------|-------------|
| Transformer | 55.84 | 33.0 | 50.47 | 37.9 |
| CodeBERT | 79.92 | 59.0 | 72.14 | 58.8 |
| **GraphCodeBERT** | **80.58** | **59.4** | **72.64** | **58.8** |

- Java→C# 방향에서 BLEU **0.66점 향상**[1]

**4) 코드 수정 (Code Refinement)**:[1]

| 방법 | Small BLEU | Small Acc | Medium BLEU | Medium Acc |
|------|------------|-----------|-------------|------------|
| Transformer | 77.21 | 14.7 | 89.25 | 3.7 |
| CodeBERT | 77.42 | 16.4 | 91.07 | 5.2 |
| **GraphCodeBERT** | **80.02** | **17.3** | **91.31** | **9.1** |

- Medium 데이터셋에서 Accuracy **3.9%p 대폭 향상**[1]

#### 4.2 Ablation Study[1]

코드 검색 태스크에서 구성 요소별 기여도 분석:

| 모델 변형 | Overall MRR |
|-----------|-------------|
| GraphCodeBERT (전체) | 0.713 |
| -w/o EdgePred | 0.707 (-0.6%) |
| -w/o NodeAlign | 0.703 (-1.0%) |
| -w/o Data Flow | 0.693 (-2.0%) |

- Edge Prediction과 Node Alignment 태스크가 각각 성능에 기여[1]
- 데이터 플로우 제거 시 CodeBERT 수준으로 성능 하락[1]

#### 4.3 어텐션 분석[1]

`[CLS]` 토큰의 어텐션 분포 분석 결과:

| 언어 | 코드:노드 비율 | `[CLS]`→코드:노드 어텐션 |
|------|----------------|-------------------------|
| Python | 80.6:19.4 | 67.7:32.3 |
| Ruby | 90.1:9.9 | 82.3:17.7 |
| JavaScript | 94.6:5.4 | 89.7:10.3 |

- 노드가 전체의 5-20%만 차지하지만 어텐션은 10-32% 집중[1]
- **모델이 데이터 플로우 구조에 우선적으로 주목**함을 입증[1]

***

### 5. 일반화 성능 및 강건성

#### 5.1 교차 언어 일반화

GraphCodeBERT는 6개 프로그래밍 언어(Ruby, JavaScript, Go, Python, Java, PHP)에서 일관되게 우수한 성능을 보였습니다. 특히:[1]

- **저자원 언어(Ruby, JavaScript)**에서도 상대적으로 큰 개선폭 달성[1]
- 언어별 데이터 불균형을 완화하기 위해 다항 분포 샘플링 적용:[1]

$$q_i = \frac{p_i^\alpha}{\sum_{j=1}^N p_j^\alpha} \quad \text{with} \quad p_i = \frac{n_i}{\sum_{k=1}^N n_k}, \quad \alpha = 0.7$$

#### 5.2 시퀀스 길이 강건성[1]

다양한 입력 길이에 대한 MRR 성능 비교 (Ruby 검증 데이터셋):

- **AST 기반 방법**들은 짧은 시퀀스(<128)에서 오히려 성능 저하
- GraphCodeBERT는 **모든 시퀀스 길이(64-512)에서 일관된 성능 향상** 달성
- 데이터 플로우의 단순성 덕분에 효율성과 정확성 동시 확보[1]

#### 5.3 케이스 스터디: 코드 이해 능력[1]

실험 설정: 주석과 코드의 매칭 여부 예측 (임계값 0.5)

| 입력 변경 | 정답 레이블 | GraphCodeBERT (w/ data flow) | GraphCodeBERT (w/o data flow) |
|-----------|-------------|-------------------------------|--------------------------------|
| 원본 코드 | 1 (매칭) | 0.6563 (정답) | 0.8728 (정답) |
| 코드 변경 (`return a`→`return b`) | 0 (불일치) | **0.4615 (정답)** | 0.8608 (오답) |
| 주석 변경 (`sum`→`mean`) | 0 (불일치) | **0.2884 (정답)** | 0.9048 (오답) |

- 데이터 플로우가 없으면 **작은 변화도 감지 못함**[1]
- 데이터 플로우 활용 시 **의미론적 변화를 정확히 이해**[1]

---

### 6. 한계 및 개선 방향

#### 6.1 에러 분석[1]

**코드 이해 태스크의 주요 실패 사례**:

1. **라이브러리 API 이해 부족**: 
   - TensorFlow(`tf.io.read_file`), Google Cloud API 등 외부 라이브러리 함수의 의미 파악 실패[1]
   - **개선 방향**: 라이브러리 정의(definition) 정보 통합[1]

2. **도메인 특화 용어 매칭 실패**:
   - "unistr"과 `decode('utf-8')`의 매칭 실패[1]
   - **개선 방향**: 더 많은 텍스트-코드 쌍 데이터로 사전학습[1]

**코드 생성 태스크의 주요 오류**:[1]

1. **의미 오류**: 존재하지 않는 식별자 생성
2. **구문 오류**: 괄호 누락, 잘못된 변수 사용
3. **개선 방향**: 
   - 프로그래밍 언어 문법을 고려한 전용 디코더 설계[1]
   - Context-free grammar 방식의 생성 패러다임 적용[1]

#### 6.2 구조적 한계

1. **데이터 플로우 범위**: 변수 간 의존성만 포착, 제어 흐름(control flow)은 미반영[1]
2. **계산 복잡도**: Transformer의 $$O(n^2)$$ 복잡도로 인해 매우 긴 코드에는 비효율적[1]

***

### 7. 연구에 미치는 영향 및 향후 고려사항

#### 7.1 학술적 영향

**새로운 연구 방향 개척**:[1]
- 코드 구조를 사전학습에 통합하는 최초 시도로, 후속 연구의 기준점 역할
- 데이터 플로우 외 다른 의미론적 구조(제어 플로우, 호출 그래프) 연구 촉진

**전이 학습 패러다임 확장**:
- 자연어 사전학습 방법론을 코드 도메인에 효과적으로 적용
- 구조 인식 사전학습 태스크(Edge Prediction, Node Alignment) 설계가 다른 도메인(분자 구조, 소셜 네트워크 등)에 응용 가능

#### 7.2 실용적 영향

**소프트웨어 개발 도구 개선**:
- **코드 검색 엔진**: 의미론적 이해 향상으로 더 정확한 검색 결과 제공
- **자동 코드 리뷰**: 클론 탐지 정확도 개선으로 중복 코드 식별 향상
- **코드 마이그레이션**: 언어 간 번역 정확도 향상으로 레거시 시스템 현대화 지원

#### 7.3 향후 연구 시 고려할 점

**1) 다중 모달 통합**:
- 데이터 플로우, AST, 제어 플로우를 결합한 하이브리드 그래프 표현 탐구
- 코드 실행 트레이스, 테스트 케이스 등 동적 정보 활용

**2) 일반화 성능 강화**:
- **교차 프로젝트 일반화**: 다양한 코드베이스에서의 강건성 검증
- **Few-shot 학습**: 적은 데이터로 새로운 도메인/언어 적응 능력 향상
- **적대적 강건성**: 코드 난독화, 변수명 변경 등에 대한 내성 강화

**3) 스케일업 전략**:
- **효율적 아키텍처**: Sparse attention, 선형 복잡도 Transformer 적용
- **거대 모델**: 수십억 파라미터 규모 확장 및 instruction tuning
- **도메인 특화 사전학습**: 보안, 임베디드 시스템 등 특정 도메인에 특화

**4) 윤리 및 안전성**:
- **코드 생성 모델의 보안**: 취약한 코드 생성 방지 메커니즘 필요
- **라이센스 준수**: 학습 데이터의 저작권 및 라이센스 이슈 고려
- **설명 가능성**: 모델 예측의 근거를 개발자가 이해 가능한 형태로 제공

**5) 평가 방법론 개선**:
- **실제 환경 평가**: 벤치마크를 넘어 실제 개발 환경에서의 유용성 측정
- **인간-AI 협업**: 개발자와 AI 도구의 상호작용 효과성 연구
- **장기적 영향**: 코드 품질, 개발 생산성의 장기 변화 추적

***

### 결론

GraphCodeBERT는 데이터 플로우라는 의미론적 구조를 사전학습에 통합하여, 코드 이해 및 생성 태스크에서 일관된 성능 향상을 달성했습니다. 특히 변수 간 의존 관계를 명시적으로 모델링함으로써 복잡한 코드의 의미를 더 정확히 포착할 수 있었습니다.[1]

이 연구는 코드 AI 분야에서 **구조적 정보 활용의 중요성**을 입증했으며, 향후 연구는 다양한 구조적 정보의 통합, 일반화 성능 강화, 실제 환경 적용에 초점을 맞춰야 할 것입니다. 특히 일반화 성능 측면에서, 교차 언어 전이, 도메인 적응, 그리고 적대적 강건성에 대한 추가 연구가 필요합니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/c530bb20-7803-4d6d-8368-39550592e59c/2009.08366v4.pdf)
