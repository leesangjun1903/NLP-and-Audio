# Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism

**핵심 요약**  
이 논문은 메모리 한계를 해결하고 대규모 트랜스포머 언어 모델(최대 8.3B 파라미터)을 효율적으로 학습하기 위해 단일 GPU에서 실행 가능한 모델을 다수의 GPU에 분산하는 **간단한 인트라-레이어 모델 병렬화 기법**을 제안한다. 주요 기여는[1]
- PyTorch에서 최소한의 통신 연산(all-reduce) 추가만으로 최대 76%의 스케일링 효율을 달성  
- GPT-2 유사 구조(8.3B)와 BERT 유사 구조(3.9B)에서 SOTA 성능 확보  
- BERT 계열 모델의 레이어 정규화 위치 재배치를 통해 대규모 모델에서의 안정적 학습 보장  

***

## 1 문제 정의  
- **메모리 병목**: 수십억 파라미터 트랜스포머는 단일 GPU 메모리(32 GB)를 초과  
- **기존 Parallelism 한계**: 파이프라인 병렬(GPipe)·컴파일러 의존 기법은 복잡도 및 효율 저하  
- **목표**: 메모리 분산뿐 아니라 연산 병목을 최소화하며 간단하게 구현 가능한 모델 병렬법 제시[1]

***

## 2 제안 기법  
### 2.1 MLP 블록 병렬화  
첫 번째 GEMM $$Y=\mathrm{GeLU}(X A)$$을 열(column) 차원으로 분할:  

$$
A = [A_1, A_2],\quad Y = [\mathrm{GeLU}(X A_1),\,\mathrm{GeLU}(X A_2)]
$$  

두 번째 GEMM은 행(row) 분할 후 결과를 all-reduce하여 결합. 이로써 순전파·역전파당 각각 한 번의 all-reduce만 필요.[1]

### 2.2 Self-Attention 블록 병렬화  
쿼리·키·값 연산의 GEMM을 **어텐션 헤드별**로 분할하여 로컬에서 처리하고, 출력 선형층 GEMM은 행 분할. 전체 레이어당 순·역전파에서 총 4회의 통신 연산 수행.[1]

### 2.3 임베딩 및 로짓 처리  
입력 임베딩 $$E\in\mathbb{R}^{H\times V}$$을 어휘 차원으로 열 분할하고, 로짓 계산 시 전통적 all-gather 대신 **교차 엔트로피와 결합**하여 배치·시퀀스 차원의 스칼라 손실만 교환함으로써 통신량 대폭 절감.[1]

***

## 3 모델 구조  
- GPT-2 유사 디코더: 최대 72개 레이어, 은닉 크기 3072, 24개 헤드(8.3B)  
- BERT 유사 인코더: 최대 48개 레이어, 은닉 크기 2560, 40개 헤드(3.9B)  
- 레이어 정규화 위치: 원본 BERT(a)에서 잔차 연결 후 정규화 → 개정(b) 정규화→잔차 연결 순으로 변경하여 대규모에서 학습 안정화 확인.[1]

***

## 4 성능 향상  
- **스케일링 효율**: 8.3B 모델 8-way 모델 병렬로 76% 효율, 모델+데이터 병렬(512 GPU)로도 74% 유지.[1]
- **언어 모델링**: WikiText103 perplexity 10.81(종전 15.79), LAMBADA 정확도 66.5%(종전 63.2%).[1]
- **BERT downstream**: RACE 정확도 단일 89.5%→앙상블 90.9%, GLUE·SQuAD 등 대규모 모델일수록 성능 향상.[1]

***

## 5 한계 및 일반화 성능  
- **통신 비용**: 헤드 수 증가 시 GEMM 크기 감소와 softmax 통신량 증가로 효율 소폭 하락.[1]
- **고정 컨텍스트 길이**: 트랜스포머 평가 시 슬라이딩 윈도우와 오버랩 전략 필요  
- **일반화**: 대규모 모델은 훈련 데이터 중복 제거(LSH)·mixed precision 적용에도 여전히 어휘 범위·장문 이해에서 더 많은 연구 필요.[1]

***

## 6 향후 영향 및 고려사항  
- **더 거대한 모델**(16B+) 학습: 하이브리드 인트라-레이어·인터-레이어 병렬화 연구  
- **다양한 아키텍처**(XLNet, T5 등) 적용 및 대화·생성 QA 과제 성능 검증  
- **지식 증류**: 대형 모델로부터 소형 모델로 전이해 효율적 배포  
- **Optimizer·메모리 최적화**: 대규모 분산 학습을 위한 새로운 최적화 알고리즘과 메모리 관리 기법 개발 필요

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/6a0efb02-2b8f-44b8-beb7-aa3bbb4338c2/1909.08053v4.pdf)
