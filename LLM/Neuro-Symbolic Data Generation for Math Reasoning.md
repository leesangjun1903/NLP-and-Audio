# Neuro-Symbolic Data Generation for Math Reasoning

### 1. 논문의 핵심 주장 및 주요 기여[1]

이 논문은 LLM의 수학적 추론 능력 부족이 **근본적인 한계인지, 아니면 고품질 수학 데이터의 부족에서 비롯된 것인지**를 규명하고자 합니다. 주요 기여는 다음과 같습니다:

1. **다양성-타당성 딜레마 해결**: 기존 방법은 LLM 기반 재표현으로 다양성을 확보하지만 타당성을 보장하지 못하고, 템플릿 기반 방법은 타당성을 보장하되 다양성이 제한됩니다. 본 논문은 이를 동시에 해결합니다.

2. **신경-기호 프레임워크**: LLM의 자연어 변환 능력과 기호 솔버의 정밀한 추론 능력을 결합하여 자동 생성 중 데이터 품질을 보장합니다.

3. **실증적 성과**: 620K 예제의 생성 데이터로 LLaMA-2와 Mistral을 미세조정하여 기존 오픈소스 SOTA 모델을 크게 상회하고, Mistral-7B는 GPT-3.5-Turbo를 GSM8K에서 2.4% 상향 초과합니다.

### 2. 논문이 해결하는 문제 및 제안 방법

#### 2.1 문제 정의[1]

LLM의 수학적 추론 능력은 여전히 만족할 수준 이하인데, 이는 고품질 데이터의 극심한 부족 때문일 수 있습니다. 기존 데이터 생성 방법은 다음 두 가지 한계를 갖습니다:

- **프롬프트 기반 방법**: 오류 유도 가능 (다양성 확보 ✓, 타당성 ✗)
- **템플릿 기반 방법**: 제한된 다양성 (타당성 ✓, 다양성 ✗)

#### 2.2 제안 방법: 신경-기호 프레임워크[1]

프레임워크는 세 단계로 구성됩니다:

**1단계: 형식화 (Formalization)**

자연언어 문제를 SMT-LIB 형식으로 변환합니다. 표준 형식은:

$$\text{Goal: } g := \text{min} | \text{max} | \text{solve } f(x)$$

$$\text{Constraints: } h := h_1 \land h_2 | h_1 \lor h_2 | \text{ite}(h_1, h_2, h_3) | \forall x. e_1(x) \triangleright\triangleleft e_2(x) | e_1 \triangleright\triangleleft e_2$$

$$\text{Expressions: } e := c | x := (x_1, \ldots, x_n) | \text{foo}(x) | e_1 \oplus e_2$$

**2단계: 변이 (Mutation)**

형식화된 문제를 변이시켜 다양한 난이도의 새로운 문제를 생성합니다. 변이는 두 부분으로 구성:

**합리화 (Complication)**:
원자 제약 조건 $$h = e_1 \triangleright\triangleleft e_2$$에 보조변수를 도입하여:

$$\tilde{h} = e_1 \triangleright\triangleleft (e_2 \oplus e')$$

여기서 $$e' = \text{foo}(z)$$는 해석된 함수이고, $$\oplus \in \{+, -, \times, \div\}$$는 랜덤 연산자입니다.

예시로, 원래 문제 (M1)에서:

$$\begin{cases} a(b + c) = 152 \\ b(c + a) = 162 \\ c(a + b) = 170 \\ a, b, c \in \mathbb{N}^+ \end{cases}$$

보조변수를 도입하면 (M2):

$$\begin{cases} a(b + c) \oplus_1 e'_1(z_1) = 152 \\ b(c + a) \oplus_2 e'_2(z_2) = 162 \\ c(a + b) \oplus_3 e'_3(z_3) = 170 \\ a, b, c \in \mathbb{N}^+, z_1, z_2, z_3 \in \mathbb{R} \end{cases}$$

기호 솔버가 $$(z_1, z_2, z_3)$$의 해를 찾으면 새로운 문제가 완성됩니다.

**간소화 (Simplification)**:
표현식 감소와 제약 감소를 수행합니다:
- 상수/변수 폴딩: $$x + 0 \Rightarrow x$$
- 식 전개: $$(x + 1)^2 \Rightarrow x^2 + 2x + 1$$
- 가우스 소거: $$x = 2 \land y \leq x + z \Rightarrow y \leq 2 + z$$

**핵심 혁신: 사영 MCMC (Projected MCMC)**

다양성을 보장하기 위해 사영 MCMC를 사용하여 보조변수 솔루션을 생성합니다:

1. 변수 부분 집합을 난수로 교란 (사영된 랜덤 워크)
2. 나머지 부분을 기호 솔버로 재해결 (역 사영)

이는 데이터 생성의 다양성과 타당성을 모두 확보합니다.

**3단계: 비형식화 (Informalization)**

형식화된 문제를 다시 자연언어로 변환합니다. 비형식화 일관성을 향상시키기 위해 6가지 연산을 결합:

| 연산 | 기본 | P1(1-5) | P2(1-3&6) |
|------|------|---------|-----------|
| 변이 | — | ↑ 90.5% | — |
| Few-shot | 75.6% | — | — |
| 주석 생성 | — | ↓ 41.6% | ↓ |
| 수학 지시 | — | ↑ 76.2% | — |
| 문제 수정 | — | ↑ 87.6% | ↑ |
| 변수 새로고침 | — | — | ↑ 97.1% |

### 3. 모델 구조 및 학습 설정[1]

#### 3.1 기호 솔버 통합

프레임워크는 5개 기호 솔버를 통합합니다:
- **Z3**: SMT 솔버
- **CVC5**: 범용 SMT 솔버
- **MathSAT**: 선형 산술 및 이론 추론
- **SymPy**: 기호 수학
- **SciPy**: 수치 최적화

PySMT 프레임워크를 통해 통합되며, 국소 귀결(fuzzy-logic-like strategy)로 등식과 부등식을 손실 함수로 변환합니다.

#### 3.2 데이터셋 생성[1]

**GSM8K 기반:**
- Level-0: 30K (단순화된 문제)
- Level-1~4: 각 100K (점진적 복잡화)
- 총 430K 생성 데이터

**MATH 기반:**
- Level-0~3: 각각 70K, 120K, 120K, 120K
- 총 430K 생성 데이터

**합계: 860K 예제** (620K 실제 사용)

각 문제는:
1. GPT-4가 생성한 자연언어 문제
2. 기호 솔버의 최종 답변
3. GPT-4가 생성하고 기호 솔버로 검증한 추론 경로

#### 3.3 미세조정 설정

- **기본 모델**: LLaMA-2 7B/13B, Mistral 7B
- **에포크**: 3
- **배치 크기**: 128
- **학습률**: 2e-5 (LLaMA), 5e-6 (Mistral)
- **70B 모델**: QLoRA (LoRA rank=96, alpha=16)

### 4. 성능 향상 및 일반화[1]

#### 4.1 RQ1: 효능성 (Efficacy)

| 모델 | 데이터셋 크기 | GSM8K | MATH | 향상도 |
|------|--------------|-------|------|--------|
| WizardMath (LLaMA-2 7B) | >240K | 54.9% | 10.7% | — |
| MetaMath (LLaMA-2 7B) | 395K | 66.5% | 19.8% | — |
| **Our (LLaMA-2 7B)** | **860K** | **79.0%** | **30.4%** | **+10.6%/+10.6%** |
| MetaMath (LLaMA-2 13B) | 395K | 72.3% | 22.4% | — |
| **Our (LLaMA-2 13B)** | **860K** | **84.1%** | **33.7%** | **+10.1%/+11.3%** |
| MetaMath (Mistral 7B) | 395K | 77.7% | 28.2% | — |
| **Our (Mistral 7B)** | **860K** | **86.8%** | **37.3%** | **+3.6%/+4.3%** |

**주목할 점**: Mistral-7B 모델이 GPT-3.5-Turbo (80.8%/34.1%)를 GSM8K에서 6.0%, MATH에서 3.2% 상향 초과

#### 4.2 RQ2: 효율성 (Efficiency)

MetaMathQA와 동일한 데이터 예산(240K/155K)으로 비교:

| 데이터셋 | 방법 | GSM8K | MATH | SVAMP | ASDiv |
|---------|------|-------|------|-------|-------|
| 240K GSM | MMQA | 66.1% | 5.8% | 61.7% | 72.5% |
| GSM | **Ours** | **72.7%** | **8.2%** | **78.8%** | **79.2%** |
| | 향상 | **+6.6%** | **+2.3%** | **+17.1%** | **+6.7%** |

#### 4.3 RQ3: 일반화 능력[1]

**메모리 검출** (Minerva 방법):
- 훈련 데이터셋 BLEU 점수: 0.4~0.6
- 테스트 데이터셋 BLEU 점수: 0.4~0.5
- 결론: 테스트 오염 증거 없음

**도메인 외 평가** (SVAMP, ASDiv, DyVal):
- SVAMP: 높은 성능 유지
- ASDiv: 경쟁력 있는 결과
- DyVal: 12개 사례 중 11개에서 SOTA 달성

#### 4.4 RQ4: 확장성 (Scalability)[1]

데이터 규모 증가에 따른 성능 개선:

| 데이터 크기 | GSM8K | SVAMP | ASDiv | MATH |
|-----------|-------|-------|-------|------|
| 30K | 55% | — | — | — |
| 100K | 60% | 60% | 70% | 5% |
| 170K | 65% | 65% | 74% | 6% |
| 240K | 70% | 70% | 78% | 7% |
| 350K | 75% | 75% | 82% | 8% |

**핵심 발견**: MetaMathQA는 70K 이후 성능 향상이 둔화되지만, 본 방법은 일관된 개선을 유지합니다. 이는 다양한 난이도 레벨의 혼합이 핵심입니다.

난이도별 다양성 이득 분석:
- 동일 난이도 데이터: 데이터 버짓 증가 시 다양성 정체
- 혼합 난이도: 데이터 버짓 증가에 따라 다양성 계속 증가

### 5. 논문의 한계[1]

논문은 다음 세 가지 주요 한계를 인정합니다:

#### 5.1 기호 솔버의 능력 제한

**현재 한계:**
- Z3: gcd, lcm 같은 고차 개념 표현 어려움
- SymPy: 다변량 부등식 해결 어려움
- 기하학 문제 지원 미약 (예: 삼각형 개념 표현 불가)

**MATH 데이터셋 범주별 성과:**

| 범주 | 향상도 |
|------|--------|
| 대수 | +18.2% |
| 세기/확률 | +11.8% |
| **기하** | **+1.0%** |
| 중급 대수 | +12.1% |
| 수론 | +10.6% |
| 사전대수 | +3.2% |
| **미적분** | **+2.5%** |

#### 5.2 변이 표현 제한

**문제점**: 고난이도 문제(대학/IMO 수준) 생성 미흡

**해결책**: 문제 융합(problem fusion) 도입 가능 - 두 형식 문제를 단일 새 문제로 융합

#### 5.3 GPT-4 의존성

**현재 상황**: 비형식화 및 추론 경로 생성에 GPT-4 필요

**완화 방안**:
1. 생성된 형식-비형식 쌍으로 전용 LLM 미세조정
2. 감독 학습 대신 **커리큘럼 학습** 도입
   - 보상: 생성된 솔루션이 기호 솔버와 일치하는지 여부
   - 진행: 다양한 난이도의 문제 점진적 포함

### 6. 최신 연구 기반 영향 및 고려사항

#### 6.1 현재 연구 동향[2][3][4][5][6][7][8][9][10]

**신경-기호 AI의 진화:**

최근 2025년 연구들은 다음 방향으로 발전하고 있습니다:

1. **다중 모달 추론**: 이미지, 텍스트, 로직을 통합하는 신경-기호 시스템 (NSL-CL 모델)[9]

2. **공식 검증 강화**: MATH-VF 프레임워크는 단순히 최종 답변이 아닌 **각 추론 단계의 정확성을 검증**합니다[8][10]

3. **에이전트 기반 데이터 생성**: AgenticMath는 다중 에이전트 시스템으로 30-60K 샘플로 400K 수준의 성능 달성[11][12]

4. **인과적 추론**: CaRing 프레임워크는 신경-기호 통합으로 **인과적 추론 경로의 신뢰성 보장**[5]

#### 6.2 아직 해결되지 않은 문제

**1. 기하학 문제 처리:**
- 현재 방법은 대수 문제에 집중
- 기하학적 개념의 형식화 표준화 필요

**2. 다단계 추론의 검증:**
- 최종 답변 검증은 가능하나, 중간 단계 오류 검출 미흡
- MATH-VF의 단계별 검증 기법 통합 필요

**3. 외부 도구 의존성 감소:**
- 기호 솔버 없이도 작동하는 순수 신경 모델 개발
- 또는 경량 기호 엔진 내장

#### 6.3 향후 연구 시 고려할 점

**1. 다중 기호 체계 지원**

$$\text{형식 언어} \in \{\text{SMT-LIB}, \text{Isabelle}, \text{Coq}, \text{Lean}\}$$

각 형식화 방식의 강점을 활용한 하이브리드 접근

**2. 인터랙티브 정리 증명 통합**[13]

FVEL 프레임워크처럼 Isabelle/Lean 같은 대화형 정리 증명기와 통합하여 더 강력한 검증

**3. 동적 평가 프로토콜**[7]

DyVal 같은 동적 생성 벤치마크로 평가하여 체계적 일반화 성능 측정

**4. 과정 감독 (Process Supervision)**

답변 감독보다 **각 추론 단계 검증**에 가중치 부여로 더 견고한 추론 능력 개발

**5. 커리큘럼 학습 자동화**

문제 난이도 자동 평가 및 학습 진행 최적화 알고리즘 개발

#### 6.4 응용 시나리오

**교육 분야:**
- 학생 맞춤 난이도 수학 문제 자동 생성
- 실시간 풀이 검증 및 피드백

**자동 정리 증명:**
- 연구 문제를 형식적 정리로 변환하여 자동 증명

**산업 응용:**
- 엔지니어링 계산 자동화 및 검증
- 금융 모델 정확성 보증

### 7. 결론

본 논문은 **고품질 데이터의 가용성이 LLM의 수학적 추론 능력의 주요 제약 요소**임을 실증적으로 증명합니다. 신경-기호 프레임워크는 기호 솔버의 정밀성과 LLM의 창의성을 결합하여, 단순 규칙 기반 변이보다 훨씬 더 유연하고 다양한 데이터 생성을 가능하게 합니다.

특히 **사영 MCMC를 통한 보조변수 솔루션 생성**은 데이터 다양성-타당성 딜레마를 우아하게 해결하는 기법입니다. 실험 결과는 동일 규모 기존 방법 대비 10% 이상의 성능 향상을 보여주며, 확장성 분석은 더 큰 데이터로도 계속 개선 가능함을 시사합니다.

향후 연구는 **기하학 및 고급 주제 지원 확장**, **더 강력한 정형 검증 시스템과의 통합**, **에이전트 기반 접근법과의 하이브리드화**로 진행될 것으로 예상됩니다.

***

**참고**: 이 논문은 NeurIPS 2024에서 발표되었으며, 2025년 초의 최신 관련 연구들은 신경-기호 AI의 확장, 형식 검증 강화, 동적 평가 프로토콜 도입 등으로 나아가고 있습니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/4b4c6ef1-53d0-426c-8271-2228374f3ba1/2412.04857v1.pdf)
[2](https://arxiv.org/pdf/2502.01657.pdf)
[3](http://arxiv.org/pdf/2501.14540.pdf)
[4](https://arxiv.org/pdf/2308.03990.pdf)
[5](http://arxiv.org/pdf/2311.09802.pdf)
[6](http://arxiv.org/pdf/2504.04110.pdf)
[7](http://arxiv.org/pdf/2310.15164.pdf)
[8](https://arxiv.org/html/2505.20869v1)
[9](https://ajithp.com/2025/07/27/neuro-symbolic-ai-multimodal-reasoning/)
[10](https://arxiv.org/pdf/2505.20869.pdf)
[11](https://openreview.net/forum?id=2aA6YwZYOJ)
[12](https://arxiv.org/abs/2510.19361)
[13](https://openreview.net/forum?id=d0gMFgrYFB)
[14](https://arxiv.org/pdf/2412.04857.pdf)
[15](https://arxiv.org/pdf/2411.08469.pdf)
[16](https://openreview.net/forum?id=CIcMZGLyZW)
[17](https://www.ijcai.org/proceedings/2024/961)
[18](https://arxiv.org/html/2506.08446v1)
[19](https://aclanthology.org/2025.emnlp-main.1556.pdf)
