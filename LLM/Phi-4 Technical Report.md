# Phi-4 Technical Report

**핵심 주장 및 주요 기여:**  
Phi-4는 140억 매개변수의 소형 언어 모델로, 기존 Phi 계열(phi-3)과 구조적 차이를 거의 두지 않으면서도 데이터 품질 향상에 집중한 훈련 레시피를 적용해 뛰어난 추론 성능을 달성했다. 특히 합성(synthetic) 데이터를 사전학습(pretraining)·중간학습(midtraining)·후처리(post-training) 전 단계에 걸쳐 전략적으로 도입함으로써, GPT-4 교사 모델을 능가하는 STEM QA 성능과 다양한 추론 지표에서 대형 모델과 견줄 만한 성능을 보였다.[1]

## 1. 해결하려는 문제  
대규모 언어 모델(Large Language Models)은 모델 크기나 연산량을 늘리는 전통적 스케일링 방식에 의존해 왔다. 그러나 소형 모델에서도 데이터 품질 개선만으로 성능 향상이 가능하다는 점을 입증하고, 특히 추론(reasoning) 및 문제해결 능력을 강화하기 위한 훈련 데이터 설계 기법의 효과를 체계적으로 탐구하는 것이 본 연구의 목표이다.[1]

## 2. 제안하는 방법  
### 2.1 합성 데이터 기반 훈련 레시피  
- **합성 데이터 생성:** 다중 에이전트 프롬프트, 자기 수정(self-revision), 명령어 반전(instruction reversal) 등 50여 유형의 워크플로를 통해 합성 데이터를 약 4000억 토큰 규모로 구축.  
- **데이터 혼합(data mixture):** 전체 훈련 토큰 중 40%를 합성 데이터, 15%를 웹 리라이트(web rewrites), 15%를 일반 웹 데이터, 20%를 코드, 10%를 학술·도서 등 취득 데이터로 할당하여 최적의 조합을 탐색.[1]
- **수식:** 모델 파라미터 θ 학습은 일반화된 언어 모델 손실 $$L(\theta)=\mathbb{E}_{(x,y)\sim D}[-\log p_\theta(y\mid x)]$$ 외에, DPO(Direct Preference Optimization) 손실을 추가 적용하여 선호도 학습을 수행한다.

### 2.2 모델 구조  
- **기본 구조:** 디코더 전용(decoder-only) 트랜스포머, 14B 파라미터, 초기 컨텍스트 길이 4K → 중간 학습 시 16K로 확장.  
- **토크나이저:** tiktoken 기반, 어휘(vocab) 크기 100,352.  
- **훈련 스케줄:** 선형 워밍업 및 감쇠, 학습률 0.0003, 배치 사이즈 5760. 중간학습은 최고학습률 1/10로 감소, 250B 토큰 추가 학습.[1]

### 2.3 후처리(post-training)  
- **SFT:** 엄선된 프롬프트-응답 쌍 80억 토큰으로 지도 학습.  
- **DPO 단계1:** Pivotal Token Search(PTS)로 식별된 핵심 토큰별 선호도 데이터로 DPO 적용.[1]
- **DPO 단계2:** GPT-4o 판정 기반 쌍(pair)으로 추가 DPO 수행.  
- **목표 함수:**  

$$
    \mathcal{L}_{\mathrm{DPO}}(\theta)
      = -\mathbb{E}_{(x,a^+,a^-)\sim D}\bigl[\log\sigma(s_\theta(x,a^+)-s_\theta(x,a^-))\bigr]
  $$
  
  여기서 $$s_\theta$$는 모델 점수 함수, $$\sigma$$는 시그모이드이다.

## 3. 성능 향상 및 한계  
### 3.1 성능 향상  
- **추론 중심 벤치마크:** MMLU, GPQA, MATH 등에서 GPT-4o를 능가.[1]
- **경량 모델 비교:** Qwen-2.5-14B-Instruct 대비 9/12개 벤치마크에서 우위.[1]
- **수학·코딩 성능:** HumanEval 82.6%, MATH 80.4% 등 동급 대비 최고 수준 달성.[1]

### 3.2 한계  
- **지시사항 준수:** 복잡한 형식·스타일 요구에 약점(IFEval 등 낮은 점수).  
- **지식 기반 과제:** SimpleQA, DROP에서 벤치마크 점수는 낮지만 실제 거절 응답(refusal) 행동은 개선됨.[1]
- **사실적 환각(hallucination):** 고정밀 답변 필요 시 외부 지식 검색 보완 필요.  
- **규모 한계:** 14B 매개변수 한계로 방대한 상식·지식 제공에는 한계 존재.

## 4. 일반화 성능 향상 가능성  
합성 데이터 설계 원칙—다양성, 복잡도, 정확성, 사고 과정(chain-of-thought)—은 모델의 일반화(generalization)를 촉진한다.  
- **데이터 다양성:** 웹·학술·다국어 데이터 시드→다양한 합성 예제 생성.  
- **체계적 학습:** 단계적 난이도 조절로 모델이 복잡한 추론 패턴 학습.  
- **Pivotal Token Search:** 핵심 토큰별 선호도 학습으로 응답 경로 분기점 강화.  
이러한 기법들은 새로운 도메인·장기 기억 과제에서도 일반화 가능성을 높인다.

## 5. 향후 연구 영향 및 고려사항  
- **후처리와 사전학습 최적화 통합:** 전 단계 데이터 혼합과 DPO 효과를 동시에 최적화하는 엔드투엔드(end-to-end) 방법 연구 필요.  
- **지시사항 준수 강화:** strict instruction-following 합성 데이터 확대 및 벤치마크 설계.  
- **대규모 지식 통합:** 외부 검색·지식 그래프 연동으로 사실적 정확성 개선.  
- **효율적 스케일링:** 소형 모델에서 합성 데이터의 효과 입증, 더 작은 모델에도 적용 가능성 탐색.  

Phi-4는 소형 모델이 합성 데이터 중심 접근법으로 대형 모델에 준하는 추론 성능과 일반화 능력을 달성할 수 있음을 보여 준 대표적 사례로서, 향후 경량 AI 시스템 연구에 중요한 이정표가 될 것이다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/4711960c-076c-4471-81a4-d825d04786db/2412.08905v1.pdf)
