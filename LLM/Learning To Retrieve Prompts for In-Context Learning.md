# Learning To Retrieve Prompts for In-Context Learning

## 1. 핵심 주장 및 주요 기여  
“Learning To Retrieve Prompts for In-Context Learning” 논문은 **대형 언어모델(LLM)의 성능이 프롬프트(사전 예시) 선택에 크게 의존**함을 지적하고, 언어모델 자체를 이용해 “좋은” 프롬프트 예시를 자동으로 라벨링하고 효율적인 검색기(Efficient Prompt Retriever, EPR)를 학습하는 **새로운 프롬프트 검색 방법**을 제안한다.[1]
- **핵심 주장**: 언어모델을 프롬프트 평가 함수로 활용해 긍정·부정 예시를 라벨링하고, 이를 대조 학습(contrastive learning)에 활용하면 기존 표면 유사도 기반 방법을 능가하는 프롬프트 검색기가 학습된다.[1]
- **주요 기여**:  
  1. **LM 기반 라벨링**: 출력 확률 $$\mathrm{Prob}_{\hat{g}}(y \mid x, e)$$를 이용해 상위·하위 예시를 자동 선별.  
  2. **효율적 검색기(EPR)**: BERT 인코더를 활용한 dense retriever로 실시간 검색이 가능.  
  3. **광범위한 검증**: 세 가지 의미 표현 과제(BREAK, MTOP, SMCALFLOW)에서 우수한 성능 개선 증명.[1]

## 2. 문제 정의, 제안 방법, 모델 구조, 성능 및 한계

### 문제 정의  
- **목표**: 입력 $$x_\text{test}$$ 에 대해, 훈련 집합 $$D=\{(x_i,y_i)\}$$에서 유용한 예시 $$P\subset D$$를 검색해 언어모델 $$g$$에 입력함으로써 최적 출력 $$y_\text{test}$$를 생성토록 함.[1]
- **한계**: 기존 BM25·SBERT 등 표면 유사도 기반 검색은 실제 언어모델 성능 예측과 불일치.

### 제안 방법  
1. **후보 예시 생성**: BM25 등으로 $$\bar{E}=Ru((x,y),D)$$ 상위 $$L$$개 후보 수집.  
2. **LM 평가 점수 계산**: scoring LM $$\hat g$$로 각 후보 $$\bar e_\ell$$에 대해  

$$
   s(\bar e_\ell) = \mathrm{Prob}\_{\hat g}(y \mid \bar e_\ell, x)
   $$  
   
   를 계산하고, 상위 $$k$$개는 긍정 $$E_\text{pos}$$, 하위 $$k$$개는 부정 $$E_\text{neg}$$로 라벨링.[1]
3. **대조 학습**: BERT 인코더 $$E_X(x)$$, $$E_P(e)$$를 초기화하고, 긍정/부정 예시로 대조 손실  

$$
   \mathcal{L} = -\log \frac{\exp(E_X(x)^\top E_P(e^+))}{\exp(E_X(x)^\top E_P(e^+)) + \sum_j \exp(E_X(x)^\top E_P(e^-_j))}
   $$  
   
   를 최소화하여 프롬프트 검색기 학습.[1]

### 모델 구조  
- **인코더**: BERT-base 기반의 문장 인코더 2종($$E_X$$, $$E_P$$)  
- **검색**: FAISS를 이용한 최대 내적 검색(MIPS)으로 훈련 예시 사전 구축  
- **추론**: 상위 예시를 토큰 예산 $$C$$에 맞춰concatenate 후 $$g$$에 입력  

### 성능 향상  
- **BREAK**: 베이스라인 BM25 26.0 → EPR 31.9 (+5.9%p)  
- **MTOP**: CBR 57.0 → EPR 64.2 (+7.2%p)  
- **SMCALFLOW**: CBR 51.4 → EPR 54.3 (+2.9%p)[1]
- **Oracle 성능 근접**: BM25-Oracle 성능을 능가하거나 유사하게 달성.  

### 한계  
- **LM 의존성**: 라벨링용 LM 품질에 성능 제약을 받음.  
- **상호 예시 의존성 미고려**: 테스트 시 프롬프트 내부 예시 간 상호작용 효과는 추후 연구 과제.  
- **대규모 계산 비용**: 후보 생성·FAISS 인덱싱 등 전처리 부담 존재.

## 3. 일반화 성능 향상 가능성  
- **추상 패턴 복사 분석**: MTOP·SMCALFLOW에서는 약 80% 이상의 예에서 추상 패턴(구조) 복사, 복사된 예제에서 정확도 대폭 상승하나(예: MTOP 복사 시 71.6% vs 전체 64.2%).[1]
- **고난도 일반화**: 복사되지 않은 예시에서도 15–40% 성능 달성, 검색기가 구조적 유사성도 포착함.  
- **프롬프트 다양성**: 높은 순위 예시에서 주로 복사 발생(Fig.4), 검색기의 정교한 순위화가 일반화에 기여.  

## 4. 향후 연구 영향 및 고려 사항  
- **영향**: LLM을 활용한 자동화된 프롬프트 최적화 연구에 표준적 프레임워크 제시. 다양한 태스크·모델에 확장 가능.  
- **고려 사항**:  
  - **LM 규모·도메인 편향**: 라벨링용 LM과 추론용 LM 불일치 시 성능 저하 분석 필수.  
  - **프롬프트 간 상호작용 모델링**: 예시 간 의존성 반영하는 retrieval-augmented generation 기법 연구.  
  - **효율성 개선**: 후보 생성·대조 학습의 계산 비용 절감 및 동적 프롬프트 조정 기법 모색.  
  - **안정성·공정성**: LM 기반 라벨링이 내재한 편향성 완화 및 공정성 검증 필요.  

---  
 Learning To Retrieve Prompts for In-Context Learning (Ohad Rubin et al., 2022)[1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/1f1fadc4-88e6-4379-a892-9287ce4012d8/2112.08633v2.pdf)
