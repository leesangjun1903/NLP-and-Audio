# Large Language Models are Better Reasoners with Self-Verification

# 핵심 요약

**주장:** 대형 언어 모델(LLM)은 자체 검증(self-verification) 메커니즘을 통해 추론(chain-of-thought) 결과를 역검증함으로써 오류 누적을 줄이고 추론 정확도를 유의미하게 향상시킬 수 있다.

**주요 기여:**  
1. **자체 검증 능력 입증:** CoT로 생성된 답안을 바탕으로 역(Backward) 검증을 수행하여 답안의 일관성을 해석 가능한 점수로 평가.  
2. **무학습 검증 기법 제안:** 추가 학습이나 외부 검증기 없이, LLM 자체만으로 True-False Item Verification(TFV) 및 Condition Mask Verification(CMV)을 구현.  
3. **다양한 과제 성능 개선:** 산술, 상식, 논리 추론 8개 데이터셋에서 CoT 대비 평균 1.67–2.84%p(최대 4.33%p) 향상, 여섯 개 데이터셋에서 SOTA 달성.  
4. **범용성 및 조합성:** Self-Consistency, PAL 등 기존 강화 기법과 결합 가능, 소규모 모델보다는 대형 모델에서 유의미한 성능 향상 관찰.  

# 문제 정의 및 해결 방식

## 1. 문제점  
- **오류 누적:** CoT 기반 추론은 다단계 계산이나 논리 전개 중 작은 실수 하나가 전체 결론 오차로 이어짐.  
- **검증기 한계:** 기존 방법들은 별도 훈련된 검증기를 요구, 대규모 고비용 학습과 불투명한 스코어링 문제 존재.

## 2. 제안 방법  
전체 과정은 **Forward Reasoning**과 **Backward Verification**의 두 단계로 구성된다.

### 2.1 Forward Reasoning  
- K개의 후보 답안 $$y_k$$을 CoT 프롬프트로 샘플링 생성  
- 확률:  

$$
P(y\mid C,X) = P(t_{\mathrm{CoT}}\mid C,X)\times P(y\mid C,X,t_{\mathrm{CoT}})
$$

### 2.2 Backward Verification  
- **후보 결론 재작성:** 질문 $$X$$과 후보 답안 $$y_k$$을 완전 서술문 $$f_Y$$으로 변환  
- **검증 문항 생성:**  
  - TFV: “제시된 모든 조건이 참인가?”  
  - CMV: 원본 조건 중 일부 값을 마스킹(예: 수치 ‘X’)하고 “‘X’의 답은?” 질의  
- **검증 점수 계산:**  
  - TFV: True 판정 횟수 합산  
  - CMV: 마스킹된 값 재예측 일치 횟수 합산  

$$
\text{Score}\_k = \sum_{p=1}^P\sum_{r=1}^R \mathbf{1}( \hat f_r = f_r )
$$

- **최종 선택:** 최고 점수 $$\max_k \text{Score}_k$$인 후보를 최종 답안으로 채택

# 모델 구조 및 성능

| 모델               | 기법            | GSM8K  | SingleEq | AddSub  | MultiArith | AQUA-RAT | SVAMP  | CSQA   | DU     |
|--------------------|-----------------|--------|----------|---------|------------|----------|--------|--------|--------|
| Davinci-002 (175B) | CoT             | 60.81  | 91.01    | 82.78   | 96.13      | 45.30    | 75.87  | 77.42  | 65.43  |
| Davinci-002 (175B) | CoT + Self-Ver. | **65.14**(+4.33) | **93.40**(+2.39) | **86.33**(+3.55) | **99.15**(+3.02) | **47.95**(+2.65) | **76.99**(+1.12) | **77.83**(+0.41) | **66.57**(+1.14) |

- 대형 모델(175B)에서 평균 2.33%p 향상, CMV가 TFV보다 수치 기반 과제에서 더 효과적.  
- Self-Consistency, PAL 등과 결합 시에도 추가 향상 확인.  
- 소규모(0.4B–7B) 모델에서도 검증 능력 발생하나, 파라미터 수가 클수록 검증 점수의 신뢰도가 상승.

# 한계 및 향후 고려 사항

1. **모델 의존성:** 자체 검증은 LLM의 사전 능력에 크게 의존, 저용량 모델엔 한계.  
2. **추론 절차 검증 부족:** 결론만 검증하며 내부 추론 과정의 오류 탐지에는 제한적.  
3. **계산 비용 증가:** 후보 생성 및 P회 검증 디코딩으로 약 1× 이상의 비용 상승.  
4. **프롬프트 설계 편향:** TFV/CMV용 프롬프트는 수작업 설계되어 프롬프트 민감성 존재.

# 일반화 성능 및 연구 영향

- **일반화 가능성:** CMV처럼 과제 특성에 맞춘 마스킹 전략은 산술 외 분야로도 확장 여지. TFV는 도메인 무관하게 적용 가능.  
- **조합 연구 촉진:** Self-Consistency, Least-to-Most 등 기존 CoT 강화 기법과 역검증 결합 연구 활성화 기대.  
- **미래 연구 시 고려:**  
  - 추론 내부 단계까지 검증하는 메타-검증 체계 연구  
  - 자동화된 조건 마스킹 및 문항 생성 기법 개발  
  - 적은 후보로도 검증 성능 유지하는 효율적 디코딩/점수 계산 전략 탐색

위 연구는 “추론 후 검증” 패러다임을 제시하여, 향후 LLM 신뢰성 및 정확도 향상을 위한 후처리 검증 메커니즘 연구에 중요한 초석이 될 것이다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/8dcdd63b-452a-47f8-b9f8-e9b422992f8b/2212.09561v5.pdf)
