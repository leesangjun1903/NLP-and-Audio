
# Toolformer: Language Models Can Teach Themselves to Use Tools

## 1. 핵심 주장과 주요 기여

**Toolformer**는 대규모 언어모델(LM)이 자기감독(self-supervised) 방식으로 외부 도구의 API를 학습하여 사용할 수 있음을 보여주는 혁신적 연구입니다. 이 연구의 핵심 주장은 다음과 같습니다.[1]

언어모델은 소수의 예제만으로 새로운 작업을 놀랍도록 잘 해결하지만, 계산이나 최신 정보 검색 같은 기본 기능에서는 상대적으로 약합니다. Toolformer는 이러한 모순을 해결하기 위해 모델이 스스로 결정하도록 학습하는 혁신적 접근을 제시합니다. 구체적으로, 모델은 어떤 API를 호출할지, 언제 호출할지, 어떤 인수를 전달할지, 그 결과를 어떻게 통합할지를 자동으로 결정합니다.[1]

**주요 기여**는 다음과 같습니다:

- **자기감독 학습 방식**: 대규모 인간 주석 없이도 단 몇 가지 API 사용 예제만으로 도구 사용을 학습할 수 있는 방법론 개발[1]
- **일반성 유지**: 사전학습 데이터셋과 동일한 데이터에서 파인튜닝하여 모델의 기본 언어 능력을 손상시키지 않음[1]
- **다양한 도구 통합**: 질의응답 시스템, Wikipedia 검색, 계산기, 달력, 기계 번역 등 5가지 도구를 단일 모델에 통합[1]
- **우수한 성능**: 6.7B 매개변수의 소형 모델이 175B 매개변수의 GPT-3를 여러 과제에서 능가[1]

***

## 2. 문제 정의, 제안 방법 및 모델 구조

### 2.1 해결하고자 하는 문제

현대의 대규모 언어모델은 다음과 같은 구조적 한계를 갖습니다:[1]

1. **최신 정보 접근 불가**: 학습 데이터 이후의 최신 뉴스나 이벤트를 알 수 없음
2. **환각 현상(Hallucination)**: 잘못된 정보를 마치 사실인 것처럼 생성
3. **수학적 계산 약점**: 정확한 산술 연산에 실패하기 쉬움
4. **시간 인식 부족**: 시간의 경과를 이해하지 못함
5. **저자원 언어 이해 부족**: 희귀 언어에 대한 이해도 낮음

기존 접근법들은 이를 해결하기 위해 대규모 인간 주석에 의존하거나 특정 작업 설정으로만 제한되었습니다. Toolformer는 이러한 한계를 극복하려 합니다.[1]

### 2.2 제안하는 방법: 3단계 접근법

Toolformer의 핵심 방법론은 데이터셋 $$\mathcal{C}$$를 API 호출로 강화하는 3단계 프로세스입니다:[1]

#### **1단계: API 호출 샘플링**

주어진 텍스트 $$x = x_1, \ldots, x_n$$에 대해, 모델은 API 토큰 시작 위치의 확률을 계산합니다:

$$p_i = p_M(\text{[API]} \mid P_x, x_{1}^{i-1})$$

여기서 $$P_x$$는 각 API별로 사전 정의된 프롬프트 템플릿입니다. 샘플링 임계값 $$\tau_s$$를 이용하여:[1]

$$I = \{i : p_i \geq \tau_s\}$$

확률이 충분한 위치들이 선택되고, 각 위치 $$i \in I$$에서 최대 $$m$$개의 API 호출 후보 $$c_i^1, c_i^2, \ldots, c_i^m$$이 샘플링됩니다.[1]

#### **2단계: API 호출 실행 및 필터링**

각 API 호출 $$c_i$$에 대해 응답 $$r_i$$을 얻은 후, **손실 감소(loss reduction)** 기준으로 필터링합니다:[1]

$$\Delta L_i = L_i - \min(L_i^{\emptyset}, L_i^{\text{call}})$$

여기서:
- $$L_i^{\text{enc}(c_i, r_i)}$$: API 호출과 결과를 포함한 가중치 크로스엔트로피 손실
- $$L_i^{\emptyset}$$: API 호출이 없는 경우의 손실  
- $$L_i^{\text{enc}(c_i, \emptyset)}$$: 호출만 있고 결과 없는 경우의 손실

$$L_i = \sum_{j=i}^{n} w_j \log p_M(x_j \mid z, x_1^{j-1})$$

여기서 가중치는 API 호출이 해당 정보를 필요로 하는 위치 근처에서 발생하도록 설계됩니다:[1]

$$w_t = \frac{w_t'}{s_N w_s'}, \quad w_t' = \max(0, 1 - 0.2t)$$

필터링 임계값 $$\tau_f$$를 이용하여 조건을 충족하는 호출만 유지합니다:[1]

$$\Delta L_i \geq \tau_f$$

#### **3단계: 모델 파인튜닝**

필터링된 API 호출들을 원본 텍스트에 삽입하여 강화된 데이터셋 $$\mathcal{C}^*$$를 생성합니다:[1]

$$x' = x_1^{i-1}, \text{[API]} c_i r_i \text{[/API]}, x_i^n$$

원본 데이터와 API 호출 데이터를 포함한 이 데이터셋으로 표준 언어모델 목적함수를 이용하여 파인튜닝합니다.[1]

### 2.3 모델 구조 및 도구 구성

**기본 모델**: GPT-J (6.7B 매개변수)[1]

**통합된 5가지 도구**:[1]

1. **질의응답 시스템**: Atlas 모델 기반, 팩토이드 질문 답변
2. **Wikipedia 검색**: BM25 기반 검색 엔진, 정보 검색
3. **계산기**: 기본 산술 연산(+, -, ×, ÷), 2자리 반올림
4. **기계 번역**: NLLB 모델, 200개 언어 지원
5. **달력**: 현재 날짜 제공 (입력 없음)

각 도구는 텍스트 입출력만 지원하여 모델에 원활하게 통합됩니다.[1]

***

## 3. 성능 향상 및 실증적 결과

### 3.1 다양한 벤치마크에서의 성능

#### **LAMA 벤치마크 (사실 검증)**

| 모델 | SQuAD | Google-RE | T-REx |
|------|-------|-----------|-------|
| GPT-J | 17.8 | 4.9 | 31.9 |
| Toolformer | 33.8 | 11.5 | 53.5 |
| GPT-3 (175B) | 26.8 | 7.0 | 39.8 |

Toolformer는 GPT-3를 능가하며, 질의응답 도구를 98.1% 활용합니다.[1]

#### **수학 연산 벤치마크**

| 모델 | ASDiv | SVAMP | MAWPS |
|------|-------|-------|-------|
| GPT-J | 7.5 | 5.2 | 9.9 |
| Toolformer | 40.4 | 29.4 | 44.0 |
| GPT-3 (175B) | 14.0 | 10.0 | 19.8 |

계산기 도구 활용으로 약 2배 이상 성능 향상 (97.9% 도구 사용).[1]

#### **질의응답 벤치마크**

| 모델 | WebQS | NQ | TriviaQA |
|------|-------|----|---------| 
| GPT-J | 18.5 | 12.8 | 43.9 |
| Toolformer | 26.3 | 17.7 | 48.8 |
| GPT-3 (175B) | 29.0 | 22.6 | 65.9 |

Wikipedia 검색 도구 99.3% 활용.[1]

#### **다국어 질의응답 (MLQA)**

| 언어 | 스페인어 | 독일어 | 힌디어 | 베트남어 | 중국어 | 아랍어 |
|------|---------|-------|--------|---------|--------|-------|
| Toolformer | 20.6 | 13.5 | 1.4 | 10.6 | 16.8 | 3.7 |

기계 번역 도구 활용으로 일관된 개선, 언어별 활용율 63.8~94.9% (힌디어 제외).[1]

#### **시간 기반 작업 (TEMPLAMA, DATESET)**

| 벤치마크 | GPT-J | Toolformer |
|---------|-------|-----------|
| TEMPLAMA | 13.7 | 16.3 |
| DATESET | 3.9 | 27.3 |

달력 도구가 DATESET에서 54.8% 활용되며 큰 성능 향상.[1]

### 3.2 언어 모델 능력 유지

파인튜닝 후에도 기본 언어 모델 능력이 손상되지 않음을 확인:

| 데이터셋 | GPT-J | GPT-J CC | Toolformer disabled |
|---------|-------|---------|-------------------|
| WikiText | 9.9 | 10.3 | 10.3 |
| CCNet | 10.6 | 10.5 | 10.5 |

API 호출이 비활성화된 상태에서도 퍼플렉시티(Perplexity)가 동등하게 유지됩니다.[1]

### 3.3 스케일링 효과

모델 크기에 따른 도구 사용 능력:

- **124M~355M 매개변수**: 도구 사용 능력 거의 없음
- **775M 매개변수**: Wikipedia 검색은 효과적이나 다른 도구는 제한적
- **1.6B 이상**: 모든 도구에서 의미 있는 성능 향상
- **6.7B (GPT-J)**: 모든 도구에서 큰 성능 향상, 그러나 도구 사용과 비사용의 격차 여전히 큼[1]

이는 도구 사용이 어느 정도의 모델 크기 임계값(약 775M)을 요구함을 시사합니다.[1]

***

## 4. 논문의 한계 및 과제

논문에서 명시적으로 제시된 주요 한계:[1]

1. **도구 체이닝 불가**: 한 도구의 출력을 다른 도구의 입력으로 사용할 수 없음. API 호출들이 독립적으로 샘플링되므로 훈련 데이터에 체인된 사용 예제가 없음

2. **대화형 도구 사용 불가**: 검색 결과 다시 검색하기, 쿼리 재구성 등 반복적 상호작용 불가능

3. **입력 민감성**: 모델이 정확한 입력 표현에 매우 민감하여 프롬프트 작성에 주의 필요

4. **샘플 효율성 문제**: 예를 들어 100만 개 이상 문서 처리에도 불구하고 계산기 API 호출 예제는 수천 개에 불과함

5. **계산 비용 미고려**: 도구 호출의 계산 비용을 의사결정 과정에서 고려하지 않음

***

## 5. 일반화 성능 향상 가능성

### 5.1 현재의 일반화 강점

**영점 학습 우수성**: 보이지 않은 과제에서도 도구를 올바르게 활용합니다. 특정 과제별 예제 없이 영점 프롬프팅만으로 도구 사용을 자동 결정.[1]

**도구 사용의 자기 보정**: 흥미롭게도, $$k=1$$ (표준 탐욕 디코딩)에서 모델은 도구 없이 잘 수행할 수 있는 사례를 회피하는 경향이 있습니다. T-REx에서 도구 비사용 사례의 성능(44.3%)이 전체 평균(34.9%)보다 높음을 시사.[1]

### 5.2 일반화 성능 향상의 가능성과 과제

**최신 연구 기반 분석** (2024-2025):

#### **1) 도구 일반화 연구 진전**

**GenTool 프레임워크** (2025): 제로-투-원(Zero-to-One) 일반화와 약-투-강(Weak-to-Strong) 일반화의 두 핵심 차원을 다룹니다. 합성 데이터 생성을 통해 이전에 본 적 없는 도구에 적응하고, 단순한 도구에서 복잡한 도구로의 성능 이전을 달성. LLaMA 3.2 (1B)부터 Mistral (7B)까지 모델에서 GPT-4o를 능가하는 성능을 달성합니다.[2]

**ToolGen** (2025): 도구 지식을 모델 자체에 통합하는 패러다임 전환으로, 문맥 길이 제약을 극복하고 더 효율적인 검색 메커니즘을 가능하게 합니다.[3]

#### **2) 에이전트 설계의 발전**

**상태 추적 에이전트** (2024-2025): StateAct와 같은 새로운 에이전트 아키텍처는 자기 프롬팅과 상태 추적을 통해 ReAct를 능가하는 성능을 달성합니다. Alfworld에서 10% 이상, Webshop에서 7% 향상을 보입니다.[4]

**계획-실행 패러다임** (2024-2025): 기존 ReAct 스타일 사고-행동-관찰 루프보다 효율적인 계획 수립 후 실행 방식이 더 빠르고 저렴하며 성능이 우수함을 입증합니다.[5]

#### **3) 인-컨텍스트 학습 능력 강화**

**문서 없는 API 학습** (2025): 최신 연구는 API 문서가 없는 상황에서도 시연 예제만으로 기능을 학습할 수 있음을 보여줍니다. 그러나 이는 여전히 대규모 LLM(GPT-4o)에도 비자명한 과제입니다. 명시적 함수 호출과 자연어 비평이 매개변수 채우기 정확도를 향상시킵니다.[6]

#### **4) 에이전트 일반화 조사** (2025)[7]

포괄적 조사는 LLM 에이전트의 일반화를 다음 차원에서 분류합니다:[7]

- **명령어 일반화**: 다양한 표현의 명령어 처리
- **작업 일반화**: 학습 범위를 넘어선 새 작업  
- **환경 일반화**: 다양한 도메인에 적응
- **도메인 일반화**: 완전히 새로운 분야에 대한 적응[7]

표준화된 평가 지표와 체계적 개선 방법의 개발이 핵심 과제입니다.[7]

### 5.3 Toolformer 기반 개선 방향

**현재 연구는 다음 방향으로 확장 가능성을 제시합니다**:

1. **반복적 애플리케이션**: 자기 주석 과정을 반복적으로 적용하여 샘플 효율성 개선[1]

2. **도구 체이닝 활성화**: 조건부 예제 생성이나 메타 학습을 통해 다단계 도구 사용 학습[1]

3. **대화형 도구 상호작용**: 강화학습이나 의사결정 프로세스 개선으로 쿼리 재구성 능력 추가[1]

4. **양적 도구 활용**: 계산 비용을 의사결정에 포함시켜 더 효율적인 도구 선택[1]

5. **모듈식 도구 확장**: GenTool과 같은 프레임워크를 활용한 새 도구 범주로의 빠른 적응[2]

***

## 6. 향후 연구의 영향과 고려사항

### 6.1 학술 영향

Toolformer는 AI 연구에 **광범위한 영향**을 미쳤습니다. 논문은 2,674회 인용(웹:10, 웹:13)되었으며, 이를 토대로 다음과 같은 후속 연구가 활성화되었습니다:

**ToolAlpaca** (2023): 소규모 모델에서 일반화된 도구 사용 능력을 습득하기 위해 3,000개의 시뮬레이션된 도구 사용 사례를 자동 생성합니다.[8]

**GEAR** (2024): 일반화 가능하고 효율적인 도구 해석(Generalizable and Efficient Tool Resolution) 프레임워크로, 작업별 시연 의존성을 줄이고 계산 비용을 감소시킵니다.[9]

**Tool Learning in the Wild** (2025): 도구 문서의 수동 파싱 없이 대규모 도구셋에 자동 적응하는 방법 개발.[10]

### 6.2 산업 응용 가능성

2025년 현재, 도구 사용 능력은 실제 LLM 에이전트 배포의 핵심 요소로 인식되고 있습니다. 기업 워크플로, 웹 네비게이션, 로봇 작업 등 다양한 도메인에서 활용됩니다.[11][7]

### 6.3 향후 연구 고려사항

**1) 계산 효율성**: 도구 호출의 계산 비용을 명시적으로 모델링하여 더 효율적인 결정 가능[1]

**2) 도구 생태계 발전**: 더 복잡하고 상호 작용하는 도구 집합에서의 학습 메커니즘 개발[2]

**3) 문맥 길이 제약 극복**: ToolGen과 같은 방법으로 모델 내 도구 지식 통합 연구[3]

**4) 신뢰성과 검증**: 도구 호출 결과의 신뢰성 평가 및 오류 처리 메커니즘 강화[1]

**5) 도메인 적응**: GenTool과 같은 일반화 프레임워크를 다양한 도메인에 적용하여 새 도구 범주로의 빠른 적응[2]

**6) 에이전트 자율성**: 에이전트가 새로운 도구의 필요성을 인식하고 스스로 도구 개발이나 통합을 요청하는 능력[7]

### 6.4 근본적 질문들

연구 커뮤니티는 다음 근본적 질문들에 주목합니다:[7]

- **표준화**: LLM 에이전트의 일반화를 측정하기 위한 표준 프레임워크 부재
- **비용-효과성**: 성능과 계산 비용 간의 트레이드오프 최적화
- **회복력**: 에이전트가 분포 외 상황(out-of-distribution scenarios)에서도 견딜 수 있는 능력
- **해석가능성**: 도구 선택 및 사용 이유의 명확한 설명 가능성

***

## 결론

**Toolformer**는 대규모 언어모델이 자기감독 학습을 통해 외부 도구를 효과적으로 활용할 수 있음을 보여주는 획기적 연구입니다. 손실 감소에 기반한 필터링이라는 우아한 자동 주석 방식으로 기존의 대규모 인간 주석 의존성을 극복했습니다. 

실증적 결과는 소형 모델(6.7B)이 대형 모델(175B)을 능가할 수 있음을 보여주어, 모델 스케일보다 **도구 활용 능력**이 중요함을 강조합니다. 다만 도구 체이닝 불가능, 대화형 상호작용 부재, 입력 민감성 등의 한계도 존재합니다.

2024-2025년 최신 연구는 이러한 한계들을 점진적으로 극복하고 있습니다. GenTool과 같은 프레임워크는 이전에 본 적 없는 도구로의 일반화를, ToolGen은 문맥 길이 제약 극복을, 새로운 에이전트 아키텍처는 더 효율적인 도구 사용을 가능케 하고 있습니다. 

향후 연구는 **도구 일반화**, **에이전트 자율성**, **신뢰성 검증**, 그리고 **표준화된 평가 프레임워크** 구축에 집중할 것으로 예상됩니다. Toolformer가 제시한 자기감독 학습 패러다임은 이제 산업 배포 수준의 다양한 도구 생태계로 진화하고 있습니다.

***

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/0773cd56-6c7a-4eb6-8330-c3952cb5b769/2302.04761v1.pdf)
[2](https://aclanthology.org/2025.findings-acl.61.pdf)
[3](https://arxiv.org/html/2410.03439)
[4](http://arxiv.org/pdf/2410.02810.pdf)
[5](https://blog.langchain.com/planning-agents/)
[6](https://aclanthology.org/2025.findings-emnlp.994.pdf)
[7](https://arxiv.org/abs/2509.16330)
[8](https://arxiv.org/pdf/2306.05301.pdf)
[9](https://arxiv.org/pdf/2307.08775.pdf)
[10](http://arxiv.org/pdf/2405.16533.pdf)
[11](https://www.ibm.com/think/insights/ai-agents-2025-expectations-vs-reality)
[12](https://arxiv.org/pdf/2401.17167.pdf)
[13](https://arxiv.org/pdf/2402.16696.pdf)
[14](https://arxiv.org/pdf/2302.04761.pdf)
[15](https://arxiv.org/pdf/2401.15724.pdf)
[16](https://openreview.net/pdf?id=Yacmpz84TH)
[17](https://www.ibm.com/think/topics/in-context-learning)
[18](https://arxiv.org/abs/2302.04761)
[19](https://github.com/conceptofmind/toolformer)
[20](https://proceedings.iclr.cc/paper_files/paper/2025/file/a3cc50126338b175e56bb3cad134db0b-Paper-Conference.pdf)
[21](https://arxiv.org/html/2505.24197v2)
[22](https://ai-scholar.tech/en/articles/large-language-models/Toolformer)
[23](http://arxiv.org/pdf/2409.12411.pdf)
[24](https://arxiv.org/pdf/2310.16427.pdf)
[25](https://arxiv.org/html/2502.19500v1)
[26](http://arxiv.org/pdf/2310.00194.pdf)
[27](http://arxiv.org/pdf/2401.14423.pdf)
[28](https://aclanthology.org/2023.emnlp-main.263.pdf)
[29](https://arxiv.org/pdf/2305.16653.pdf)
[30](https://research.google/pubs/a-recipe-for-improving-remote-sensing-zero-shot-generalization/)
[31](https://www.arxiv.org/abs/2506.15705)
[32](https://towardsdatascience.com/toolformer-guiding-ai-models-to-use-external-tools-37e4227996f1/)
[33](https://www.openxcell.com/blog/chain-of-thought-prompting/)
[34](https://generalistai.com/blog/nov-04-2025-GEN-0)
[35](https://arxiv.org/html/2510.01253v1)
[36](https://www.superannotate.com/blog/llm-agents)
