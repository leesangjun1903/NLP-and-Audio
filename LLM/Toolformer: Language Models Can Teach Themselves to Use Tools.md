# Toolformer: Language Models Can Teach Themselves to Use Tools

**핵심 주장 및 주요 기여 (간결 요약)**  
Toolformer는 대규모 언어 모델이 *스스로* 외부 API(검색, 계산기, 번역, 달력 등)를 언제 어떻게 호출할지 결정하도록 학습시킴으로써, 최신 정보 활용 능력, 정확한 계산 능력, 시계열 정보 인지 능력 등을 크게 향상시킨다. 이를 위해 사전훈련 텍스트에 무작위 API 호출 후보를 삽입하고, 호출 결과가 언어 모델의 다음 토큰 예측 손실을 줄이면 학습 데이터로 삼아 미세조정한다.  

---  

## 1. 해결하고자 하는 문제  
대형 언어 모델(LLM)은 풍부한 언어 이해 능력을 보이지만,  
-  최신 정보 결여 → 환각(hallucination) 발생  
-  정밀 연산 능력 부족 → 계산 오류  
-  시간 정보 무지 → “오늘 날짜” 인지 불가  
등의 한계를 가진다.  

기존 접근법은 대량의 인간 라벨링, 또는 태스크별 툴 사용 예시가 필요했으나, 비용·확장성 측면의 한계를 안고 있다.  

## 2. 제안 방법  
Toolformer는 *자기지도(self-supervised)* 방식으로 툴 사용을 학습한다. 주요 단계는 다음과 같다.  

-  샘플링: 문장 내부 여러 위치에 API 호출 후보 $$c$$를 삽입한다.  
-  실행: 각 호출을 실제로 실행해 응답 $$r$$을 얻는다.  
-  필터링: 호출이 응답까지 제공될 때 언어 모델의 뒤이어 오는 토큰 예측 손실이  

$$
L_i^-= \min\bigl(L_i(\epsilon),\,L_i(e(c,\epsilon))\bigr),\quad
L_i^+=L_i\bigl(e(c,r)\bigr)
$$  

만큼 감소하면(즉 $$L_i^- - L_i^+ \ge \tau_f$$) 예시로 채택한다.  
-  미세조정: 필터링된 호출과 원문을 합성한 데이터로 모델을 미세조정한다.  

여기서 $$L_i(z)$$는 호출 위치 $$i$$부터 문장 끝까지의 가중 크로스엔트로피 손실이며, $$\tau_f$$는 감소 임계치이다.  

### 모델 구조  
기반 모델은 GPT-J(6.7B)로, API 호출 토큰(`<API>` 등)만 추가한 채 어휘 사전은 그대로 유지한다.  
인퍼런스 시 `<API>` 토큰이 예측되면 즉시 해당 API를 호출·삽입하고 디코딩을 이어간다.  

## 3. 성능 향상  
다양한 제로샷 태스크에서 GPT-J 대비 뚜렷한 개선을 보였다.  
- **지식 검색**(LAMA): QA API 호출로 SQuAD 서브셋 17.8%→33.8%↑, T-REx 31.9%→53.5%↑  
- **수리 추론**(ASDiv 등): 계산기 API로 평균 7.5→≈38% 성능↑  
- **QA 벤치마크**(WebQSP 등): 위키 검색 API로 18.5%→26.3%↑  
- **다국어 QA**(MLQA): 번역 API 활용으로 일부 언어에서 1–3%p↑  
- **시간 인식**(DATESET): 달력 API 호출 27.3% 정답률 달성  
- **언어모델링 퍼플렉서티**: API 없이 디코딩 시 GPT-J+CC와 동등  

성능 향상은 모델이 *필요할 때만* API를 호출하기 때문에 모델 일반화 능력을 희생시키지 않는다.  

## 4. 한계  
-  **툴 연쇄 사용 불가**: API 간 체인 호출 미지원  
-  **상호작용 부재**: 검색 결과 재질의, 쿼리 재작성 불가  
-  **샘플 비효율**: 유용 호출 비율 낮아 대규모 데이터 필요  
-  **비용 고려 미흡**: API별 호출 비용을 학습 시 반영 못함  
-  **문구 민감도**: 입력 표현 변화에 따라 호출 여부 편차  

## 5. 일반화 성능 향상 가능성  
Toolformer는 *모델 스스로* 손실 감소 신호에 따라 외부 지식을 취사선택하도록 학습함으로써,  
-  기존 사전훈련 분포 외 정보(최신·수치·시계열)를 체계적으로 활용  
-  과도한 호출 없이 핵심 정보만 추출  
-  단일 파라미터 증가는 없으나 기능적 확장 달성  

이 접근법은 다양한 언어 모델에 적용 가능하며, *추후 체인 호출*, *대화형 검색*, *비용 최적화*를 결합하면 더욱 강력한 일반화 역량을 기대할 수 있다.  

## 6. 향후 연구에 미치는 영향 및 고려 사항  
Toolformer는 LLM이 외부 도구를 자율적으로 활용하는 새로운 패러다임을 제시한다. 앞으로는  
-  **체인 API** 학습: 복합 질의 해결 능력 강화  
-  **메타-비용 최적화**: 호출 시점과 API 선택의 경제적 판단 내재화  
-  **인터랙티브 툴** 통합: 검색·브라우저·코드 실행 환경 연계  
-  **소형 모델 확장**: 파라미터가 적은 모델에도 동일한 이점 적용 여부  

등을 고려하여 보다 효율적이고 범용적인 도구 사용 메커니즘을 개발하는 것이 중요하다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/24d30ffe-2715-49db-850d-37a9b509a9f5/2302.04761v1.pdf)
