# Want To Reduce Labeling Cost? GPT-3 Can Help

## 1. 핵심 주장과 주요 기여 (간결 요약)
이 논문은 **대규모 사전학습 언어모델 GPT-3**를 “저비용 라벨러”로 활용하여, 전통적인 인간 라벨링 대비 **50%–96% 비용 절감**을 이루면서도 동등 이상의 성능을 달성할 수 있음을 보인다.  
주요 기여:
- GPT-3 API를 통해 자동 생성한 라벨로 소형 모델을 학습시켜 비용 효율적 데이터 라벨링 파이프라인을 제안  
- GPT-3 라벨링과 인간 라벨링을 예산 비율에 따라 혼합하는 **Dual Supervision** 전략 도입  
- GPT-3가 반환하는 **로짓(logit)**을 기반으로 불확실한 샘플만 인간이 재라벨링하는 **Active Labeling** 기법 제안  
- 다양한 NLU/NLG 태스크(예: SST-2, Gigaword, XSum 등)에서 비용 대비 성능을 체계적으로 비교·검증  

## 2. 문제 정의, 제안 방법, 모델 구조, 성능 향상 및 한계

### 2.1 해결하고자 하는 문제
- **문제**: 인간 라벨링 비용과 시간이 과도하게 소요되어, 특히 저자원 상황(low-budget)에서 대규모 데이터 확보가 어려움.  
- **목표**: GPT-3의 **few-shot** 능력을 활용해 비지도(unlabeled) 데이터에 라벨을 자동으로 생성하고, 이를 통해 소형 모델을 학습시켜 비용 효율을 극대화.

### 2.2 제안 방법
1. **GPT-3 라벨링**  
   - 입력 프롬프트에 $$n$$개의 예제(“n-shot”)와 대상 문장 $$X_i$$를 함께 입력하여 GPT-3가 예측한 라벨 $$Y_i$$ 및 로짓 $$\text{logit}_i$$를 반환:  

$$
       (Y_i, \text{logit}_i) = \mathrm{GPT3}(\{\text{labeled examples}\}, X_i)
     $$
   
   - 분류 과제는 첫 번째 토큰, 생성 과제는 전체 출력을 라벨로 사용.

2. **Dual Supervision (GPT3–Human Mix)**  
   - 예산을 GPT-3 라벨링용 $$T$$와 인간 라벨링용 $$H$$으로 분할하고, 두 소스의 손실을 가중합:  

$$
       \mathcal{L} = \sum_{i\in T} L_g(Y_i, X_i) + \alpha \sum_{j\in H} L_h(Y_j, X_j)
     $$
   
   - $$\alpha$$는 인간 라벨의 중요도를 조정하는 가중치.

3. **Active Labeling**  
   - GPT-3 로짓을 신뢰도 지표로 활용하여, **신뢰도 하위** 인스턴스만 인간이 재라벨링하도록 예산 집중 투입.

### 2.3 모델 구조
- **라벨러**: OpenAI GPT-3 (Davinci)  
- **소형 모델**:  
  - NLU: RoBERTa\<large\> (24-layer Transformer)  
  - NLG: PEGASUS\<large\> (16-layer encoder–decoder Transformer)  

### 2.4 성능 향상
- 저예산(\$1.1 수준) 환경에서 GPT-3 라벨링만으로도 인간 라벨링(\$27.5)과 동일 성능 달성 (SST-2 기준 96% 비용 절감).  
- Gigaword 요약 과제에서도 \$4.4 예산으로 인간 \$70.4 대비 동등 ROUGE-L 성능 확보 (93.8% 절감).  
- 충분한 예산 시 인간 라벨링 우세하나, 제한된 예산 시 GPT-3 라벨링 및 혼합 전략이 최적의 비용–성능 trade-off를 보여줌.

### 2.5 한계
- **고위험(high-stakes) 과제**(예: 독성 언어 감지)에는 GPT-3 라벨 품질이 불충분할 수 있음.  
- GPT-3 API 비용 변동, 지연(latency) 문제, 그리고 프롬프트 설계 민감도가 결과에 큰 영향을 미침.  
- 대규모 GPT-3 호출 시 인프라 및 응답 속도 병목 가능성.

## 3. 일반화 성능 향상 가능성
- **Self-training** 관점: GPT-3 라벨을 “의사 정답(pseudo-label)”으로 활용한 자기학습(self-training)으로, 소형 모델이 **raw GPT-3**를 능가하는 성능을 보임.  
- 이론적 보장: **Consistency**와 **(a,c)-expansion** 가정 하에, 소형 모델의 오류율이 GPT-3 오류율보다 낮다는 상한식 증명.  
- 다양한 샷(n-shot) 설정에서 로짓 기반 불확실성 추정이 일반화 성능 향상에 기여.

## 4. 향후 연구 영향 및 고려 사항
- **영향**: 대규모 사전학습 모델을 비용 효율적 데이터 라벨링에 활용하는 패러다임을 제시하여, **저자원 도메인**(의료, 법률 등)에서 실질적 라벨링 비용 절감 가능성을 확대.  
- **고려사항**:  
  - **프롬프트 최적화 및 편향 완화** 연구 병행  
  - **API 비용·지연** 대비 하이브리드 온프레미스/클라우드 워크플로우 설계  
  - **고위험 도메인** 안전성·신뢰성 검증 메커니즘 강화  
  - GPT-3 이후 등장할 더욱 저비용 대규모 모델(예: GPT-4 등)과의 통합 가능성 검토

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/1c2eec12-6853-410e-9acc-46a3f33b68f6/2108.13487v1.pdf)
