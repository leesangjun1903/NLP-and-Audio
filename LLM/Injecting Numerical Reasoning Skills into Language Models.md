# Injecting Numerical Reasoning Skills into Language Models

## 1. 핵심 주장과 주요 기여 요약

"Injecting Numerical Reasoning Skills into Language Models"는 기존 사전 훈련된 언어 모델이 가진 근본적인 한계를 해결하고자 제안된 혁신적 연구입니다. 이 논문의 핵심 주장은 **대규모 합성 데이터 생성과 다중 태스크 학습을 통해 언어 모델에 수치 추론 능력을 주입할 수 있다**는 것입니다.[1]

### 주요 기여

**범용적 스킬 주입 방법론**: 자동 데이터 생성이 가능한 모든 스킬에 적용할 수 있는 일반적인 레시피를 제공합니다. 이는 기존의 특화된 아키텍처 접근법과 달리 확장성과 유연성을 보장합니다.[1]

**GENBERT 아키텍처**: 생성형과 추출형 능력을 모두 갖춘 BERT 기반 모델을 설계했습니다. 이 모델은 표준 인코더-디코더 구조를 사용하면서도 수치 계산을 내부적으로 수행할 수 있습니다.[1]

**합성 데이터 생성 프레임워크**: 수치 데이터(ND)와 텍스트 데이터(TD) 생성을 위한 체계적인 프레임워크를 구축했습니다. 수치 데이터는 기본적인 산술 연산을, 텍스트 데이터는 자연어로 표현된 수치 추론 문제를 다룹니다.[1]

## 2. 문제 정의와 제안 방법론

### 해결 대상 문제

기존 수치 추론 모델들은 **특화된 아키텍처의 제약**으로 인해 심각한 한계를 가지고 있었습니다. 구체적으로 9까지만 세기가 가능하고, 2-3개 숫자의 덧셈과 뺄셈만 처리할 수 있었습니다. 또한 지원되지 않는 계산으로 일반화하려면 모델 아키텍처 자체를 수정해야 했습니다.[1]

### 제안 방법론

논문에서 제안하는 방법론은 **두 단계의 사전 훈련**을 통한 점진적 스킬 주입입니다:[1]

#### 1단계: 수치 데이터(ND) 사전 훈련
수치 데이터는 6가지 템플릿으로 구성됩니다:[1]
- **부호 있는 부동소수점 조합**: $$s_1f_1 + s_2f_2 + s_3f_3 + s_4f_4$$ 형태
- **최소/최대/평균 연산**: 2-4개 부동소수점 수에 대한 집계 함수
- **논항 최대/최소**: 단어-숫자 쌍에서 극값 찾기
- **날짜 최소/최대**: 날짜 데이터에 대한 극값 연산
- **날짜 차이**: 일, 월, 년 단위의 날짜 산술
- **백분율 계산**: $$100 - x$$ 형태의 백분율 연산

#### 2단계: 텍스트 데이터(TD) 사전 훈련
텍스트 데이터는 Hosseini et al.(2014)의 프레임워크를 확장하여 생성합니다. 이는 **엔티티**(계산되는 객체)와 **컨테이너**(엔티티를 소유하는 객체)로 구성된 월드 스테이트를 기반으로 합니다.[1]

### 모델 구조

**GENBERT의 핵심 설계**:
- **가중치 연결**: 인코더와 디코더 가중치를 연결하되, 각각 고유한 표현을 학습할 수 있도록 별도의 FFN(Feed-Forward Network)을 추가합니다[1]
- **숫자별 토큰화(DT)**: 숫자를 자릿수별로 분할하여 토큰화합니다[1]
- **랜덤 시프트(RS)**: 위치 ID를 무작위로 이동시켜 과적합을 방지합니다[1]

**손실 함수**:
모델은 다음과 같이 여러 방식으로 답을 예측할 수 있는 확률을 최대화합니다:[1]

$$L_{model} = -\log\left[p_{dec} \cdot p_{dec}(\langle a \rangle) + \sum_{h \in \{q,c\}} p_h \cdot \sum_{(i,j) \in S} p_h(i,j)\right]$$

## 3. 성능 향상과 일반화 능력

### 주요 성능 지표

**DROP 데이터셋**: GENBERT+ND+TD는 68.8 EM(Exact Match), 72.3 F1 점수를 달성하여 비교 가능한 크기의 MTMSN-BASE(68.2 EM)와 동등한 성능을 보였습니다.[1]

**수학 단어 문제(MWP) 일반화**: 제로샷 설정에서 GENBERT+ND+TD는 ADDSUB(22.8%), SOP(28.3%), SEQ(22.3%)에서 기본 GENBERT 대비 극적인 성능 향상을 보였습니다.[1]

### 일반화 성능 향상의 핵심 요인

**상호 보완적 스킬**: ND와 TD가 학습하는 스킬이 상호 보완적임을 실증적으로 확인했습니다. ND는 순수한 수치 계산 능력을, TD는 자연어 맥락에서의 수치 추론 능력을 제공합니다.[1]

**강건성 향상**: 산술 표현의 항 개수별 분석에서 GENBERT+ND+TD가 2항에서 3항으로의 성능 저하가 다른 모델들에 비해 현저히 작았습니다. 이는 두 데이터셋이 모두 강건성 향상에 기여함을 시사합니다.[1]

**언어 이해 능력 보존**: SQuAD v1에서 GENBERT+ND+TD는 81.3 EM으로 원래 BERT(81.1 EM)와 거의 동일한 성능을 유지했습니다. 이는 수치 스킬 획득이 기존 언어 능력을 해치지 않음을 보여줍니다.[1]

### 재사용성과 전이 가능성

**아키텍처 독립성**: GENBERT+ND+TD의 가중치를 다른 아키텍처(NABERT+, MS-TAG)의 인코더로 사용했을 때 약 2 EM 점수 향상을 보였습니다. 이는 학습된 표현이 범용적으로 활용 가능함을 의미합니다.[1]

## 4. 한계와 미래 연구 방향

### 주요 한계점

**복잡한 추론의 제약**: 오류 분석 결과, 실패 사례의 43%가 사전 훈련 태스크에서 다루지 않은 추론 스킬(정렬 등)이나 비수치적 문제를 요구했습니다.[1]

**산술 복잡도의 벽**: 모든 모델이 3개 이상의 항을 포함한 계산에서 완전히 실패했습니다. 이는 현재 접근법의 근본적 한계를 드러냅니다.[1]

**정확도 문제**: 23%의 실패 사례가 부정확한 예측(너무 긴 스팬, 부분적 숫자 매치 등)으로 인한 것이었습니다.[1]

### 미래 연구에 대한 영향

**확장 가능한 패러다임**: 이 연구는 **자동 데이터 생성이 가능한 모든 스킬에 대해 적용 가능한 일반적 방법론**을 제시했습니다. 이는 향후 다양한 추론 능력(논리 추론, 상식 추론 등)을 언어 모델에 주입하는 연구의 토대가 될 것입니다.[1]

**다중 태스크 학습의 중요성**: Masked Language Modeling과의 결합이 성능에 미치는 결정적 영향을 실증했습니다. 이는 향후 스킬 주입 연구에서 기존 능력 보존의 중요성을 강조합니다.[1]

### 앞으로 고려할 점

**데이터 다양성 확대**: 현재 프레임워크를 확장하여 더 많은 수치 스킬과 더 큰 숫자 범위를 다루는 것이 필요합니다.[1]

**아키텍처 혁신**: 3개 이상의 항을 포함한 복잡한 계산을 처리할 수 있는 새로운 아키텍처나 학습 방법론 개발이 요구됩니다.

**평가 방법론 개선**: 현재의 정확 매치 기반 평가를 넘어서, 추론 과정의 질을 평가할 수 있는 새로운 메트릭 개발이 필요합니다.

이 논문은 언어 모델의 능력 확장에 대한 새로운 관점을 제시하며, 특화된 아키텍처 대신 **데이터 기반 스킬 주입**이라는 패러다임 전환을 이끌어냈습니다. 향후 연구는 이 방법론의 한계를 극복하고 더 복잡한 추론 능력으로 확장하는 방향으로 진행될 것으로 예상됩니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/29999a3a-bcba-451a-8126-750d5da6e7af/2004.04487v1.pdf)
