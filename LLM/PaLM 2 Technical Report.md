# PaLM 2 Technical Report

## 1. 핵심 주장 및 주요 기여 (간결 요약)
PaLM 2는 이전 버전 PaLM 대비  
-  추론·다국어·코드 생성 성능을 크게 향상  
-  동일 FLOPs 예산에서 모델 크기와 토큰 수를 균형 있게 확장하는 최적 스케일링 법칙 검증  
-  혼합형 사전학습 목적(UL2 방식)과 다양하고 고품질의 다국어·도메인 데이터 활용으로 추론력·효율성 개선  
-  해석 제어 토큰을 통한 독성 억제 등 책임 있는 AI 기능 내장  
총체적으로 성능·추론·다국어 역량·책임성 모두에서 PaLM 대비 획기적 발전을 이루었음을 입증한다.

## 2. 문제 정의·제안 방법·모델 구조·성능·한계

### 문제 정의
대규모 언어모델(LLM)은
-  지식, 추론, 다국어, 코드 생성 등 다양한 과제에서 활용되나  
-  모델 크기 확장만으로는 비용·지연·책임성 한계 존재  
→ 더 작은 모델로 더 높은 성능·효율성을 달성하고자 함

### 제안 방법
1) **최적 스케일링 법칙 검증**  
   – FLOPs≈6·N·D(모델 파라미터 수·토큰 수) 가정 하에  
   – 1e19∼1e22 FLOPs에서 파라미터 N, 데이터 토큰 수 D의 이소FLOPs 곡선을 2차 함수로 피팅  
   – 최적 N과 D가 FLOPs 증가에 비례해 1:1로 확장됨을 확인[표 1][그림 5]  
2) **혼합형 사전학습 목적(Ultra-LLM, UL2)**  
   – 인과·마스킹·다양한 언어목적을 결합해 다방면 이해 강화  
3) **고품질·다국어 데이터 혼합**  
   – 기존 PaLM 대비 비영어·병렬코퍼스 비중 확대, 전문 도메인(코드·수학·문학) 데이터 포함  
   – 중복 제거·민감정보 필터링으로 책임성 향상  
4) **모델 구조**  
   – Transformer 기반·공유 임베딩·출력층  
   – Small/Medium/Large 세 가지 크기로 제공  
5) **추론 시 독성 제어 토큰**  
   – Perspective API 태그를 학습 시 주입해 추론 시 독성 제어 가능

### 모델 구조
– PaLM 2-L: 대규모·UL2 목적·병렬 Multi-Head Attention 구조  
– 파라미터 수·FLOPs 구체치 생략  
– 텍스트 인·출력만 지원(코드·다국어 모두 동일 구조)

### 성능 향상
– **스케일링 법칙**: 1e22 FLOPs에서 D∝N, 최적 모델 9.5B 파라미터[표 1]  
– **언어 능력**: C2 수준 언어시험 전언어 합격, PaLM 대비 평균 +?%[그림 1]  
– **QA·분류**: SuperGLUE·TyDiQA 등 1-shot/0-shot서 PaLM 대비 상당 폭 상승[표 2][표 3]  
– **추론**: BIG-Bench Hard·MATH·GSM8K서 비약적 향상, Chain-of-Thought와 Self-Consistency 융합 시 GPT-4 급 성능[표 5][표 7]  
– **코드**: HumanEval·MBPP·ARCADE pass@k서 PaLM-Coder 대비 절반 크기로 동등 이상 성능[표 8][그림 6]  
– **번역**: WMT21·FRMT서 PaLM·Google Translate 제치고 MQM·BLEURT 최상위[표 9][표 10]  
– **NLG**: WikiLingua·XLSum·XSum서 라지 모델이 기존 대비 ROUGE-2 기준 +60∼100% 개선[표 11]  
– **책임성**:   
  -  대화서 독성 ↓, 제어 토큰으로 독성 확률 조절 가능[표 14][그림 10]  
  -  민감 ID 그룹 생성서 편향률 ↓(7% 미만)[D.3.2]  
  -  기억력(과도한 복제) ↓, tail 언어 반복 시 기억 ↑[D.7]  

### 한계
– 평가 주로 Few-shot/Zero-shot, Fine-tune·Prompt-Tune 효과 미반영  
– 일부 책임성 지표(의미적 독성·비이진 젠더 등) 자동측정 한계  
– 사용자·서비스별 위험 분석·후처리·모니터링 필요  
– 번역 등 특정 언어·도메인서 평가 편향 가능

## 3. 일반화 성능 향상 가능성
– **스케일링 법칙**: FLOPs 내 토큰·파라미터 균등 확장이 일반화 데이터·모델에 적용 가능  
– **UL2 목적 혼합**: 여러 학습 목적 결합이 언어·추론·코드·다국어 일반화 향상에 기여  
– **다국어 고품질 데이터**: Tail 언어 포함, 병렬코퍼스 확대 전략→저자원 언어 일반화 상승(성능 격차↓)  
– **제어 토큰**: 독성·책임성 제어 방식 일반화가능, 기타 민감속성 컨트롤 잠재력

## 4. 향후 연구 영향 및 고려사항
– **하위모델·시스템별 책임성 분석**: downstream 맥락에 맞춘 편향·유해성·프라이버시 방지 설계 필요  
– **평가 개선**: 자동 vs. 인간 지표 창발 효과, 멀티모달·비정형 평가 세트 확충  
– **프롬프트·튜닝 일반화**: 자원제약 환경서 T0·FLANㆍLoRA 등 범용 적용 연구  
– **스케일 vs. 효율 교차 최적화**: 더 작은 모델+고수준 데이터 품질 전략 일반화  
– **제어·안전 메커니즘**: 제어 토큰 외 차원별 steerability 강화, 롱컨텍스트·지속적 모니터링 채택

PaLM 2는 스케일링 법칙 재검증, 데이터·목적·아키텍처 개선을 결합해 **작은 모델로 더 넓은 일반화 역량**을 달성함을 입증했다. 향후 LLM 연구는 이 전략을 기반으로 책임성과 효율성을 모두 고려하는 방향으로 확장될 것이다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/3353427e-ff92-4647-a0a5-f3025f71912a/2305.10403v3.pdf)

# 2 Scaling Law Experiments

PaLM 2의 **Scaling Law 실험**(2장)은 네 가지 다른 컴퓨팅 예산(1×10¹⁹ FLOPs, 1×10²⁰ FLOPs, 1×10²¹ FLOPs, 1×10²² FLOPs)을 바탕으로 모델 크기(파라미터 수)와 학습 토큰 수(데이터량)의 최적 비율을 찾고, 이 비율이 하위 과업(Downstream tasks) 성능에도 유효한지 평가하는 과정을 다룹니다.

***

## 2.1 Scaling Laws

1. **목적**  
   - 한정된 훈련 예산(총 FLOPs)이 주어졌을 때, 모델 파라미터 수 *N*과 학습 토큰 수 *D*를 어떻게 배분해야 최저 검증 손실(validation loss)을 얻을 수 있는지 확인.

2. **절차**  
   1. 4가지 예산(1e19∼1e22 FLOPs)에 대해 여러 크기의 모델(N)과 그에 대응하는 학습 토큰 수(D)를 조합해 학습.  
   2. 각 조합에서 최종 검증 손실을 측정.  
   3. 동일한 FLOPs 범위 내에서 손실을 *파라볼라(2차 함수)*로 스무딩한 뒤 최소점(손실이 가장 낮은 지점)을 찾음(그림 4).  
   4. 4개 최소 파라미터 수(Nₒₚₜ), 최소 토큰 수(Dₒₚₜ)를 획득하고, 이를 FLOPs에 대해 로그–로그 스케일로 플롯(그림 5).  
   5. 회귀 결과, **N ∝ FLOPs^0.5** 및 **D ∝ FLOPs^0.5**로 나타나, N과 D가 **1:1 비율**로 성장해야 함을 확인.

3. **결과 요약**  
   - PaLM 2 학습 예산 1×10²² FLOPs에서 최적 파라미터 수는 약 1.61×10¹⁰ (≈16 B)이며, 1×10²¹ FLOPs에서는 ≈9.50 B(≈9.5 B), 1×10²⁰ FLOPs에서는 ≈4.44 B(≈4.4 B)로 예측됨[?].  
   - Chinchilla 논문과도 유사한 결론을 얻음(데이터와 모델 크기를 균등하게 늘림).

***

## 2.2 Downstream Metric Evaluations

1. **목적**  
   - 앞서 찾은 *손실 최적화* 관점에서의 최적 N, D 비율이 실제 과업(예: QA, 분류, 추론 등) 성능에서도 그대로 최적인지 검증.

2. **절차**  
   1. 1×10²² FLOPs 예산 하에서, 서로 다른 크기(3.86 B, 7.08 B, 9.50 B, 16.1 B) 모델을 훈련.  
   2. 각 모델을 대규모 하위 과업 벤치마크(표 2)에서 1-shot 설정으로 평가.

3. **관찰**  
   - 손실 최적(N≈9.5 B) 모델이 실제 과업에서도 뛰어난 성능을 보이지만, 일부 벤치마크(예: 리딩 컴프리헨션)에서는 더 큰 모델(16.1 B)이 소폭 더 우수함.  
   - **훈련 손실 최저**와 **하위 과업 최적**은 완전히 일치하지 않으며, 실제 과업 성능, 서빙 레이턴시, 처리량 등의 요소를 함께 고려해야 함을 시사.

***

### 결론

- **Scaling Law** 실험을 통해, PaLM 2와 같은 대형 언어 모델은 모델 크기와 학습 데이터량을 **1:1 비율**로 늘리는 것이 계산 예산 대비 최적이라는 것을 대규모 실험으로 검증.  
- 그러나 실제 과업 성능은 최적 손실 추정치와 완전 일치하지 않으므로, 모델 규모 결정 시에는 **하위 과업 성능, 효율성, 레이턴시** 등을 종합적으로 고려해야 함.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/3353427e-ff92-4647-a0a5-f3025f71912a/2305.10403v3.pdf)

# 4 Evaluation

PaLM 2의 **4장: 평가**에서는 모델의 성능을 인간 언어시험, 분류·질문응답, 추론, 코딩, 번역, 자연어 생성까지 6개 주요 범주별로 체계적으로 검증합니다. 각 소장별로 평가 대상, 방법, 결과를 정리하면 다음과 같습니다.  

***

## 4.1 언어 숙련도 시험 (Language proficiency exams)  
- **목표**: PaLM 2가 인간 대상의 CEFR C2 수준 전문 언어시험에서 어느 정도 성취를 보이는지 평가  
- **시험들**:  
  - 중국어 HSK 7–9  
  - 일본어 J-Test A–C  
  - 프랑스어 TCF  
  - 스페인어 DELE C2  
  - 이탈리아어 PLIDA C2  
- **방법**:  
  1. 실제 공개된 기출·모의시험지 사용 (말하기 제외)  
  2. 듣기 → 지문 전사본을 읽기 문제에 포함  
  3. 객관식은 0.3 온도로 1회 샘플, 서술형은 0.6 온도로 1회 샘플  
  4. 제3자 원어민 평가자 3인에게 글쓰기 채점(원어민 성인 수준에 5점 만점)  
  5. 읽기와 쓰기에 동등 가중치 적용, 공식 합격 기준(시험별 60–90%)에 따라 Pass/Fail 산출  
- **결과**: PaLM 대비 모든 언어시험에서 점수 상승, 전 과목 합격[Fig. 1]

***

## 4.2 분류·질문응답 (Classification and question answering)  
### 4.2.1 영어 과제  
- **데이터셋**: TriviaQA, Natural Questions, WebQuestions, LAMBADA, HellaSwag, StoryCloze, Winograd,  
  WinoGrande, SQuAD v2, RACE, PIQA, ARC, OpenBookQA, BoolQ, COPA, RTE, WiC, MultiRC, ReCoRD, ANLI  
- **설정**: 1-샷(in-context learning)  
- **측정 지표**: 정확도(EM, F1)  
- **핵심 결과**: PaLM 2-L 평균 76.9% → PaLM 70.4%, 특히 ANLI(R1) 73.1% → 52.6%[Table 2]  

### 4.2.2 다국어 질문응답 (TyDi QA)  
- **Gold Passage** vs. **No-context**(폐쇄형) 설정  
- **언어**: 아랍어, 벵골어, 영어, 핀란드어, 인도네시아어, 한국어, 러시아어, 스와힐리어, 텔루구어  
- **결과**: PaLM 2 평균 73.6%/40.3% → PaLM 69.8%/31.5%, 저자원·비라틴문자어 더 큰 개선[Table 3]  

### 4.2.3 다국어 독성 분류  
- **데이터**: Jigsaw Multilingual toxicity, Civil Comments(영어)  
- **설정**: 0-shot, 10-shot prompting  
- **지표**: AUC-ROC  
- **결과**: 비영어 AUC 88.9% → 77.1%, 영어 75.96% → 71.45% (0-shot 기준)[Table 4]  

***

## 4.3 추론 (Reasoning)  
- **데이터셋**: WinoGrande, ARC-C, DROP, StrategyQA, CommonsenseQA, XCOPA, BIG-Bench Hard  
- **방식**: few-shot prompting, chain-of-thought, self-consistency 기법 적용  
- **비교군**: PaLM, GPT-4, SOTA  
- **주요 결과**: PaLM 2-L이 모든 추론 과제에서 PaLM 상회, SOTA 혹은 GPT-4 수준[Table 5], BIG-Bench Hard 평균 +26%[Table 6]  
- **수학적 추론**: MATH, GSM8K, MGSM에서 Minerva·GPT-4와 경쟁[Table 7]  

***

## 4.4 코딩 (Coding)  
- **모델**: PaLM 2-S* (코드 특화 소형 모델)  
- **데이터셋**: HumanEval, MBPP, ARCADE, BabelCode 멀티언어 HumanEval  
- **측정**: pass@1, pass@k  
- **결과**: PaLM 2-S* pass@1 37.6% → PaLM-Coder-540B 35.9% (HumanEval), 다국어 코드는 대부분 언어서 PaLM 대비 우위[Table 8, Fig 6]  

***

## 4.5 번역 (Translation)  
### 4.5.1 WMT21  
- **언어쌍**: 중→영, 영→독  
- **메트릭**: BLEURT, MQM(전문 번역가)  
- **결과**: PaLM 2 BLEURT 69.2/73.3 vs. PaLM 67.4/71.7, MQM 3.0/0.9 vs. 3.7/1.2[Table 9]  

### 4.5.2 지역 방언 번역 (FRMT)  
- **대상 지역**: 포르투갈·브라질, 중국 본토·대만  
- **결과**: PaLM 2 BLEURT 81.1/78.3/74.4/72.0 vs. Google Translate 80.2/75.3/72.3/68.5[Table 10]  

### 4.5.3 잠재적 오역 피해(성별)  
- **영→다국어**: zero-shot gender agreement– human 평가, 일부 언어서 향상, 힌디어 등 몇몇 언어서 소폭 하락  
- **다국어→영**: automated pronoun-match 평가, 전반 안정적[Sec 4.5]  

***

## 4.6 자연어 생성 (Natural language generation)  
- **데이터셋**: XSum(영), WikiLingua(7개국어), XLSum(11개국어)  
- **설정**: 1-shot, greedy  
- **지표**: ROUGE-2, SentencePiece-ROUGE-2  
- **결과**: PaLM 2-L 대폭 개선 (XSum +59.4%, WikiLingua +100.8%)[Table 11]  
- **데이터 중복 검증**: 15-그램 필터링, 델타 +0.1~0.6 (기억·암기 영향 미미)[Table 12]  
- **대표성·편향**: ParlAI Dialogue Safety, BBQ, RealToxicityPrompts 등에서 토큰·문맥별 독성·편향 분석[Sec 4.6]  

***

## 4.7 암기 경향 (Memorization)  
- **방법**: 훈련문서 50+50 토큰 추출·생성(explicit memorization), canary 삽입 평가  
- **결과(영어)**: PaLM 2 전반 암기율↓ vs. PaLM, 3회 이하 반복 시 크게↓, tail 언어 반복 시↑[Fig 8–9]  
- **의미**: 평균 암기율 감소, 희귀 반복 데이터는 별도 주의 필요  

***

> **요약**  
> PaLM 2는 PaLM 대비 모든 영역(언어시험, 분류·QA, 추론, 코딩, 번역, 생성)에서 성능 향상을 달성했습니다. 다국어·편향·암기·안전성까지 종합 평가하여, 실제 제품·연구 활용 시에도 강력한 기반이 될 수 있음을 확인했습니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/3353427e-ff92-4647-a0a5-f3025f71912a/2305.10403v3.pdf)

# 5 Responsible usage

“5 책임감 있는 사용” 장에서는 PaLM 2 모델을 안전하고 윤리적으로 활용하기 위한 원칙과 권고 사항을 다룹니다. 주요 내용은 두 개의 하위 섹션으로 구성됩니다.

## 5.1 추론 시 제어(Inference-time control)

1. **제어 토큰(Control token) 도입**  
   -  모델 사전학습 데이터 일부에 “저독성(Low)”, “중독성(Medium)”, “고독성(High)” 같은 제어 토큰을 삽입  
   -  토큰을 입력 앞이나 뒤에 붙이면 모델의 생성 텍스트 독성 수준을 실시간으로 조절 가능  

2. **독성 생성 시험**  
   -  비독성 입력(토큰화된 Perspective API 점수&lt;0.5) 50,000개 중 38,000개를 골라 시험  
   -  단일 응답(그리디 디코딩)마다 독성(점수≥0.5) 여부 측정  
   -  제어 토큰 미사용 시 약 7.6%가 독성 생성 → “저독성” 토큰 사용 시 3.3%로 절반 이상 감소[표 14]  

3. **대화 맥락(Dialog)에서의 효과**  
   -  일반 언어 모델링보다 대화형 프롬프트(“Assistant:” 등) 시 더 낮은 독성 생성  
   -  표준 대화 데이터셋에서 토큰 제어만으로 30%→12% 감소, 공격적(adversarial) 데이터셋에서 18%→7% 감소  
   -  다만 대화용 특화 시스템(LaMDA)에는 미치지 못해, 애플리케이션별 추가 조치 필요  

4. **고려 사항**  
   -  전체 프롬프트 독성 뿐 아니라, 다양한 샘플(Top-k)에서도 유효성 확인 필요  
   -  제어 토큰 삽입 비율이 작아 다른 기능에 미치는 부작용 거의 없음  
   -  추후 연구 과제: 더 정밀한 제어 토큰 설계, 모델-파인튜닝 연계 제어 강화를 통한 투명성·유연성 확보  

***

## 5.2 개발자를 위한 권고사항(Recommendations for developers)

1. **책임감 있는 개발 가이드 검토**  
   -  PaLM 2 논문 (Chowdhery et al., 2022) 및 Google AI 원칙(Google 2018)과 Generative AI 정책(Google 2023a, 2023b) 숙지  
   -  변환형 검증(“red teaming”) 기법(Bai et al., 2022), 악용 시뮬레이션(Ganguli et al., 2022) 활용  

2. **애플리케이션별 위험 평가**  
   -  대화, 분류, 번역, 질의응답 등 예시별로 잠재적 위해(독성, 편향, 프라이버시 침해) 점검  
   -  디코딩 전략(그리디·샘플링·탑-k/탑-p)과 프롬프트가 결과에 미치는 영향 실험  

3. **다양한 관점·언어 고려**  
   -  다국어 모델인 만큼, 한국어·영어·기타 언어에서 독성·편향 평가 지표 재검증  
   -  소수자·취약집단이 겪는 누적적 부정적 영향(“교차성” 차원) 반영  

4. **추가적 안전장치 도입**  
   -  애플리케이션 별 fine-tuning, 사용자 샘플링·응답 순위화(sample-and-rank), 외부 필터링 삽입  
   -  서비스 모니터링·로깅 체계 구축해 이상 징후 실시간 감지  

5. **지속적 평가와 개선**  
   -  모델·데이터 변경 시 검증 테스트 재실행해 부작용 발생 여부 점검  
   -  내부·외부 감사, 사용자 피드백 수집·분석 루프 구축  

***

PaLM 2는 추론 시 제어 토큰으로 독성 생성 억제 등의 **실시간 제어** 기능과, 애플리케이션 수준에서 **책임감 있는 사용**을 위한 다양한 **개발자 권고사항**을 제공합니다. 그러나 최종 서비스에 적용하기 위해서는 이들의 효과를 자체적인 평가와 모니터링 절차로 보완·검증하여야 합니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/3353427e-ff92-4647-a0a5-f3025f71912a/2305.10403v3.pdf)
