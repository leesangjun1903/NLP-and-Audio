# G-EVAL: NLG Evaluation Using GPT-4 with Better Human Alignment

**핵심 주장 및 주요 기여 요약**  
G-EVAL은 대형 언어 모델(LLM)을 체인오브-생각(chain-of-thought) 방식으로 활용해 자연어 생성(NLG) 출력의 품질을 평가하는 새로운 프레임워크이다. GPT-4를 백본 모델로 사용하여 요약·대화 생성 과제에서 기존 평가 지표 대비 인간 평가와의 상관성을 크게 향상시켰다. 주요 기여는 다음과 같다:  
- CoT 기반 자동 평가 절차 생성으로 평가 기준의 세분화  
- 점수 토큰 확률을 가중합해 연속적이고 미세한 평가 점수 산출  
- 요약과 대화 생성 모두에서 인간 평가와 상관성 개선  

***

## 1. 해결하고자 하는 문제  
기존 NLG 자동 평가 지표(BLEU, ROUGE, BERTScore 등)는 인간 평가와 낮은 상관성을 보이며, 특히 개방형·창의적 과제(대화, 추상 요약)에서 부정확하다. 또한 LLM 기반 평가도 단일 확률 점수만 이용해 세밀도가 떨어진다.

***

## 2. 제안하는 방법  
### 2.1. 프롬프트와 체인오브-생각 생성  
1) **Task Introduction**: 평가 과제와 기준을 자연어로 정의  
2) **CoT 생성**: LLM에 “Evaluation Steps”를 묻고, 요약·대화 품질 평가를 위한 세부 절차를 자동 생성  

### 2.2. 폼 필링(form-filling) 평가  
- CoT와 입력(원문·생성문)을 결합해 LLM에게 각 평가 차원별 점수(1–n)를 출력하도록 요청  
- 예: 일관성, 응집성, 유창성, 관련성 등  

### 2.3. 확률 가중 합산  
LLM이 생성한 각 점수 토큰 $$s_i$$의 확률 $$p(s_i)$$를 구해 다음 식으로 최종 점수 산출:  

$$
\text{score} = \sum_{i=1}^{n} p(s_i) \times s_i
$$  

이로써 정수 기반 평가의 계단 현상을 완화하고, 연속적·미세한 점수 분포 확보.

***

## 3. 모델 구조 및 구현  
- **백본 모델**: GPT-3.5(text-davinci-003) 및 GPT-4  
- GPT-3.5: 온도 $$T=0$$로 결정론적 출력  
- GPT-4: 샘플링 $$n=20$$, 온도 $$T=1$$, top-p=1로 토큰 확률 추정  
- 입력: Task Introduction + CoT + 원문 + 생성문  
- 출력: 평가 폼(각 차원별 점수)

***

## 4. 성능 향상  
### 4.1. 요약 평가(SummEval)  
- GPT-4 기반 G-EVAL: 평균 Spearman ρ=0.514, Kendall’s τ=0.418로 기존 UniEval 대비 0.04–0.1 포인트 향상  
- CoT 도입 전/후 비교: 모든 차원에서 CoT 사용 시 상관성 상승  

### 4.2. 대화 생성 평가(Topical-Chat)  
- GPT-4: 평균 Spearman ρ=0.575, Kendall’s τ=0.588  
- GPT-3.5와 유사한 성능, 다소 쉬운 과제 환경에서 모델 크기 차별화 미미  

### 4.3. Hallucination 측정(QAGS)  
- 추출적 데이터셋에서는 BARTScore에 근접, 추상적(XSum)에서는 G-EVAL-4가 우월  
- GPT-3.5 대비 GPT-4가 일관성 차원에서 대폭 향상  

***

## 5. 한계 및 일반화 성능  
- **LLM 생성문 편향**: G-EVAL은 LLM이 생성한 텍스트에 일관되게 높은 점수를 부여하는 경향이 있어, 자가강화(self-reinforcement) 현상 우려  
- **모델 용량 의존성**: 복잡한 평가(일관성, 사실성)에서는 GPT-4 급 대형 모델에서만 실질적 성능 확보  
- **데이터/언어 확장성**: 영어 요약·대화에 집중되어 있어 다국어 및 다른 NLG 과제에 대한 일반화 검증 필요  

***

## 6. 미래 연구에의 영향 및 고려 사항  
- **LLM 기반 평가의 자가강화 방지**: 평가에 사용되는 LLM과 다른 모델을 분리하거나, 휴먼 피드백 루프를 구성해 편향 완화 필요  
- **경량화된 CoT 평가 절차**: 중소형 모델에서도 활용 가능한 CoT 프롬프트 설계 연구  
- **다국어·멀티모달 확장**: 비영어권, 음성·이미지 생성 평가로의 적용 가능성 탐색  
- **샘플 효율성**: GPT-4 같은 대형 모델 호출 비용을 줄이기 위한 샘플링·지식증류(distillation) 기법 도입  

G-EVAL은 향후 NLG 평가의 새로운 표준이 될 수 있으며, 특히 CoT와 확률 기반 가중합을 통해 보다 세밀하고 인간 친화적인 평가를 제안한다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/9e763c26-2081-4652-8c6d-12a5f1900d01/2303.16634v3.pdf)
