# Tree of Thoughts: Deliberate Problem Solving with Large Language Models

## 1. 핵심 주장과 주요 기여  
이 논문은 **대형 언어 모델(LLM)의 토큰 단위 연속 생성 한계**를 극복하기 위해, 문제 해결 과정에서 **일관성 있는 중간 단계(“thought”)를 트리 구조로 탐색**하는 새로운 추론 패러다임인 **Tree of Thoughts(ToT)**를 제안한다. 주요 기여는 다음과 같다.[1]
- **Tree of Thoughts 프레임워크 제시**: 문제를 노드가 중간 해결 과정을 나타내는 트리 탐색 문제로 일반화.  
- **생성, 평가, 탐색 모듈화**: 중간 단계 생성(G), 상태 평가(V), BFS/DFS 기반 탐색 알고리즘을 독립적으로 설계·교체 가능.  
- **다양한 문제에 적용**: 산술 퍼즐(Game of 24), 창의적 글쓰기, 5×5 미니 십자말풀이까지 세 가지 어렵고 유형이 다른 문제에서 기존 체인 오브 코트(CoT) 대비 획기적 성능 향상 확인.  

## 2. 문제 정의, 제안 방법, 모델 구조, 성능 및 한계  

### 2.1 해결하고자 하는 문제  
전통적 LLM 추론은 토큰 단위의 왼쪽→오른쪽 생성만 가능해,  
- 초기 결정이 잘못되면 교정 불가  
- 기획, 탐색, 백트래킹 같은 **글로벌 탐색 계획** 부재  
이로 인해 **조합적·계획적 문제**(수학 퍼즐, 구조화된 생성 등) 해결에 취약하다.[1]

### 2.2 제안 방법  
ToT는 문제 x를 중간 사고 단계 z₁…zᵢ를 거쳐 해답 y로 가는 트리 탐색으로 모델링한다.  
1) **생각 단위(thought)**: 연산식 한 줄, 계획 문단, 단어 등 문제 특성에 맞게 설계  
2) **사고 생성 G(pθ, s, k)**  
   a. 독립 샘플링: $$z^{(j)}\_{i+1}\sim p_{\text{CoT}\_\theta}(z_{i+1}\mid s)$$ (k회)  
   b. 순차 제안: $$[z^{(1)}…z^{(k)}]\sim p_{\text{propose}\_\theta}(z_{i+1}^{(1…k)}\mid s)$$  
3) **상태 평가 V(pθ, S)**  
   a. 개별 가치: $$V(p_\theta,S)(s)\sim p_{\text{value}\_\theta}(v\mid s)$$  
   b. 투표 방식:

```math
V(p_\theta,S)(s)=1[s=s^*], \quad s^* \sim p_{\text{vote}_\theta}(s\mid S)
```

4) **탐색 알고리즘**  
   - **BFS** (Algorithm 1): 깊이 제한 T, 너비 제한 b  
   - **DFS** (Algorithm 2): 가치 임계치 v_thres로 가지치기 및 백트래킹  

### 2.3 모델 구조  
- 베이스는 사전 학습된 GPT-4  
- **프롬프트 기반**으로 G·V 모듈화  
- 별도 학습 없이 **0~few-shot 프롬프트**만 사용  

### 2.4 성능 향상  
| Task                 | CoT Self-Consistency | ToT (b=5) |
|----------------------|----------------------|-----------|
| Game of 24 (성공률)  | 9.0%                 | 74%       |
| Creative Writing (coherency) | 6.93→7.56/10        | 7.56      |
| Mini Crosswords (단어 정답률) | 15.6%               | 60%       |  
ToT는 CoT가 **첫 단계에서 실패**하는 비율(약 60%)를 극복하고, **폭넓은 탐색**으로 최종 성과를 대폭 향상시킨다.[1]

### 2.5 한계  
- **비용·속도**: BFS/DFS 탐색 복합도로 인해 API 호출량·토큰 수 급증  
- **평가 휴리스틱 불완전**: 잘못된 가치 추정으로 유망해 보이는 해답이 배제될 수 있음  
- **얕은 탐색 깊이**: 연구에서는 최대 깊이 5 이하로 평가, 더 깊은 구조적 문제에 미지수  

## 3. 일반화 성능 향상 가능성  
ToT의 **모듈성**은 다양한 문제에 유연하게 적용 가능하다.  
- **제로-샷 ToT**: GSM8K, StrategyQA 등의 표준 추론 과제에서도 CoT 대비 소폭 향상  
- **모델 교체 유연성**: GPT-3.5에서도 ToT > CoT > IO 관계 유지[1]
- **탐색 알고리즘 확장**: A*·MCTS 같은 고급 기법 도입 시 더 복잡한 문제로 확장 가능  
- **프롬프트 설계** 최적화 및 휴리스틱 학습을 통해 평가 정확도 증가 기대  

이처럼 LLM 기반 문제 해결을 단순 생성에서 **탐색 계획**으로 일반화함으로써, 다양한 형식·도메인 문제에 적용 가능하다.  

## 4. 미래 연구 영향 및 고려 사항  
**영향**: ToT는 LLM 활용 범위를 ‘단순 텍스트 생성 → 고차원적 의사결정·계획’으로 확장하며,  
- **로보틱스·코드 생성·데이터 분석** 분야에 탐색·백트래킹 기법 접목  
- **LLM 자체 평가 역량** 강화 연구 촉진  

**고려 사항**:  
- **효율성 개선**: 탐색 예산·가지치기 전략 최적화  
- **평가 신뢰도**: 학습된 가치 모델과 결합하거나 인간 피드백 통합  
- **모델 크기·비용 절감**: 경량 모델에 ToT 적용 및 비용-성능 균형 맞추기  
- **안전성·정책 준수**: 자율 계획 특성상 잘못된 의사결정 방지 메커니즘 필요  

— Tree of Thoughts는 LLM의 연역적·계획적 문제 해결 능력을 한층 끌어올릴 수 있는 혁신적 방향을 제시한다.[1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/6225519b-55f5-4fd6-8fde-2f4fe50e304f/2305.10601v2.pdf)
