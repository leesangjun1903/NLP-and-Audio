# Proving Olympiad Inequalities by Synergizing LLMs and Symbolic Reasoning

### 1. 핵심 주장 및 주요 기여 (요약)

이 논문은 **LIPS**(LLM-based Inequality Prover with Symbolic reasoning)라는 신경-기호적(neuro-symbolic) 프레임워크를 제시하여, LLM의 수학적 직관과 기호적 방법의 도메인 특정 지식을 통합함으로써 올림피아드 수준의 부등식 증명 문제를 해결한다. 핵심 기여는 다음과 같다:[1]

**주요 기여점:**
- **전술 분류**: 인간의 부등식 증명 전략을 두 가지 전술로 분류 - (1) **스케일링(Scaling)**: 기호적 방법으로 처리, (2) **리라이팅(Rewriting)**: LLM으로 처리
- **효과적인 통합**: 각 접근법의 강점을 활용하여 제한된 형식화 증명 데이터 없이도 최첨단 성능 달성
- **실증적 성과**: 161개의 도전적인 부등식에서 평가하여 기존 LLM 및 기호적 접근법을 현저히 능가

### 2. 상세 설명: 문제 정의, 제안 방법, 모델 구조, 성능

#### 2.1 문제 정의

**기본 문제 클래스**:[1]
이 논문은 다음 형태의 초등 대수 부등식(Elementary Algebraic Inequality)을 다룬다:

$$\Phi_j \triangleleft\!\!\triangleright 0, \quad j = 1, \ldots, m$$

여기서 $\triangleleft\!\!\triangleright \in \{≤, <, ≥, >, =, \neq\}$이고, 각 다항식은 $n$개 변수로 정의된다:

$$\Phi_j(x_1, \ldots, x_n) := \sum_{i=1}^k a_i \cdot x_1^{i_1} x_2^{i_2} \cdots x_n^{i_n}$$

**문제의 어려움:**[1]
- LLM 기반 접근: 광대한 전술 공간과 형식화 증명 데이터 부족
- 기호적 방법(CAD): 이중 지수 계산복잡도로 인해 경쟁 수준 문제에서 비실효적
- 인간 판독 가능한 증명 생성 불가

#### 2.2 제안 방법: LIPS 프레임워크

**프레임워크 구조**:[1]

LIPS는 다음 네 가지 핵심 단계로 구성된다:

**(1) 스케일링 전술 생성 및 가지치기**

스케일링 전술은 기존 부등식 보조정리(예: AM-GM, Cauchy-Schwarz)를 현재 목표의 부분항에 적용한다. 주어진 보조정리에 대해 **e-매칭(e-matching)**을 사용하여 모든 가능한 패턴 인스턴스화를 열거한다:

$$\text{For lemma: } u^2 + v^2 \geq 2uv$$

가능한 인스턴스화 예시: $\{u := a, v := b\}$, $\{u := a, v := \sqrt{2}\}$, $\{u := 1, v := \frac{1}{\sqrt{a^2+2}}\}$

**검증 및 가지치기:**
생성된 각 스케일링 전술에 대해, SMT 솔버(Z3, CVC5, RC-CAD, Bottema)를 사용하여 반례를 검색한다. 반례가 발견되면 그 전술을 제거한다.

$$\text{Pruning ratio} = \frac{\text{Valid tactics}}{\text{Total tactics}} \times 100\%$$

논문의 실험에서 평균적으로 70-90%의 스케일링 전술이 제거되었다.[1]

**(2) 리라이팅 전술 생성**

리라이팅 전술은 항을 동치 형태로 변환한다 (예: 양변에서 $2ab$ 빼기). 동치 변환의 수가 무한하므로 LLM 프롬프팅을 사용한다.

**16가지 리라이팅 연산:**[1]
- 단순화 (조건 있음/없음)
- 제곱 완성, 변수 대체
- 식의 확장, 재배열
- 분자/분모 약분
- 거듭제곱 약분
- 공약수 추출/약분
- 분수 분리/축소
- Sum-of-squares 트릭
- 접선(Tangent line) 트릭

**LLM 프롬프트 예시:**
```
Task: Simplify the inequality using condition: a² + b² + c² = 1
...
Output: [simplified form in \boxed{}]
```

각 연산에 대해 동일한 LLM에 3회 쿼리하여 다양한 변환을 커버한다.

**(3) 목표 필터링 및 신경 순위 지정**

스케일링과 리라이팅 전술을 적용하면 새로운 부분 목표들이 생성된다. 효율적인 증명 탐색을 위해 두 단계 필터링 프로세스를 적용한다:

**기호적 필터링 - 동차성 및 결합도 점수:**

$$DC(\Phi) = \frac{1}{k} \sum_{i=1}^k a_i \left( \sum_{j=1}^n I(i_j > 0) \right)$$

$$HM(\Phi) = \frac{1}{k} \sum_{i=1}^k \left( d_i - \frac{1}{k} \sum_{j=1}^k d_j \right)^2$$

여기서:
- $DC(\Phi)$: 결합도 점수 (낮을수록 더 나뉨)
- $HM(\Phi)$: 동차성 점수 (낮을수록 더 동차)
- $d_i = i_1 + \cdots + i_n$: $i$번째 항의 전체 차수

평균 점수: $\text{Score}_{\text{avg}} = \frac{DC(\Phi) + HM(\Phi)}{2}$

**신경 순위 - Chain-of-Thought 프롬팅:**

상위 $k$개 목표(필터링 후)를 LLM에 전달하여 증명 난이도에 따라 순위 지정.[1]

```
Original inequality: [...]
Transformed inequalities: (1), (2), (3)
Task: Rank in descending order of promising difficulty.
Output: \boxed{(2), (1), (3)}
```

**(4) 전체 증명 생성 과정**

**알고리즘 3 (전체 증명 생성):**[1]
```
Input: 형식 부등식 문제 g₀
       스케일링 전술 라이브러리 Φ
       리라이팅 전술 프롬프트 세트 Ψ
       언어 모델 M

Initialize Ω = {g₀}  // 후보 목표 집합

for i = 1, ... do
    Select first goal g from Ω
    Obtain tactic set T using Algorithm 1 on g
    
    for each tactic t in T do
        Apply t to g in Lean, derive new goal g'
        Add g' to Ω
    end for
    
    Update Ω using Algorithm 2 (filtering & ranking)
end for

Output: 형식 증명 또는 타임아웃
```

#### 2.3 성능 평가

**데이터셋:**[1]
- ChenNEQ: 41개 올림피아드 수준 부등식
- MO-INT: 20개 IMO 단축 및 국가 올림피아드 문제
- 567NEQ: 567개 어려운 부등식 중 100개 무작위 선택

**성능 비교 (표 1):**[1]

| 데이터셋 | 신경 기반 | 기호 기반 | **LIPS** | 개선도 |
|---------|----------|----------|---------|--------|
| | DSP | MCTS | AIPS | CAD | MMA | | |
| ChenNEQ | 0.0% | 17.0% | - | 70.7% | 68.2% | **95.1%** | +24.4%↑ |
| MO-INT | 0.0% | 15.0% | 50.0% | 60.0% | 60.0% | **80.0%** | +20.0%↑ |
| 567NEQ | 0.0% | 4.0% | - | 54.0% | 52.0% | **68.0%** | +14.0%↑ |
| **합계** | 0.0% | 8.6% | - | 59.0% | 57.1% | **76.3%** | +17.3%↑ |

**효율성 분석 (RQ2):**[1]

스케일링 전술 가지치기 비율에서 LIPS는 AIPS보다 평균 7.92% 개선을 달성했으며, 평균 15.75개의 탐색 루프로 증명을 완성했다 (Oracle의 7.25배 정도, 즉 2.17배).

**확장성 분석 (RQ3):**[1]

- 스케일링 전술 수 증가 시 성능 지속적 향상
- 필터링 집합 크기 8-16 사이에서 성능 안정적 (>85%)
- 더 강력한 LLM 사용 시 성능 향상 (Mathstral 7B → DeepSeek-chat → GPT-4o)

### 3. 모델 일반화 성능 향상 가능성 (중점)

#### 3.1 현재 일반화의 한계

**데이터 의존성 없음:**[1]
- 추가 학습 데이터 없이 기존 LLM과 기호적 솔버를 직접 사용
- 도메인 특정 형식화된 데이터의 부족(Lean의 경우 46K 샘플, AIPS 생성 데이터 191K)을 해결

**도메인 특정 최적화:**[1]
스케일링 전술은 96개의 사전 정의된 부등식 보조정리에 기반하며, 리라이팅 전술은 16가지 수동으로 설계된 연산이다.

#### 3.2 일반화 성능 향상 메커니즘

**(1) 스케일링 라이브러리 확장:**

현재 96개 전술에서 더 많은 보조정리를 추가하면 성능이 지속적으로 증가한다.[1]

$$\text{Success Rate}(n_{\text{tactics}}) \text{는 단조 증가}$$

논문의 실험에서: 0개 → 3/41, 96개 → 39/41 성공

**(2) LLM 성능 의존성:**[1]

| LLM | 리라이팅 | 신경 순위 |
|-----|---------|---------|
| 기준(SymPy) | 51.2% | 17.1% |
| Mathstral 7B | 92.7% | 73.2% |
| LLaMA-3 8B | 80.5% | 63.4% |
| DeepSeek-chat v2.5 | 87.8% | 85.4% |
| GPT-4o | **95.1%** | **95.1%** |

더 강력한 LLM을 사용하면 모두 성능이 향상된다.

**(3) 필터링 품질 개선:**

신경 순위 제거 시 성능 95.1% → 41.2%로 급락하고, 기호적 필터링만 사용 시 43.9%로 저하. 이는 둘 다 필수적임을 의미한다.[1]

#### 3.3 외삽(Generalization) 능력

**새로운 부등식에 대한 일반화:**[1]

논문에서는 세 가지 독립적인 데이터셋에서 평가하여 일반화 능력을 검증:
- ChenNEQ (Chen 2014)
- MO-INT (Wei 2024, AIPS)
- 567NEQ (Tung 2012)

**결과:**
LIPS는 세 데이터셋 모두에서 일관되게 최고 성능을 달성하여 도메인 외(Out-of-domain) 일반화 능력을 입증했다.

**제약사항:**[1]
- 현재는 초등 대수 부등식에만 적용
- 기호적 가지치기에 의존하므로 비다항식 항의 경우 보조 변수 도입 필요

### 4. 한계와 미래 연구 방향

#### 4.1 현재 한계[1]

**자동화 부족:**
- 96개 스케일링 전술과 16개 리라이팅 연산이 수동으로 작성됨
- 새로운 전술 추가에 인적 노력 필요

**확장성 제약:**
- 변수 수 증가 시 기호적 솔버의 이중 지수 복잡도
- 무한 변수나 기댓값 같은 고차 개념 미지원

**LLM 의존성:**
- "Lost in the middle" 문제: 컨텍스트 길이가 증가하면 LLM 효율성 저하
- 프롬프트 설계에 따른 민감성

#### 4.2 미래 연구 방향[1]

**(1) 전술 자동화:**
- 새로운 부등식 보조정리의 자동 발견, 형식화, 증명
- 메타-러닝을 통한 적응형 전술 라이브러리

**(2) LLM 개선:**
- 추가 형식화 부등식 문제 수집/생성 및 미세 조정
- Li et al. (2025)의 기법을 활용한 다양한 고품질 문제 생성

**(3) 응용 범위 확장:**
- 정보 이론, 최적화 이론의 부등식
- 기계 학습 이론의 농도 부등식(Concentration inequalities)
- 무한 변수 및 고차 개념 처리 능력 개발

**(4) 다른 정리 증명 영역:**
- 평면 기하학 (AlphaGeometry와 비교)
- 조합론
- 정수론

### 5. 최신 연구 기반 영향과 고려사항

#### 5.1 AI 정리 증명 분야에의 영향

**LLM 기반 정리 증명의 새로운 패러다임:**[1]

전통적 LLM 미세 조정 방식(Int, AIPS, DeepSeek-Prover)과 달리, LIPS는 다음을 제시한다:
- **데이터 없는 학습**: 추가 훈련 데이터 없이도 최첨단 성능
- **신경-기호 분업**: 어느 작업이 어느 방법에 적합한지 명확히 규정

**문제 공간 구조의 명시적 활용:**[1]
- 스케일링과 리라이팅의 수학적 특성 활용
- 도메인 지식의 효과적 인코딩

#### 5.2 2025년 최신 관련 연구들

현재 (2025년 11월 기준) ICLR 2025에 발표된 이 논문은 다음 연구들과의 연계성을 갖는다:[1]

**AlphaGeometry 계열:**
- Trinh et al. (2024): 기하학 문제에 특화된 신경-기호 접근
- 본 논문은 더 일반적인 부등식 영역으로 확대

**LLM 기반 정리 증명의 진화:**
- Yang et al. (2024): LeanDojo, 검색 증강 LLM
- Lin et al. (2025): Gödel-Prover, 전개 가능한 라이브러리

**신경-기호 학습의 일반화:**
- Li et al. (2025): 신경-기호 데이터 생성을 통한 수학 추론
- Blaauwbroek et al. (2024): Graph2Tac, 개념 표현 학습

#### 5.3 고려해야 할 사항

**(1) 실용성 평가:**
- 90분 타임리밋은 실제 올림피아드 조건과 일치
- 그러나 더 큰 문제 클래스에 대한 확장성 미지

**(2) 신뢰성 검증:**
- Lean 형식 검증을 통한 증명 정확성 보장 ✓
- 증명 발견 알고리즘의 완전성 증명 미흡

**(3) 비용-효율성:**
- GPT-4o 의존성 → 계산 비용 증가
- 오픈소스 LLM(LLaMA, DeepSeek)으로 85-87% 성능 달성 가능

**(4) 이론적 기초:**
- 왜 특정 LLM이 리라이팅에 더 나은가? → 기계적 증명보다 창의성 필요
- 왜 기호적 필터링이 효과적인가? → 도메인 구조의 정성적 특성 활용

### 결론

LIPS는 **LLM의 직관적 창의성과 기호적 방법의 정확한 검증을 결합**함으로써 부등식 증명에서 획기적인 성과를 달성했다. 추가 학습 데이터 없이도 기존 방법을 17.3% 능가하며, 인간이 읽을 수 있는 형식 증명을 생성한다. 향후 연구는 **전술 자동화**, **더 강력한 LLM 활용**, **다른 수학 영역으로의 확장**에 초점을 맞춰야 할 것이다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/cdea7a73-93c5-4e6d-969e-8bff077230fd/2502.13834v3.pdf)
