# Measuring AI Ability to Complete Long Tasks

### 1. 핵심 주장과 주요 기여

본 논문은 **AI 에이전트가 장시간에 걸쳐 완료할 수 있는 작업의 길이**를 측정하는 새로운 메트릭인 **"시간 지평선(task completion time horizon)"**을 제안합니다. 이는 인간 전문가가 특정 작업을 완료하는 데 소요되는 시간을 기준으로 삼아, AI 모델이 50% 확률로 성공할 수 있는 작업의 길이를 정량화하는 방식입니다.[1]

**핵심 발견 사항:**
- Claude 3.5 Sonnet 등 현재 최첨단 AI 모델의 시간 지평선은 약 **50분** 정도입니다[1]
- 2019년부터 2025년까지 **약 7개월마다 지평선이 2배씩 증가**하는 지수 함수적 추세를 보입니다[1]
- 이러한 추세가 지속될 경우, 향후 5년 내 AI 시스템은 **현재 인간이 한 달 정도 걸리는 소프트웨어 작업을 대부분 자동화할 수 있게 될 것으로 예측**됩니다[1]

### 2. 연구의 문제 정의 및 해결 방법

#### 2.1 문제 정의

기존의 AI 벤치마크(GLUE, SuperGLUE, MMLU 등)는 다음과 같은 한계를 가지고 있습니다:[1]

1. **인공적이고 경제적 가치가 낮은 작업**: 대부분의 벤치마크가 실제 업무와 괴리가 있습니다
2. **벤치마크 포화**: 개별 벤치마크가 빠르게 포화되어 모델 간 의미 있는 비교가 어렵습니다
3. **통일된 메트릭 부재**: 서로 다른 능력 수준의 모델(예: GPT-2 vs o1)을 비교할 수 있는 일관된 척도가 없습니다

#### 2.2 제안하는 방법론

연구팀은 **심리측정학의 항목 반응 이론(Item Response Theory, IRT)**에 영감을 받아 로지스틱 회귀 모델을 사용합니다.[1]

**핵심 수식:**

$$P(\text{success}_{\text{model}, \text{task}}) = \frac{1}{1 + \exp(\beta_{\text{model}} \log h_{\text{model}} - \log t_{\text{task}} - \alpha_{\text{model}})}$$

여기서:
- $$t_{\text{task}}$$: 성공한 인간 기준선의 기하 평균 시간
- $$h_{\text{model}}$$: 모델의 50% 시간 지평선 (학습할 매개변수)
- $$\alpha_{\text{model}}, \beta_{\text{model}}$$: 모델별 학습 매개변수

이 방법은 전통적 IRT와 달리, **인간 기준선 데이터를 활용**하여 작업 난이도를 시간으로 정의합니다.[1]

#### 2.3 데이터셋 구성

연구팀은 총 **170개의 작업**으로 구성된 3가지 벤치마크를 구축했습니다:[1]

| 벤치마크 | 작업 수 | 난이도 범위 | 특징 |
|---------|--------|----------|------|
| **HCAST** | 97개 | 1분 ~ 30시간 | 소프트웨어 엔지니어링, ML, 사이버보안 작업 |
| **RE-Bench** | 7개 | 8시간 고정 | ML 연구 엔지니어링 작업 |
| **SWAA** | 66개 | 1초 ~ 30초 | 원자적 소프트웨어 개발 작업 |

**인간 기준선:**
- 총 **800개 이상의 기준선**, 약 **2,529시간**의 인간 작업 시간 기록[1]
- 평균 약 **5년 경력**의 소프트웨어 엔지니어, ML 엔지니어, 사이버보안 전문가 참여[1]

### 3. 모델 구조 및 에이전트 아키텍처

#### 3.1 에이전트 스캐폴딩(Agent Scaffolding)

연구팀은 **ReAct 프레임워크**에 기반한 두 가지 주요 스캐폴딩을 사용했습니다:[1]

**1. Modular 스캐폴딩 (기본):**
- 모델이 Python 및 Bash 명령을 생성
- 환경에서 실행되고 피드백(stdout/stderr) 반환
- 간단한 문맥 관리로 LM의 문맥 길이 내에 유지

**2. Triframe 스캐폴딩 (o1/o1-preview용):**
- 1개의 계획 + 3개의 실행 계획 + 3개의 계획 무시 명령 생성
- 각 행동에 -2 ~ +2 점수 부여
- 점수가 높은 행동 선택 실행

#### 3.2 평가된 모델

2019-2025년 출시된 **13개의 최첨단 모델** 평가:[1]
- GPT-2, davinci-002 (GPT-3), gpt-3.5-turbo-instruct
- GPT-4 시리즈 (0314, 0125, 1106, Turbo, o)
- Claude 3 Opus, Claude 3.5 Sonnet, Claude 3.7 Sonnet
- o1-preview, o1

각 모델-작업 조합당 **8번의 실행** 수행[1]

### 4. 성능 향상 분석

#### 4.1 주요 성능 지표

**모델 성공률과 작업 난이도 관계:**

$$\text{success rate} = 0.07 \times \log(\text{human time}) + 0.66$$
$$R^2 = 0.83$$

이는 인간 작업 시간의 로그값이 모델 성공률을 설명하는 **강력한 예측 인자**임을 보여줍니다.[1]

#### 4.2 시간 지평선 증가 추세

**핵심 결과:**
- **50% 시간 지평선**: 약 212일마다 2배 증가 (95% CI: 171-249일)[1]
- **80% 시간 지평선**: 213일마다 2배 증가 (50% 지평선보다 약 5배 짧음)[1]
- 2024-2025 추세가 더 빠를 가능성: 2024년부터 가속화 신호[1]

#### 4.3 성능 향상의 주요 요인

질적 분석을 통해 다음 **3가지 주요 개선 메커니즘** 확인:[1]

**1. 도구 사용 능력 향상:**
- 모델들이 Python/Bash 명령을 더 효과적으로 활용
- 환경 피드백에 더 잘 대응

**2. 오류 적응 능력 개선:**
- GPT-4 1106: 실패 사유 중 33%가 "반복되는 실패 행동"[1]
- o1: 2/32만 반복 실패 (93% 감소)[1]
- Claude 3.5 Sonnet: 오류 발생 후 효율적인 복구

**3. 논리 추론 및 코드 생성 개선:**
- 복잡한 프로그래밍 작업에서 문법적/의미적으로 정확한 코드 작성

### 5. 한계 및 일반화 성능 분석

#### 5.1 주요 한계

**1. "메시한" 작업에서의 낮은 성능:**

연구팀은 **16개 메시성 요소**를 정의하여 현실 작업과의 차이를 정량화했습니다:[1]
- 자동 채점 불가능 작업
- 리소스 제약이 있는 작업
- 동적 환경 상호작용
- 실시간 조정이 필요한 작업

$$\text{성공률 감소} = -0.081 \times \text{메시성 점수}, \quad R^2 = 0.251$$

메시성 점수가 1 증가할 때마다 평균 성공률이 약 **8% 감소**[1]

**2. AI 에이전트의 주요 약점:**
- 명확한 피드백 루프가 없는 작업 실패 (블랙박스 회귀, 기호 회귀)[1]
- 정보 주도적 탐색 부재: 모델들이 능동적으로 도움말을 찾지 않음[1]
- 과도한 추측: API 문서 확인 전에 무작정 시도[1]

#### 5.2 일반화 능력 평가

**외부 타당성(External Validity) 검증:**

**1. Messiness 분석 결과:**
- 저메시성 작업: 2023-2025년 40 백분 포인트 증가[1]
- 고메시성 작업: 2023-2025년 40 백분 포인트 증가[1]
- **결론**: 메시성이 높은 작업에서도 성능 증가 추세가 유지됨[1]

**2. SWE-bench Verified 검증:**
- 동일한 지수 추세 관찰[1]
- 배 증가 시간: 약 70일 (원래 104일보다 빠름)[1]
- 이유: 낮은 난이도 작업의 시간 추정이 과소평가됨[1]

**3. 내부 PR 실험:**
- 저-문맥 계약자(contractors): 5-18배 더 오래 소요[1]
- 고-문맥 저장소 관리자(maintainers)와의 시간 차이 발생
- **결론**: 시간 지평선이 **저-문맥 노동자의 작업 능력**을 더 잘 반영[1]

**일반화 가능성 평가:**
- 절대 성능은 메시한 작업에서 낮음
- **그러나 성능 증가 추세는 유지됨** ← 중요한 발견
- 현실 작업으로의 일반화 가능성에 대한 불확실성 여전함[1]

### 6. 향후 추세 예측

#### 6.1 1개월(167시업 시간) 지평선 달성 시점

**기본 외삽법(Naïve Extrapolation):**

$$t_{\text{month}} = t_0 + 8 \times T_{\text{double}}$$

여기서 $$t_0$$는 o1의 출시 시점, $$T_{\text{double}}$$은 배 증가 시간

**예측 결과:**
- 중앙값: **2029년 말**[1]
- 80% 신뢰 구간: 2028년 말 ~ 2031년 초[1]
- 2024-2025 추세 적용 시: **2027-2028년 상반기** (더 낙관적)[1]

#### 6.2 성장률 변화 요인

**성장을 가속화할 요소:**

1. **에이전시 학습(Agency Training):**
   - 보상 기반 강화학습으로 에이전시 능력 향상
   - 사전학습보다 사후학습이 더 효율적[1]

2. **AI R&D 자동화:**
   - AI 시스템이 자신의 개발을 가속화할 수 있을 때[1]

**성장을 둔화할 요소:**

1. **계산 스케일링 한계:**
   - GPT-2 이후 10,000배의 계산량 증가[1]
   - 5년 내 추가 수배 스케일링의 한계 가능성[1]

2. **알고리즘 효율성:**
   - 역사적으로 계산 요구사항 감소 대체 가능[1]

### 7. 최신 연구와의 연결성 및 향후 연구 방향

#### 7.1 현재 AI 에이전트 분야의 발전

**자체 진화 에이전트(Self-Evolving Agents):**
- MUSE 프레임워크: 경험 축적을 통해 장시간 작업 성능 70%+ 향상[2]
- 계층적 메모리 모듈로 지속적 학습[2]

**멀티-에이전트 시스템:**
- 2025년 약 25%의 기업이 에이전트 AI 파일럿 시작, 2027년 50%로 증가 예상[3]
- 생성 AI 발전으로 에이전트가 실용적 자동화 도구로 진화[3]

**컴퓨터 사용 에이전트:**
- Agent S2: 다양한 OS 및 애플리케이션에서 기존 방법 대비 50-60% 성능 향상[4]

#### 7.2 일반화 성능 향상을 위한 고려사항

**1. 외부 타당성 개선:**
- 더 현실적이고 "메시한" 작업 벤치마크 개발 필요[1]
- 동적 환경, 다중 에이전트 상호작용, 리소스 제약을 포함한 작업 설계[1]

**2. 문맥 학습(In-context Learning) 강화:**
- 현재 에이전트들이 작업 특정 문맥을 충분히 활용하지 못함[1]
- 능동적 정보 탐색 메커니즘 개발 필요[1]

**3. 안전성 및 거버넌스:**
- AI가 한 달 이상의 작업을 독립적으로 수행 가능해질 경우, 안전 메커니즘 필수[1]
- CBRN 무기 자동 개발, 자기 증식 등 위험 시나리오 고려[1]

**4. 추론 시간 계산 활용:**
- 현재 에이전트는 추론 시간 계산을 거의 활용하지 않음[1]
- o1/o3 같은 모델의 추론 시간 확대 적용으로 성능 향상 가능성[1]

**5. 멀티태스크 학습 및 전이:**
- 서로 다른 도메인 간 기술 전이 메커니즘 개발[4]
- 단순 작업 성공이 복잡한 작업에도 일반화될 수 있는 구조[4]

#### 7.3 평가 방법론 개선

**향후 연구 시 고려할 점:**

1. **더 엄격한 인간 기준선:**
   - 현재 기준선에는 선택 편향 존재 (성공한 시도만 기록)[1]
   - 더 큰 샘플 크기 및 일관된 기술자 필요[1]

2. **모델 간 공정한 비교:**
   - 각 모델에 더 많은 엘리시테이션(elicitation) 노력 필요[1]
   - o1은 2-3주의 엔지니어링이 적용됨[1]

3. **도메인 다양성:**
   - 현재 소프트웨어/ML 작업에 편중[1]
   - 과학, 비즈니스, 창의적 작업 등 다양한 도메인 포함[1]

### 결론

본 논문의 **시간 지평선 메트릭**은 AI 능력을 **인간과 직접 비교 가능한 방식**으로 정량화하는 중대한 기여를 합니다. 약 7개월마다 2배씩 증가하는 추세는 매우 인상적이며, 향후 4-7년 내 AI가 인간 월간 작업을 자동화할 수 있음을 시사합니다.[1]

그러나 **메시한 현실 작업에서의 성능 차이**와 **일반화 가능성의 불확실성**은 주요 해결 과제입니다. 향후 연구는 더 현실적인 벤치마크 개발, 에이전트의 능동적 학습 능력 강화, 그리고 무엇보다 **안전 메커니즘 구축**에 집중해야 할 것입니다.[1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/30e41892-4746-4e55-affe-cb8eabd5ebd6/2503.14499v2.pdf)
[2](https://arxiv.org/abs/2510.08002)
[3](https://www.researchprotocols.org/2024/1/e60361)
[4](http://medrxiv.org/lookup/doi/10.1101/2025.10.17.25338266)
[5](https://journalofcloudcomputing.springeropen.com/articles/10.1186/s13677-025-00738-9)
[6](http://arxiv.org/pdf/2211.11174.pdf)
[7](http://arxiv.org/pdf/2401.03428v1.pdf)
[8](https://arxiv.org/pdf/2203.08994v2.pdf)
[9](https://arxiv.org/pdf/2503.12687.pdf)
[10](http://arxiv.org/pdf/2402.05929.pdf)
[11](https://arxiv.org/html/2504.00906v1)
[12](http://arxiv.org/pdf/2503.03459.pdf)
[13](https://arxiv.org/html/2503.23350v1)
[14](https://arxiv.org/html/2503.14499v1)
[15](https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/)
[16](https://safe.ai/blog/forecasting)
[17](https://dev.to/aniruddhaadak/the-rise-of-ai-agents-in-2025-24ba)
[18](https://proceedings.neurips.cc/paper_files/paper/2024/file/7d6e85e88495104442af94c98e899659-Paper-Conference.pdf)
[19](https://www.e-spincorp.com/ai-safety-for-autonomous-systems-avoiding-unintended-impacts/)
[20](https://www.ml-science.com/blog/2025/4/17/developments-in-ai-agents-q1-2025-landscape-analysis)
[21](https://arxiv.org/abs/2509.08755)
[22](https://arxiv.org/html/2504.18328v1)
[23](https://cs191w.stanford.edu/projects/Spring2025/Humishka___Zope_.pdf)
