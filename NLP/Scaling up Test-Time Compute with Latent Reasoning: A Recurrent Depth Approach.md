
# Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach

## 1. 핵심 주장과 주요 기여

본 논문은 **언어 모델의 테스트 시간 계산을 반복적인 잠재 추론(latent reasoning)을 통해 확장하는 새로운 접근법**을 제시합니다. 기존의 Chain-of-Thought(CoT) 기반 추론이 장문의 외부 토큰을 생성하는 방식과 달리, 이 연구는 모델이 **연속 잠재 공간에서 암묵적으로 추론**할 수 있도록 하는 재귀적 깊이(recurrent depth) 아키텍처를 도입합니다.[1]

**주요 기여:**
- 3.5B 매개변수, 800B 토큰으로 학습한 재귀적 깊이 모델 개발[1]
- 테스트 시간에 최대 50B 매개변수 고정 깊이 변환기에 해당하는 계산량까지 성능 개선 가능성 입증[1]
- 특별한 학습 데이터나 미세조정 없이도 적응형 계산, KV-캐시 공유, 자기 추측 디코딩 등의 기능 자동으로 지원[1]
- 잠재 공간에서 궤도(orbits), 수렴 경로, 방향 드리프트 등 흥미로운 계산 패턴의 자연적 출현 분석[1]

***

## 2. 문제 설정, 제안 방법 및 모델 구조

### 2.1 문제 설정

기존 LLM의 추론 능력 확장 방식은 두 가지로 제한됩니다.

1. **매개변수 확장**: 막대한 데이터와 계산량 필요
2. **Chain-of-Thought 기반 테스트 시간 확장**: 장문의 토큰 생성 필요로 메모리 부담 증가, 특화된 학습 데이터 필요

본 논문은 이러한 한계를 극복하기 위해 **모델이 높은 차원의 연속 잠재 공간에서 비언어적 추론을 수행**할 수 있도록 하는 접근법을 제안합니다.

### 2.2 제안 방법: 재귀적 깊이 아키텍처

#### 2.2.1 거시적 설계

모델은 세 가지 기능 블록으로 구성됩니다:

$$P(\text{Prelude}): \text{입력 토큰을 잠재 공간으로 임베딩}$$

$$R(\text{Recurrent Block}): \text{상태 } s \in \mathbb{R}^{n \times h} \text{를 반복 처리}$$

$$C(\text{Coda}): \text{잠재 공간에서 어휘로 디코딩}$$

**순방향 계산 과정:**

$$e = P(x)$$

$$s_0 \sim \mathcal{N}(0, \sigma^2 I_{nh})$$

$$s_i = R(e, s_{i-1}) \quad \text{for } i = 1, \ldots, r$$

$$p = C(s_r)$$

여기서 $x$는 입력 토큰 시퀀스, $r$은 반복 횟수, $p$는 다음 토큰의 확률입니다.

**핵심 설계 원리:**
- 입력 임베딩 $e$를 매 반복 단계에서 주입: 안정적인 수렴과 경로 독립성 보장
- 랜덤 초기화: 초기 조건에 의존하지 않는 수렴 가능
- 깊이의 최소성: 안정적인 반복 연산자 학습에 필요한 최소 구조

#### 2.2.2 미시적 설계

각 블록은 표준 변환기 층으로 구성되며, 안정성을 위해 **샌드위치 정규화 형식**을 사용합니다:

$$x_l^n = n_2(x_l^{l-1})$$

$$x_l^{att} = \text{Attention}(n_1(x_l^{l-1})) + x_l^n$$

$$x_l = \text{MLP}(n_3(x_l^{att})) + x_l^{att}$$

여기서 $n_1, n_2, n_3$는 RMSNorm 층입니다.

**전체 아키텍처 특성:**
- 아키텍처 형태: $(l_P, l_R, l_C)$ = (2, 4, 2)
- 은닉 크기: $h$ = 5280
- 총 매개변수: 3.5B (비반복 사전/후미 1.5B씩, 반복 코어 1.5B)
- 유효 깊이: $2 + 4r + 2$개 층 (r=32일 때 130개 층에 해당)

### 2.3 학습 목표 함수 (수식)

#### 2.3.1 반복 펼침(Unrolling)을 통한 학습

반복 반복 횟수를 무작위로 샘플링하여 학습합니다:

$$\mathcal{L} = \mathbb{E}_{x \sim X} \mathbb{E}_{r \sim \mathcal{R}} L_m(x, r, x')$$

여기서 $x'$는 좌측 시프트된 시퀀스(다음 토큰들)입니다.

**반복 횟수 분포:**

반복 횟수 $r$은 로그-정규 포아송 분포를 따릅니다:

$$\mathcal{R} = \text{Poisson}\left(e^{\mathcal{N}(\log(r-1) - \frac{\sigma^2}{2}, \sigma^2)}\right)$$

표적 평균 $\bar{r} = 32$, 분산 $\sigma^2 = 1$의 경우:

$$\text{mean} \approx 33, \quad \text{median} \approx 29, \quad \text{mode} \approx 24$$

이 분포는 대부분의 경우 평균보다 작은 값을 샘플링하되, 긴 꼬리로 가끔 매우 큰 값을 샘플링합니다.

#### 2.3.2 절단 역전파(Truncated Backpropagation)

메모리 효율성을 위해 마지막 $k=8$ 반복 단계만 역전파합니다:

$$\text{Only backprop through last } k \text{ steps}$$

하지만 사전 블록 $P(x)$는 매 단계에서 주입되므로 모든 단계에서 그래디언트 업데이트를 받습니다.

이는 RNN의 절단 역전파와 유사하지만, **시간 차원이 아닌 깊이 차원에서의 반복**입니다.

***

## 3. 성능 향상 및 일반화 능력

### 3.1 표준 벤치마크 성능

모델은 3.5B 매개변수이지만 사전 학습 중 32B 매개변수 변환기에 해당하는 FLOPs를 소비하며, 테스트 시 50B 매개변수까지 확장 가능합니다.

**주요 성과:**
- **GSM8K CoT** (수학 추론): 34.80% (유연한 매칭) vs OLMo-7B 6.07%
- **HumanEval** (코드 생성): 23.17% vs StarCoder2-3B 31.09%
- **ARC-Challenge** (상식 추론): 38.23% vs OLMo-7B 40.27%

### 3.2 테스트 시간 계산과 일반화

**맥락 의존적 수렴:**

ARC-Challenge 과제에서 few-shot 예제 수에 따른 반복 횟수:

| Few-shot 예제 수 | 포화점 반복 횟수 |
|---|---|
| 0-shot | 8-12 |
| 1-shot | ~20 |
| 5-shot | ~25 |
| 25-50-shot | ~32 |

모델은 더 많은 맥락이 주어질수록 더 많은 반복을 활용하여 추론하고, 이는 일반화 능력의 개선을 반영합니다.

**과제별 계산 활용도:**

| 과제 | 난이도 | 계산 활용 |
|---|---|---|
| HellaSwag | 낮음 | 8회 반복에서 최적 |
| GSM8K CoT | 높음 | 32회 반복까지 지속적 개선 |
| HumanEval | 높음 | 32회 반복까지 선형 개선 |

### 3.3 일반화 성능 분석

#### 3.3.1 재귀 vs 비재귀 기준선

동일한 설정에서 180B 토큰으로 학습한 모델 비교:

| 모델 | ARC-E | ARC-C | HellaSwag | GSM8K CoT |
|---|---|---|---|---|
| 비재귀 기준선 (r=1) | 34.01 | 23.72 | 29.19 | 0.00-0.15 |
| 재귀 모델 (r=32) | 53.62 | 29.18 | 48.80 | 9.02-10.24 |
| 성능 향상 | +19.61 | +5.46 | +19.61 | +9.02배 |

어려운 과제일수록 재귀 모델의 이점이 더 명확합니다.

#### 3.3.2 개방형 vs 폐쇄형 QA 성능

사실 기억 능력 vs 추론 능력 분석:

| 모델 | 폐쇄형 | 개방형 | 차이 |
|---|---|---|---|
| 우리 모델 (r=32) | 38.2% | 49.2% | +11.0% |
| OLMo-2 | 46.2% | 53.4% | +7.2% |

재귀 모델은 **사실 저장 용량은 감소하지만 맥락에 대한 추론 능력이 증대**됩니다. 적절한 배경 정보가 제공될 때 일반화 성능이 크게 향상됩니다.

***

## 4. 모델의 한계

### 4.1 학습 데이터 및 규모 한계

- 800B 토큰: 최신 공개 모델(OLMo는 3T+)에 비해 작음
- 공개 데이터만 사용: 산업용 모델(4T+ 개인 데이터)에 비해 제한적
- 47,000 단계, 학습률 냉각 없음: 최적화 미완료

### 4.2 아키텍처 제약

- **단일 재귀 단계**: 여러 연속 재귀 단계 고려 가능
- **선형 주의와의 관계**: 선형 주의 메커니즘은 시퀀스 길이에 선형이지만 비교 횟수 제한
- **매개변수 vs FLOPs 트레이드오프**: 계산 집약적이어서 효율성 고려 필요

### 4.3 해석성 우려

- **블랙박스 추론**: 외부적으로 검증 불가능한 암묵적 추론
- **인간 가독성 부족**: Chain-of-Thought와 달리 중간 과정 이해 어려움

***

## 5. 최신 연구와의 연관성 및 미래 방향

### 5.1 최신 AI 추론 패러다임과의 비교

#### 5.1.1 OpenAI o1-preview vs 본 논문

| 특성 | OpenAI o1 | 본 논문 |
|---|---|---|
| 추론 방식 | Chain-of-Thought (외부) | 잠재 공간 (내부) |
| 학습 데이터 | 특화된 추론 데이터 필요 | 표준 사전학습 데이터 |
| 메모리 효율성 | 낮음 (장문 출력) | 높음 (숨겨진 계산) |
| 해석성 | 높음 | 낮음 |

### 5.1.2 DeepSeek-R1 및 최신 연구 동향

최근 연구들(DeepSeek-R1, Quiet-STaR 등)은 **강화학습을 통한 암묵적 추론 학습**에 초점을 맞추고 있으며, 본 논문의 접근법은 더 간단한 사전학습 목표로도 가능함을 시사합니다.

### 5.2 미래 연구 고려사항

#### 5.2.1 아키텍처 개선

**혼합 전문가(MoE) + 재귀 깊이:**
- MoE는 복잡한 정보 저장/검색에 우수
- 재귀 깊이는 추론 패턴 학습에 우수
- 향후: 재귀 MoE 모델로 두 장점 결합 가능

$$\text{Recurrent MoE: 여러 반복에서 같은 전문가 재활성화 가능}$$

#### 5.2.2 사후학습(Post-training) 개선

**가능한 방향:**
- **반복 압축**: 테스트 시간 계산 효율성 증대를 위한 미세조정
- **강화학습**: 다양한 난이도의 데이터로 학습
- **CoT 내재화**: 외부 CoT 데이터를 암묵적 반복으로 변환

#### 5.2.3 효율적인 시퀀스 혼합

**선형 주의와의 시너지:**

선형 주의는 시퀀스 길이에 대해 선형이지만 요소 간 비교 횟수 제한:

$$\text{재귀 깊이로 선형 연산자 반복 가능} \Rightarrow \text{필요한 모든 비교 완료}$$

$$\text{결과적으로 효율성과 표현력 동시 달성}$$

#### 5.2.4 여러 재귀 단계

현재 단일 재귀 블록 사용, 향후 연구:
- 연속 재귀 단계 추가
- 각 단계별 독립적인 계산 구조
- 동적 단계 선택 메커니즘

***

## 6. 잠재 공간에서의 계산 메커니즘

### 6.1 나타나는 구조적 패턴

모델이 학습하지 않은 명시적 감시 없이도 다음과 같은 패턴이 자연스럽게 출현합니다:

#### 6.1.1 수렴 경로 (Convergent Paths)

많은 토큰에서 상태가 고정점으로 수렴:

$$\|s_i - s_\infty\| \to 0 \text{ as } i \to \infty$$

특히 간단한 과제에서 빠른 수렴.

#### 6.1.2 궤도 (Orbits)

수학적 추론이 필요한 토큰에서 다차원 궤도 패턴:

$$s_i \text{ traces out periodic or quasi-periodic orbit in latent space}$$

예: "3"에 대한 회전 행동이 산술 문제에서 관찰됨

#### 6.1.3 방향 드리프트 (Directional Drift - "Sliders")

특정 방향으로 일관되게 드리프트하는 궤적:

$$s_i = s_0 + i \cdot \Delta s + \text{noise}$$

반복 횟수 계산에 사용될 수 있는 메커니즘

### 6.2 경로 독립성 (Path Independence)

여러 초기 상태에서 시작해도 같은 궤적 패턴 도출:

$$\text{For different } s_0, s_0': \text{ trajectories converge to same attractor}$$

이는 모델의 **일관성과 안정성**을 나타냅니다.

***

## 7. 결론 및 학문적 영향

### 7.1 핵심 기여의 의의

본 논문은 다음과 같은 새로운 관점을 제시합니다:

1. **테스트 시간 계산의 새 축**: 매개변수, Chain-of-Thought에 이어 **잠재 반복** 추가
2. **특화된 데이터 불필요**: 표준 사전학습만으로 복잡한 추론 능력 자연 획득
3. **효율적 메모리 사용**: 외부 토큰 생성 대신 숨겨진 계산 활용
4. **자동 기능 지원**: 적응형 계산, 자기 추측 디코딩 등 미세조정 없이 지원

### 7.2 향후 연구의 중요 지점

1. **규모 확장**: 더 큰 모델/데이터로의 확장 연구
2. **하이브리드 접근**: CoT + 잠재 반복의 결합 방식
3. **이론적 기초**: 왜 이 아키텍처가 효과적인지 이론적 분석
4. **모니터링 및 안전성**: 암묵적 추론의 해석성 개선

***

## 참고 자료 방향

최신 관련 연구(2024-2025):
- **강화학습 기반 추론**: DeepSeek-R1, OpenAI o1
- **암묵적 CoT**: Quiet-STaR, Deliberation in Latent Space
- **길이 일반화**: Looped Transformers for Length Generalization
- **혼합 전문가 확장**: MoEUT (Mixture-of-Experts Universal Transformers)

***

**논문 정보**: Geiping et al., 2025, "Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach", arXiv:2502.05171v2

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/38ab5812-9d0f-4f21-8a71-a92806dc6a0c/2502.05171v2.pdf)
