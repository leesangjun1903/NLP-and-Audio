# LightRAG: Simple and Fast Retrieval-Augmented Generation

## 핵심 요약

**LightRAG**는 기존 검색-증강 생성(RAG) 시스템의 근본적인 한계를 해결하기 위해 설계된 혁신적인 프레임워크입니다. 기존 RAG 방식이 평면적(flat) 데이터 표현에만 의존하여 엔티티 간 복잡한 상호 의존성을 포착하지 못하는 반면, LightRAG는 **그래프 구조를 텍스트 인덱싱과 검색 프로세스에 통합**합니다. 이 논문의 핵심 기여는 세 가지입니다: (1) 그래프 기반 텍스트 인덱싱 패러다임으로 포괄적 정보 검색 실현, (2) 저수준(low-level)과 고수준(high-level) 이중 검색을 통한 효율성 증대, (3) 점진적 업데이트 알고리즘으로 동적 환경에서의 신속한 적응. 실험 결과, LightRAG는 Naive RAG, RQ-RAG, HyDE, GraphRAG 등 기존 기법들을 크게 능가하며, 특히 대규모 말뭉치와 복잡한 쿼리 환경에서 우수한 일반화 성능을 보여줍니다.

***

## 1. 논문의 배경 및 문제 제시

### 1.1 RAG 시스템의 필요성과 기존 한계

검색-증강 생성(RAG) 시스템은 대규모 언어모델(LLM)에 외부 지식 기반을 통합하여 응답의 정확성과 관련성을 향상시킵니다. 예를 들어, "전기자동차의 증가가 도시 공기질과 대중교통 인프라에 미치는 영향은?"이라는 질문에 대해, 기존 RAG는 전기자동차, 공기 오염, 대중교통 관련 문서들을 각각 검색하지만, 이들 정보 간의 **복잡한 상호 의존성을 종합하지 못해** 단편적이고 불완전한 답변을 제공합니다. 이는 다음과 같은 근본적인 한계에서 비롯됩니다:[1]

1. **평면적 데이터 표현의 한계**: 기존 방식들은 청크(chunk) 기반의 평면적 구조만 사용하여 엔티티 간 고수준의 관계를 표현하지 못합니다.

2. **문맥 인식의 부족**: 다양한 엔티티와 그들의 상호작용 간 일관성을 유지하지 못해 사용자의 의도를 완전히 반영하지 못합니다.

3. **검색 효율성 문제**: 대규모 데이터셋에서 모든 청크를 순회하거나 커뮤니티 보고서를 생성해야 하므로 계산 비용이 매우 높습니다.

4. **동적 업데이트 어려움**: 새로운 정보가 추가될 때 전체 인덱스를 재구성해야 하므로 빠른 적응이 어렵습니다.

***

## 2. LightRAG의 핵심 아이디어 및 방법론

### 2.1 그래프 기반 텍스트 인덱싱 패러다임

LightRAG의 첫 번째 혁신은 **그래프 기반 텍스트 인덱싱**입니다. 이는 문서를 처리할 때 엔티티(entity)와 관계(relationship)를 추출하여 구조화된 지식 그래프를 구축합니다.[1]

#### 수식적 표현:

$$\hat{D} = (\hat{V}, \hat{E}) = \text{Dedupe} \circ \text{Prof}(V, E)$$

$$V, E = \bigcup_{D_i \in D} \text{Recog}(D_i)$$

여기서 $\hat{D}$는 결과 지식 그래프, $V$와 $E$는 각각 노드(엔티티)와 엣지(관계), $\text{Recog}(\cdot)$는 엔티티-관계 추출 함수, $\text{Prof}(\cdot)$는 LLM 프로파일링 함수, $\text{Dedupe}(\cdot)$는 중복 제거 함수입니다.

#### 그래프 구성 단계:

1. **엔티티 및 관계 추출**: LLM을 활용하여 텍스트에서 "당사자(Cardiologist)", "대상(Heart Disease)", "관계(diagnoses)" 같은 정보를 자동으로 추출합니다.

2. **LLM 프로파일링 (핵심-값 쌍 생성)**: 각 엔티티 노드와 관계 엣지에 대해 텍스트 핵심-값 쌍 $(K, V)$를 생성합니다. 여기서 $K$는 검색용 인덱스 키(예: 엔티티 이름), $V$는 관련 텍스트 스니펫을 요약한 문단입니다. 관계는 연결된 엔티티의 글로벌 테마에서 파생된 다중 인덱스 키를 가질 수 있습니다.[1]

3. **중복 제거 최적화**: 서로 다른 문서 세그먼트에서 추출된 동일한 엔티티와 관계를 병합하여 그래프 크기를 최소화하고 연산 오버헤드를 감소시킵니다.

### 2.2 점진적 업데이트 알고리즘

기존 GraphRAG와 달리, LightRAG는 **전체 인덱스 재구성 없이** 새로운 데이터를 신속하게 통합합니다:[1]

$$\hat{D}_{\text{updated}} = (\hat{V} \cup \hat{V}', \hat{E} \cup \hat{E}')$$

새로운 문서 $D'$에 대해 동일한 그래프 기반 인덱싱을 적용하여 $\hat{D}' = (\hat{V}', \hat{E}')$를 생성한 후, 기존 노드 집합 $\hat{V}$와 새 노드 집합 $\hat{V}'$를 합집합으로 결합하고, 마찬가지로 엣지도 통합합니다. 이를 통해 계산 오버헤드를 극적으로 감소시킵니다.

### 2.3 이중 검색 패러다임: 저수준 및 고수준 검색

LightRAG의 두 번째 혁신은 **이중 검색 시스템**입니다:[1]

#### 저수준 검색 (Low-Level Retrieval):
- **목적**: 특정 엔티티와 그들의 속성 및 관계에 대한 정확한 정보 추출
- **특징**: 상세하고 구체적인 질문 처리에 최적화

#### 고수준 검색 (High-Level Retrieval):
- **목적**: 광범위한 주제와 개괄적 테마 다루기
- **특징**: 여러 관련 엔티티와 관계에 걸쳐 정보 수집

#### 이중 검색 알고리즘:

1. **쿼리 키워드 추출**: 주어진 쿼리 $q$에 대해 저수준 키워드 $k^{(l)}$과 고수준 키워드 $k^{(g)}$를 추출합니다.

2. **키워드 매칭**: 효율적인 벡터 데이터베이스를 사용하여 저수준 키워드를 후보 엔티티와 매칭하고, 고수준 키워드를 글로벌 키에 연결된 관계와 매칭합니다.

3. **고차 관련성 통합**: 검색된 그래프 요소의 로컬 부분그래프에서 인접 노드를 수집하여 정보 완전성을 강화합니다:

$$\{v_i | v_i \in V \land (v_i \in N_v \lor v_i \in N_e)\}$$

여기서 $N_v$와 $N_e$는 각각 검색된 노드 $v$와 엣지 $e$의 1홉 인접 노드입니다.[1]

### 2.4 복잡도 분석

LightRAG의 계산 복잡도는 두 부분으로 나뉩니다:[1]

**인덱싱 단계**: LLM을 청크당 호출하므로 총 호출 횟수는 $\frac{\text{total tokens}}{\text{chunk size}}$입니다. 추가 오버헤드가 없으므로 텍스트 업데이트 관리에 매우 효율적입니다.

**검색 단계**: 각 쿼리에 대해 LLM을 호출하여 관련 키워드를 생성하고 벡터 검색을 수행합니다. GraphRAG의 커뮤니티 기반 순회와 달리 엔티티와 관계에 중점을 두어 **검색 오버헤드를 현저히 감소**시킵니다.

***

## 3. 모델 구조 및 생성 메커니즘

### 3.1 RAG 프레임워크의 형식화

LightRAG는 기본 RAG 프레임워크를 다음과 같이 정의합니다:[1]

$$M = \{G, R = (\varphi, \psi)\}$$

$$M(q; D) = G(q, \psi(q; \hat{D}))$$

$$\hat{D} = \varphi(D)$$

여기서:
- $G$: 생성 모듈 (LLM)
- $R$: 검색 모듈 (검색기와 함수로 구성)
- $\varphi$: 데이터 인덱서 (외부 데이터베이스 $D$로부터 인덱스된 데이터 $\hat{D}$ 생성)
- $\psi$: 데이터 검색기 (쿼리 $q$와 인덱스된 데이터를 비교하여 관련 정보 추출)

### 3.2 검색-증강 답변 생성

검색된 정보 $\psi(q; \hat{D})$를 활용하여 LightRAG는 다음과 같이 답변을 생성합니다:[1]

1. **정보 활용**: 관련 엔티티와 관계에서 나온 핵심-값 쌍 $V$를 연결합니다. 여기에는 엔티티 및 관계의 이름, 설명, 원본 텍스트 발췌가 포함됩니다.

2. **문맥 통합**: 쿼리와 검색된 정보를 결합하여 LLM에 입력합니다.

3. **답변 생성**: LLM이 통합된 문맥을 기반으로 사용자의 의도에 맞춘 정보 풍부한 답변을 생성합니다.

***

## 4. 성능 향상 및 실험 결과

### 4.1 성능 비교 분석

논문의 실험은 UltraDomain 벤치마크의 네 가지 데이터셋(농업, 컴퓨터 과학, 법률, 혼합)을 사용하여 평가되었으며, 각 데이터셋은 600,000~5,000,000 토큰을 포함합니다.[1]

#### 전체 성능 비교 (평균 우승률):

| 비교 대상 | 포괄성 | 다양성 | 권능성 | 전체 |
|----------|--------|--------|--------|------|
| **Naive RAG** | 63.2% | 73.0% | 63.9% | 65.9% |
| **RQ-RAG** | 63.6% | 72.4% | 63.9% | 63.5% |
| **HyDE** | 66.5% | 76.0% | 66.5% | 66.5% |
| **GraphRAG** | 51.3% | 67.5% | 52.8% | 51.5% |

LightRAG는 가장 경쟁력 있는 기준인 GraphRAG와 비교하여 특히 **다양성 측면에서 우수성을 보여줍니다**. Legal 데이터셋에서 LightRAG는 Naive RAG에 대해 83.6%의 포괄성 우승률을 기록하였습니다.[1]

### 4.2 그래프 기반 RAG의 우월성

대규모 말뭉치와 복잡한 쿼리를 다룰 때 **그래프 기반 RAG 시스템의 진정한 가치가 드러납니다**:

- **Legal 데이터셋 (5,081,069 토큰)**: 기존 청크 기반 방법들은 약 20% 우승률만 기록한 반면, LightRAG는 80% 이상의 우승률을 달성했습니다.
- **복잡한 의미 처리**: 그래프 구조가 대규모 말뭉치 내 복잡한 의미 의존성을 포착함으로써 더 나은 일반화 성능을 제공합니다.
- **다양성 증대**: 이중 검색 패러다임이 저수준(구체적 엔티티) 및 고수준(광범위한 주제) 모두에서 종합적 정보 검색을 가능하게 합니다.

### 4.3 이중 검색 패러다임의 효과 (제거 연구)

제거 연구(ablation study)를 통해 각 컴포넌트의 기여도를 분석했습니다:[1]

#### 저수준 전용 검색 (-High 변형):
- 성능 저하: 거의 모든 데이터셋과 메트릭에서 유의미한 감소
- 원인: 구체적 정보에만 과도하게 집중하여 복잡 쿼리에 대한 종합적 통찰 수집 실패

#### 고수준 전용 검색 (-Low 변형):
- 장점: 광범위한 콘텐츠 수집으로 포괄성 측면에서 상대적 이점
- 단점: 구체적 엔티티 검사의 깊이 감소로 상세한 답변 제공 능력 제약

#### 하이브리드 모드 (전체 LightRAG):
- **최적의 균형**: 저수준 검색의 깊이와 고수준 검색의 넓이를 결합하여 모든 차원에서 균형잡힌 성능 달성

#### 원본 텍스트 제거 (-Origin 변형):
놀랍게도 원본 텍스트를 제거하고 순수 그래프 구조만 사용해도 성능이 크게 저하되지 않았습니다(Agriculture, Mix 데이터셋에서 오히려 개선):

- **이유**: 그래프 기반 인덱싱 중 효과적으로 핵심 정보가 추출되므로, 원본 텍스트는 종종 노이즈를 도입합니다.
- **의의**: 의미론적 그래프가 RAG에서 원본 텍스트만큼 또는 더욱 가치 있다는 증거입니다.

### 4.4 비용 및 확장성 분석

LightRAG와 GraphRAG의 비용 비교 (Legal 데이터셋 기준):[1]

#### 검색 단계:
- **GraphRAG**: 610개 커뮤니티 보고서 × 1,000 토큰/보고서 = 610,000 토큰 + 수백 API 호출
- **LightRAG**: < 100 토큰 + 1 API 호출

#### 점진적 업데이트 (새 데이터셋 추가):
- **GraphRAG**: 기존 커뮤니티 구조 해체 후 재생성 필요 → 약 1,399 × 2 × 5,000 = 13,990,000 토큰
- **LightRAG**: 새로운 엔티티와 관계를 기존 그래프에 통합만 수행 → 훨씬 낮은 오버헤드

이는 **동적 환경에서 LightRAG의 실질적 우월성**을 명확히 보여줍니다.

***

## 5. 모델의 일반화 성능 향상

### 5.1 다양한 도메인에서의 일반화

LightRAG는 네 가지 서로 다른 도메인에서 일관되게 우수한 성능을 보여줍니다:[1]

- **농업**: 양봉, 벌 관리, 작물 생산 등 구체적 실무 지식
- **컴퓨터 과학**: 데이터 과학, 소프트웨어 공학, 기계학습, 빅데이터 처리
- **법률**: 기업 재구조화, 법적 합의, 규정 준수, 거버넌스 (가장 복잡한 도메인)
- **혼합**: 문학, 전기, 철학 등 광범위한 학문 분야

각 도메인에서 LightRAG는 **도메인 특화 구조적 특성을 학습하면서도 일관된 우수성을 유지**합니다. 특히 Legal 도메인(5백만 토큰 이상)에서의 압도적 우위는 **대규모, 복잡한 데이터에서의 강력한 일반화 능력**을 입증합니다.

### 5.2 쿼리 유형에 따른 적응성

LightRAG의 이중 검색 패러다임은 다양한 쿼리 유형에 효과적으로 대응합니다:[1]

1. **구체적 쿼리** ("Pride and Prejudice의 저자는?"):
   - 저수준 검색으로 특정 엔티티("Jane Austen") 정확히 추출

2. **추상적 쿼리** ("인공지능이 현대 교육에 미치는 영향"):
   - 고수준 검색으로 AI, 교육, 영향 등 관련 개념 간 상호작용 포착

3. **복합 쿼리** ("원주민 관점이 캐나다와 호주의 기업 인수합병에 미치는 영향?"):
   - 저수준과 고수준을 결합하여 원주민 권리, 자산 소유권, 법적 틀 등 다각적 관점 제공

### 5.3 일반화 성능의 메커니즘

LightRAG의 우수한 일반화는 다음과 같은 메커니즘에서 비롯됩니다:[1]

1. **구조화된 지식 표현**: 평면적 청크 대신 그래프 기반 표현으로 도메인 특화 구조를 포착
2. **다중 스케일 검색**: 저수준(국소) 및 고수준(전역) 정보를 동시에 고려하여 정보 손실 최소화
3. **적응적 키-값 쌍**: 엔티티별 다중 인덱스 키로 다양한 검색 의도 수용
4. **점진적 학습**: 새로운 도메인 정보 추가 시 전체 재처리 없이 신속하게 적응

***

## 6. 논문의 한계 및 고려사항

### 6.1 내재적 한계

1. **LLM 환각(Hallucination) 문제**: 그래프 구성 단계에서 LLM이 엔티티/관계를 잘못 추출할 경우, 전체 시스템 성능이 저하될 수 있습니다. 최근 연구(AGRAG, KGGen)는 통계 기반 방법이나 다중 검증으로 이를 해결하고 있습니다.[2][3]

2. **스키마 정의의 어려움**: 사전 정의된 스키마 없이 개방형 정보 추출을 수행할 때, 의미상 동일한 엔티티가 다양한 표현으로 나타날 수 있습니다. 최근 제안된 EDC(Extract-Define-Canonicalize) 프레임워크는 자동 스키마 생성과 정규화로 이 문제를 해결합니다.[4]

3. **멀티모달 미지원**: 현재 LightRAG는 텍스트 기반만 처리하며 이미지, 음성, 비디오 등 다양한 모달리티를 통합하지 못합니다.[5]

4. **추론 경로의 해석성 제한**: 복잡한 그래프 구조에서 검색된 정보와 최종 답변 간의 인과관계를 명확히 설명하기 어려울 수 있습니다. MCMI(최소 비용 최대 영향) 부분그래프 개념은 이를 개선하고 있습니다.[2]

### 6.2 평가 방법론의 제약

논문이 채택한 LLM 기반 다중차원 비교 방식은 다음과 같은 한계가 있습니다:[1]

- **객관성 문제**: GPT-4o-mini의 평가도 완벽하지 않으며, 평가 프롬프트 구성에 따라 결과가 영향을 받을 수 있습니다.
- **정답 부재**: 많은 고수준 쿼리는 명확한 정답이 없어 상대적 우월성만 측정 가능합니다.
- **순서 편향 완화의 한계**: 응답 순서를 교대로 배치했지만, 특정 응답 스타일에 대한 LLM의 선호가 완전히 제거되지 않을 수 있습니다.

***

## 7. 향후 연구에 미치는 영향과 고려사항

### 7.1 RAG 분야의 기술 트렌드

최근 RAG 관련 최신 연구들은 다음과 같은 방향으로 진화하고 있습니다:[6][7][8]

#### (1) 엔드-투-엔드 최적화 (OpenRAG, Stochastic RAG)
기존 RAG는 검색기와 생성기를 독립적으로 훈련했으나, 최신 연구는 **검색의 관련성이 RAG 맥락에서 일반 검색과 다를 수 있음**을 인식하고 문맥 내 학습을 통해 검색기를 동적으로 조정합니다.[9][10]

#### (2) 고급 RAG(Advanced RAG)
- **적응적 검색**: 모델이 언제 검색할지, 무엇을 검색할지 동적으로 결정(Self-RAG, FLARE)
- **재귀적 검색**: 검색 결과를 다시 쿼리로 사용하여 다층적 정보 발굴(IRCoT)
- **멀티모달 RAG**: 텍스트뿐 아니라 이미지, 비디오, 코드 등 다양한 모달리티 지원[5]

#### (3) 지식 그래프 기반 고급 기법
최신 연구들이 LightRAG의 그래프 아이디어를 확장하고 있습니다:[11][12]

- **SimGRAG**: 유사 부분그래프를 활용하여 지식 그래프 기반 RAG의 효율성 증대
- **K-RagRec**: 추천 시스템에서 지식 그래프 구조 정보 활용으로 평균 41.6% 성능 향상
- **AGRAG**: 통계 기반 엔티티 추출로 LLM 환각 제거 및 MCMI 부분그래프로 추론 경로 명확화[2]

#### (4) 도메인 특화 RAG 응용
최근 임상 의료, 법률, 추천 시스템 등 다양한 분야에서 RAG의 효과가 입증되고 있습니다:[13][14][15]

- **의료**: RAFT4MED 같은 프레임워크로 의료 QA에서 기존 RAG 능가
- **생명과학**: 체계적 리뷰 결과, RAG 적용 시 기본 LLM 대비 1.35배 성능 향상(95% CI: 1.19-1.53)
- **법률**: NLPALA 시스템이 Claude-3.5 Sonnet과 결합하여 응답 시간 단축

### 7.2 LightRAG가 향후 연구에 미칠 영향

#### (1) 그래프-벡터 하이브리드의 확산
LightRAG의 성공으로 **순수 벡터 검색과 그래프 구조의 결합**이 RAG의 표준 패러다임으로 자리잡을 가능성이 높습니다. 최신 K-RagRec과 AGRAG 연구가 이를 증명합니다.[12][2]

#### (2) 엔티티 추출의 신뢰성 개선
LightRAG에서 핵심인 **LLM 기반 엔티티-관계 추출**의 한계가 인식되면서, EDC와 KGGen 같은 **다단계 정규화 기법**이 활발히 개발되고 있습니다.[3][4]

#### (3) 실시간 적응형 RAG의 필수화
동적 환경에서의 효율성이 강조되면서, LightRAG의 **점진적 업데이트 개념**이 미래 시스템의 기본 요구사항으로 진화할 것으로 예상됩니다.[16]

#### (4) 복합 추론 능력 강화
AGRAG의 MCMI 부분그래프 개념처럼, **명시적 추론 경로 생성**이 더욱 주목받을 것으로 보입니다. 이는 LightRAG의 이중 검색을 한 단계 진화시킨 형태입니다.[2]

### 7.3 향후 연구자들이 고려할 핵심 사항

#### (1) 사전검색 최적화 (Pre-Retrieval Optimization)
데이터 인덱싱 품질이 전체 성능에 미치는 영향이 중요합니다:
- 텍스트 입도(granularity) 최적화
- 메타데이터 추가 및 정렬 최적화
- 혼합 검색(hybrid search) 전략 강화[5]

#### (2) 평가 방법론 개선
LLM 기반 평가의 신뢰성을 높이기 위해:
- 다중 LLM을 통한 교차 검증
- 인간 평가와의 상관성 분석
- 평가 프롬프트의 편향성 체계적 분석

#### (3) 생성 후 처리 (Post-Retrieval Processing)
검색된 정보의 품질 관리:
- 문맥의 관련성 재평가
- 정보 간 모순 감지 및 해결
- 사실성 검증 메커니즘 통합

#### (4) 멀티모달 및 구조화된 데이터 통합
- 표, 그래프, 이미지 등 다양한 데이터 형식 처리
- 서로 다른 데이터 유형 간 의미론적 연결
- 크로스모달 검색 및 검증

#### (5) 계산 효율성과 확장성
- GPU 가속화된 그래프 처리
- 대규모 그래프에서의 점진적 학습
- 엣지 기기에서의 경량 RAG 구현

***

## 8. 결론

**LightRAG**는 기존 RAG 시스템의 세 가지 근본적 문제―평면적 표현의 한계, 문맥 인식 부족, 검색 비효율성―를 **그래프 기반 구조화와 이중 검색 패러다임으로 해결하는 혁신적 접근**입니다. 광범위한 실험에서 기존 기법들(Naive RAG, RQ-RAG, HyDE, GraphRAG)을 크게 능가하며, 특히 **대규모 복잡 데이터에서의 우수한 일반화 성능**을 입증했습니다.[1]

LightRAG의 핵심 기여―**그래프 구조와 벡터 표현의 효율적 결합**, **저수준-고수준 이중 검색의 상보적 활용**, **점진적 업데이트로 인한 동적 적응성**―은 앞으로의 RAG 연구에 중요한 디자인 패러다임을 제시합니다. 최근 AGRAG, SimGRAG, K-RagRec 등 후속 연구들이 이러한 아이디어를 확장하고 있으며, 의료, 법률, 추천 시스템 등 다양한 실제 응용에서 검증되고 있습니다.[14][13][12][2]

향후 연구자들은 다음을 고려해야 합니다: (1) LLM 환각 감소를 위한 통계 기반 추출 병행, (2) 자동 스키마 생성과 정규화 기법 개발, (3) 멀티모달 데이터 통합, (4) 엔드-투-엔드 최적화를 통한 검색-생성 파이프라인 일관성 강화, (5) 대규모 그래프에서의 계산 효율성 개선. 이러한 노력들이 결합될 때, RAG 기술은 복잡하고 동적인 현실 세계의 지식 기반 시스템으로서 더욱 신뢰할 수 있고 효율적인 기술로 진화할 것입니다.

***

LightRAG 논문은 다음과 같은 기존 RAG 연구와 최신 동향을 반영합니다: Gao et al.의 초기 RAG 제안, Edge et al.의 GraphRAG, 그리고 최신 엔드-투-엔드 최적화 및 도메인 특화 응용 연구들이 LightRAG의 설계와 평가에 영향을 미쳤습니다. 특히 그래프 기반 표현과 효율적 검색의 균형을 추구하는 방향은 향후 모든 RAG 시스템 개발의 기본 원칙이 될 것으로 예상됩니다.[7][13][12][5][2][1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/216a8aa7-8292-4367-ba3b-0cfa61bdd284/2410.05779v3.pdf)
[2](https://arxiv.org/abs/2511.05549)
[3](https://openreview.net/forum?id=YyhRJXxbpi)
[4](https://www.themoonlight.io/ko/review/extract-define-canonicalize-an-llm-based-framework-for-knowledge-graph-construction)
[5](https://www.promptingguide.ai/research/rag)
[6](http://thesai.org/Publications/ViewPaper?Volume=15&Issue=3&Code=IJACSA&SerialNo=79)
[7](https://dl.acm.org/doi/10.1145/3637528.3671470)
[8](https://arxiv.org/pdf/2410.12837.pdf)
[9](https://arxiv.org/pdf/2503.08398.pdf)
[10](http://arxiv.org/pdf/2405.02816.pdf)
[11](http://arxiv.org/pdf/2412.15272.pdf)
[12](https://aclanthology.org/2025.acl-long.1317.pdf)
[13](https://academic.oup.com/jamia/article/32/4/605/7954485)
[14](https://ieeexplore.ieee.org/document/11019949/)
[15](https://pmc.ncbi.nlm.nih.gov/articles/PMC12005634/)
[16](http://arxiv.org/pdf/2502.14614.pdf)
[17](https://arxiv.org/abs/2405.06211)
[18](https://ieeexplore.ieee.org/document/11022479/)
[19](https://ieeexplore.ieee.org/document/11107459/)
[20](https://ieeexplore.ieee.org/document/11011699/)
[21](https://www.jstage.jst.go.jp/article/endocrj/advpub/0/advpub_EJ25-0201/_article)
[22](https://ieeexplore.ieee.org/document/10862926/)
[23](https://arxiv.org/pdf/2312.10997.pdf)
[24](https://arxiv.org/pdf/2405.13576.pdf)
[25](https://www.pingcap.com/article/using-llm-extract-knowledge-graph-entities-and-relationships/)
[26](https://www.aryaxai.com/article/what-is-retrieval-augmented-generation-rag-the-future-of-ai-powered-decision-making-by-aryaxai)
[27](https://www.nature.com/articles/s44401-024-00004-1)
[28](https://openreview.net/forum?id=R1NWMExESj)
[29](https://dev.to/neuml/build-knowledge-graphs-with-llm-driven-entity-extraction-4hlm)
[30](https://arxiv.org/html/2507.18910v1)
