
# Chain-of-Reasoning: Towards Unified Mathematical Reasoning in Large Language Models via a Multi-Paradigm Perspective

## 1. 핵심 주장과 주요 기여 (요약)

**Chain-of-Reasoning (CoR)**은 LLM의 수학적 추론 능력을 획기적으로 향상시키기 위해 설계된 통합 프레임워크입니다. 본 연구의 핵심 주장은 기존의 단일 패러다임 추론(Natural Language Reasoning, Algorithmic Reasoning, Symbolic Reasoning 중 하나만 사용)의 근본적인 한계를 극복하기 위해 **세 가지 추론 패러다임을 시너지 있게 통합**해야 한다는 점입니다.[1]

### 주요 기여

**CoR-Math-7B** 모델은 다음과 같은 성과를 달성했습니다:[1]

- **정리 증명(Theorem Proving)**: GPT-4o 대비 **41.0% 절대 향상**을 제시 (Lean 4 기반 miniF2F 벤치마크)
- **산술 연산(Arithmetic Tasks)**: MATH 벤치마크에서 **15% 개선** (강화학습 기반 방법 대비)
- **영점샷 일반화(Zero-shot Generalization)**: 5개 벤치마크 모두에서 SOTA 달성
- **자원 효율성**: 기존 단일 패러다임 방식 대비 더 적은 학습 데이터로 우수한 성능 구현

## 2. 문제 정의, 제안 방법, 모델 구조

### 2.1 해결하고자 하는 문제

기존 LLM 기반 수학 추론의 주요 문제점들:[1]

1. **비대칭 성능 문제**: NLR에 특화된 모델은 정리 증명에 취약하고, SR에 특화된 모델은 산술 계산에 약함
2. **단일 패러다임의 한계**: 각 추론 방식이 독립적으로 최적화되어 상호 보완의 기회를 놓침
3. **일반화 능력 부족**: 특정 작업에만 적용 가능한 모델로 인한 교차 작업 일반화 실패
4. **계산 비용 증가**: 단일 패러다임 내에서 성능 향상을 위해 광범위한 탐색 필요

### 2.2 제안하는 방법 및 수식

#### Progressive Paradigm Training (PPT) 전략

모델이 단계별로 다양한 추론 패러다임을 습득하도록 설계되었습니다:[1]

```math
L_{sample} = -\sum_{t=1}^{|z|} \log P_\theta(z_t | z_{ < t})
```

여기서:
- $\theta$: 모델 매개변수
- $z_t$: 생성 수열의 $t$번째 토큰
- $z_{<t}$: $t$번째 토큰 이전의 모든 토큰

#### Sequential Multi-Paradigm Sampling (SMPS)

트리 기반 샘플링 대신 패러다임 수준의 계층적 샘플링을 수행합니다:[1]

첫 번째 패러다임의 J개 경로 생성:
$$\tau_{1j} \sim P(\tau_{1j} | x), \quad \forall j \in \{1, ..., J\}$$

각 $\tau_1$ 경로에 대해 두 번째 패러다임의 K개 경로 생성:
$$\tau_{2k} \sim P(\tau_{2k} | x, \tau_{1j}), \quad \forall k \in \{1, ..., K\}, \forall j$$

최종 답변 생성:
$$y_{jk} \sim P(y_{jk} | x, \tau_{1j}, \tau_{2k}), \quad \forall j, k$$

이 방식으로 **J × K개의 잠재적 응답**을 생성하여 다양한 패러다임 기반 해결책을 탐색합니다.[1]

### 2.3 데이터 수집 및 처리

#### Multi-Paradigm Mathematical (MPM) 데이터셋[1]

**Stage 1: 재구성 및 확장**
- Numina-TIR (72k) 및 Lean-Workbook (223k) 기존 데이터 활용
- GPT-4o를 이용한 생성 모델: $$\tau_g \sim P_G(\tau_g | p_s \oplus x \oplus y \oplus \tau')$$
  - $p_s$: 각 데이터셋에 맞춘 프롬프트
  - $\oplus$: 연결(concatenation)
  - $\tau'$: 기존 추론 경로

**Stage 2: 검증 및 수정**
- Lean 정리 증명기를 통한 자동 검증
- 검증 실패 시 반복 수정: $$\tilde{\tau}\_{SR} \sim P_R(\tilde{\tau}\_{SR} | p_\epsilon \oplus x \oplus y \oplus \tau_{SR})$$
  - 최대 64회 반복 또는 성공 시까지

**결과**: 167,412개 다중 패러다임 추론 솔루션 (82,770개 문제)

### 2.4 모델 구조 및 PPT의 세 단계

#### 단계 ①: 자연언어 추론 (NLR)
- Numina-CoT* 데이터셋 사용
- 생성 수열: $z = [x]\tau_{NLR}y$
- LLM의 사전학습 데이터에서 이미 포함된 능력 활성화

#### 단계 ②: NLR + 알고리즘 추론 (AR)
- Numina-TIR* 데이터셋 사용
- 생성 수열: $z = [x]\tau_{NLR}\tau_{AR}y$
- 정확한 계산 능력 추가 (Python 코드 실행)
- 사전학습 데이터의 코드 코퍼스 활용

#### 단계 ③: NLR + AR + 기호 추론 (SR)
- MPM 데이터셋 사용
- 생성 수열: $z = [x]\tau_{NLR}\tau_{AR}\tau_{SR}y$
- Lean 4 정리 증명기를 통한 형식적 증명 능력 추가

각 단계에서 다음 단계를 위한 기초를 제공하는 누적적 학습 구조입니다.[1]

### 2.5 추론 시 변수 추론 깊이

프롬프트 조정을 통해 작업에 맞게 추론 깊이를 제어합니다:[1]

- **정리 증명**: NLR → SR → 최종 증명 추출
- **산술 계산**: NLR → SR (논리적 일관성) → AR (정확한 계산) → 요약

이러한 유연성으로 다양한 문제 유형에 적응 가능한 일관된 프레임워크를 제공합니다.[1]

## 3. 성능 향상 및 실험 결과

### 3.1 산술 계산 성능

| 데이터셋 | CoR-Math-7B | 기존 SOTA | 향상도 |
|---------|------------|---------|--------|
| MATH | 66.7% | 53.6% (DART-Math) | +13.1% |
| GSM8K | 88.7% | 88.2% (DeepSeekMath-RL) | +0.5% |
| AMC2023 | 34/40 (85%) | 15/40 (37.5%) | +47.5% |
| AIME2024 | 12/30 (40%) | 1/30 (3.3%) | +36.7% |

**특히 주목할 점**: CoR-Math-7B는 **1,098k개의 학습 데이터**로 Qwen2.5-Math (3,026k 데이터) 다음으로 우수한 성능을 달성하면서도 **자원 효율성이 우수**합니다.[1]

### 3.2 정리 증명 성능

miniF2F 벤치마크 (영점샷):[1]

| 모델 | 성능 | 샘플 예산 |
|-----|------|---------|
| GPT-4o | 25.0% | 128 |
| o1-mini | 13.2% | 1 |
| CoR-Math-7B | 66.0% | 128×128 |
| DeepSeek-Prover-V1.5-RL+RMaxTS | 63.5% | 32×6400 |

CoR-Math-7B가 **영점샷 상황에서 66.0%** 달성한 반면, 기존 방법들은 상당한 계산 비용을 필요로 합니다.[1]

### 3.3 Pareto 효율성 분석

Figure 1(b)에 표시된 것처럼, CoR-Math-7B는 **효율 최적선(Efficiency Zone)을 벗어나** 기존 단일 패러다임 방식의 최적 성능 곡선을 초과합니다.[1]

## 4. 모델 일반화 성능 강화

### 4.1 영점샷 일반화 달성 메커니즘

CoR-Math-7B가 영점샷 성능을 달성한 이유:[1]

1. **다중 패러다임 학습의 상호 보강**: 
   - NLR은 문제 분해를 위한 기초 제공
   - SR은 논리적 구조화를 통해 NLR 개선
   - AR은 수치 계산의 정확성 보장

2. **패러다임 간 자가 수정 (Cross-paradigm Self-correction)**:
   - AR이 NLR의 계산 오류 수정
   - SR이 NLR의 불완전한 논리 단계 보완
   - 오류 분석 결과, 200개 오류 중 85개가 AR/SR에서 자가 수정됨[1]

### 4.2 다양한 모델 크기에서의 일반화

표 6의 결과로 볼 때 CoR이 **모델 크기별로 확장 가능(scalable)**함을 보여줍니다:[1]

| 모델 크기 | MATH (CoT vs CoR) | GSM8k (CoT vs CoR) |
|----------|------------------|-------------------|
| 1.5B | 34.0% → 57.6% | 39.3% → 84.5% |
| 7B | 51.8% → 64.7% | 90.0% → 90.0% |
| 8B | 4.2% → 58.2% | 6.2% → 84.0% |
| 70B | 16.8% → 70.7% | 20.5% → 90.0% |

**일반화 패턴**: 더 큰 모델일수록 CoR의 이점이 더욱 두드러지며, 작은 모델도 상당한 성능 향상을 보임.

### 4.3 추론 경로 순서의 영향

표 4의 분석이 흥미로운 발견을 제시합니다:[1]

| 추론 순서 | MATH | GSM8K |
|----------|------|-------|
| NLR→AR→SR | 49.9% | 84.2% |
| NLR→SR→AR | 66.7% | 88.7% |

**NLR→SR→AR 순서가 최적**인 이유: SR이 문제를 관리 가능한 부분 단계로 분해하고, AR이 최종 계산 실행을 담당함으로써 구조화된 기초를 제공합니다.[1]

## 5. 한계 및 제약사항

### 5.1 기술적 한계

1. **패러다임 간 능력 불균형**:[1]
   - 사전학습 데이터에서 NLR이 지배적 → SR 능력 격차 지속
   - 오류 분석: 200개 오류 중 33개 이해 오류, 56개 계산 오류, 85개 증명/문법 오류

2. **고정 컨텍스트 윈도우**:[1]
   - 긴 추론 체인 자르기 가능성
   - 핵심 단계 누락으로 불완전한 출력 발생

3. **데이터 누수 리스크**:[1]
   - Levenshtein 거리 기준 0.7 이상 유사도 제거 필요
   - 약 1,000개 케이스(0.6% 미만) 제거

### 5.2 평가 시 제약사항

1. **영점샷 성능 평가의 이질성**:[1]
   - 대부분의 기존 방법이 few-shot 설정에 최적화
   - 공정한 비교를 위해 부록 C.2에서 추가 검증 전략 제시

2. **계산 비용 고려**:[1]
   - MATH와 같은 대규모 산술 작업에서 SMPS 적용 제한
   - 다른 방법과의 공정한 비교를 위한 제약

### 5.3 윤리적 고려사항[1]

- AR 패러다임의 Python 코드 실행 관련 보안 리스크
- 기저 모델에 내재된 편향성 (예: Llama의 성별 편향)
- 배포 전 도구 감시 및 윤리적 정렬 필요

## 6. 일반화 성능 향상의 핵심 메커니즘

### 6.1 해석적 계층 구조

논문이 정의한 추론의 세 계층 구조:[1]

- **추론 단계 (Reasoning Steps)**: 토큰 또는 그룹, 불완전한 해결 과정
- **추론 경로 (Reasoning Paths)**: 여러 단계의 완전한 추론 라인, 최종 답변 포함
- **추론 패러다임 (Reasoning Paradigms)**: 단일 지식 매체(NL/코드/기호) 사용, 여러 경로 포함

기존 방법들은 단일 패러다임 내에서 깊이(단계) 또는 폭(경로)만 최적화하지만, CoR은 **패러다임 수준의 새로운 차원을 추가**합니다.[1]

### 6.2 순차적 추론 종속성 (Sequential Reasoning Dependency)

각 패러다임의 출력이 다음 패러다임의 입력으로만 아니라 **기초 정보(foundational information)**로 기능합니다:[1]

예) 자연언어 패러다임에서 도출된 지식이 후속 알고리즘 패러다임의 코드 생성을 효율성 있게 가이드 → 이는 **사전 리허설 메커니즘**처럼 작동

### 6.3 해결 공간 확장

다중 패러다임 추론이 **orthogonal relationship**을 고려하여 해결 공간을 확장합니다:[1]

- 단일 패러다임: 해결 공간은 제한된 지식 표현만 탐색
- 다중 패러다임: 다양한 지식 매체를 통한 보완적 탐색
- **intra-paradigm 및 inter-paradigm 검색 능력 모두 향상**

## 7. 앞으로의 연구 방향과 영향

### 7.1 논문이 미치는 영향

#### 학계에 대한 영향

1. **새로운 테스트 타임 스케일링 패러다임**[1]
   - 기존: 단일 패러다임 내 경로 수 증가 (예: DeepSeek-Prover는 32×6400=204,800개 경로)
   - 제안: 패러다임 수준의 확장 (예: 128×128=16,384개로 효율성 우수)

2. **일반화 가능한 통합 모델의 가능성**
   - 최신 연구 (2025년 기준)는 다중 모달 및 다중 작업 학습 방향 추구[2]
   - CoR의 multi-paradigm 접근은 이들 방향과 자연스럽게 결합 가능

3. **신경-기호 AI 통합의 실제 사례**[3][4]
   - 기존 신경-기호 AI는 이론적으로 제안되었으나, CoR은 **실제로 검증 가능한 구현**
   - Lean 4 정리 증명기 통합으로 형식 검증 가능

#### 산업 적용 가능성

1. **자동화된 정리 증명**
   - 현재 전문 도메인(수학 올림피아드 수준) → CoR로 실용 영역 확대 가능

2. **교육 보조 시스템**
   - 다중 추론 방식을 보여줌으로써 학생들이 문제 해결의 다양한 경로 이해

3. **자동 소프트웨어 검증**
   - SR 패러다임을 통해 형식 검증과 NLR/AR을 결합한 종단간 검증 시스템

### 7.2 향후 연구 시 고려할 점

#### 기술적 개선 방향

1. **컨텍스트 윈도우 확장**[1]
   - 현재: Stage ①,② 2,048 토큰 → Stage ③ 4,096 토큰
   - 향후: 더 복잡한 증명을 위해 추가 확장 필요

2. **패러다임 확장**
   - 논문은 3가지 패러다임만 다루었으나, **그래프 기반 추론**, **시각적 추론** 등 추가 패러다임 통합 가능[5][6]

3. **동적 패러다임 선택**[1]
   - 현재: 프롬프트 기반 고정 순서
   - 향후: 문제 특성을 분석하여 최적 패러다임 순서를 동적으로 결정

#### 일반화 강화 방안

1. **도메인 외 평가**
   - 현재: 수학 문제에만 특화
   - 향후: 논리 퍼즐, 코딩, 과학 추론 등 다양한 도메인 테스트 필요[2]

2. **분포 외 일반화 (Out-of-Distribution Generalization)**[7]
   - 최신 신경망 일반화 연구는 domain generalization과 distribution generalization 강조
   - CoR에 이러한 기법 적용 고려

3. **샘플 효율성 개선**[1]
   - 현재 Qwen2.5-Math (3,026k) 대비 적은 데이터 사용하나, 추가 개선의 여지 있음
   - Few-shot compositional learning 기법 통합 고려[8]

#### 평가 및 검증 방법 개선

1. **정보 이론 기반 평가**[9]
   - 최근 연구가 information gain을 통한 중간 단계 평가 제안
   - 이를 CoR 평가에 적용하여 각 패러다임의 기여도 정량화 가능

2. **비용-효율성 분석의 정교화**
   - 계산 비용(computation cost)뿐 아니라 메모리 효율성, 에너지 소비 고려
   - Pareto frontier 분석 심화

3. **장시간 추론 생성의 신뢰성**[5]
   - 최근 o1/o3 같은 대규모 추론 모델은 매우 긴 CoT 생성
   - CoR도 이런 장시간 추론 상황에서 성능 분석 필요

#### 윤리 및 해석성

1. **설명 가능성 강화**[4][3]
   - 다중 패러다임으로 인한 복잡성 → 사용자 입장에서 어떤 패러다임이 최종 결정에 기여했는지 이해 필요

2. **기호적 투명성**
   - SR 패러다임은 형식 검증 가능하나, 전체 시스템의 투명성은 여전히 과제

3. **공정성과 편향성**
   - Multi-paradigm에서 기저 모델의 편향이 패러다임마다 다르게 표현될 수 있음

### 7.3 관련 최신 연구 트렌드

#### 신경-기호 AI의 진화 (2024-2025)
최신 연구는 신경망과 기호 추론의 통합을 다양한 방식으로 시도 중입니다:[3][4]

- **Nested Approaches**: 기호 해결기가 심층학습 활용
- **Cooperative Approaches**: 신경 vs 기호 컴포넌트가 협력하여 결정
- **Compiled Approaches**: 기호 논리를 신경망 학습 데이터에 통합
- **Tightly Coupled Systems**: 신경 및 기호 컴포넌트를 긴밀히 통합

CoR은 **Cooperative Approaches**의 진화형으로 볼 수 있으며, 추후 **Tightly Coupled** 방향으로 진화 가능합니다.

#### 추론 스케일링의 새로운 관점 (2025)
최신 연구는 단순히 CoT 길이를 늘리는 것의 한계를 지적합니다:[5]

- 많은 긴 CoT는 중복 및 과잉 분석 포함
- 효율적인 추론을 위해 **신뢰할 수 있는 장시간 CoT 생성** 기술 필요
- CoR의 패러다임 수준 스케일링은 이에 대한 **대안적 접근**

#### 생성 모델의 일반화 능력[7][8][2]
2024-2025 연구 동향:

- **Compositional generalization**: 새로운 조합의 성분도 이해하는 능력[8]
- **Task generalization through meta-learning**: 적은 샘플로 새 작업 학습
- **Modality generalization**: 한 모달리티에서 학습한 패턴을 다른 모달리티에 적용

CoR의 다중 패러다임 학습은 이러한 일반화 형식들과 상호 보완적입니다.

***

## 결론

**Chain-of-Reasoning**은 LLM 기반 수학 추론의 패러다임 전환을 제시합니다. 기존의 개별 최적화된 단일 패러다임 방식에서 벗어나 세 가지 추론 방식의 시너지를 통해 **일반화 가능하고 효율적인 통합 모델**을 구현했습니다.[1]

특히 다음 세 가지 측면에서 의의가 있습니다:

1. **테스트 타임 스케일링의 새로운 차원**: 경로 수 증가 대신 패러다임 수준의 확장으로 효율성 달성
2. **형식 검증 가능한 신경-기호 통합**: Lean 4와의 통합으로 증명 가능성 보장
3. **영점샷 일반화의 실제 달성**: 5개 벤치마크에서 검증된 강력한 cross-task 능력

앞으로의 연구는 이러한 기초 위에서 **(1) 더 많은 패러다임 통합, (2) 동적 패러다임 선택 메커니즘, (3) 도메인 외 일반화 강화** 등의 방향으로 진화할 것으로 예상됩니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/bb5d04f8-2323-4962-9bbd-9f152b6ae780/2501.11110v4.pdf)
[2](https://arxiv.org/pdf/2502.03671.pdf)
[3](https://arxiv.org/html/2510.21425v1)
[4](https://journalwjarr.com/sites/default/files/fulltext_pdf/WJARR-2025-0287.pdf)
[5](https://arxiv.org/html/2503.21614)
[6](https://aclanthology.org/2023.emnlp-main.169.pdf)
[7](https://arxiv.org/html/2209.01610v3)
[8](https://www.nature.com/articles/s41586-023-06668-3)
[9](https://openreview.net/forum?id=IjOWms0hrf)
[10](https://arxiv.org/pdf/2410.10336.pdf)
[11](http://arxiv.org/pdf/2410.19817.pdf)
[12](https://arxiv.org/pdf/2312.08901.pdf)
[13](https://arxiv.org/html/2403.14312)
[14](http://arxiv.org/pdf/2502.11169.pdf)
[15](https://futureagi.com/blogs/chain-of-thought-prompting-ai-2025)
[16](https://www.sciencedirect.com/science/article/abs/pii/S1566253525006578)
[17](https://openreview.net/forum?id=gwRwHUZUgz)
[18](https://kili-technology.com/blog/llm-reasoning-guide)
[19](https://www.reddit.com/r/LocalLLaMA/comments/1mkza1b/new_paper_reveals_chainofthought_reasoning_of/)
