# iWAX: interpretable Wav2vec-AASIST-XGBoost framework for voice spoofing detection

### 1. 핵심 주장 및 주요 기여[1]

iWAX는 **음성 스푸핑 탐지에서 딥러닝 모델의 해석 불가능성 문제를 해결**하는 것을 핵심 목표로 한다. 논문이 제시하는 세 가지 주요 연구 질문과 이에 대한 답변은 다음과 같다:[1]

**1) 사전학습된 대규모 음성 모델의 표현력을 활용하면서 성능을 향상시키는 해석 가능한 모델을 구축하는 방법**

**2) 음성 스푸핑 탐지 과정에서 모델이 주목하는 구체적 영역 식별 방법**

**3) 빈도 영역(frequency domain)에서 XGBoost의 특성 중요도(feature importance) 메커니즘을 통한 대규모 딥러닝 기반 대책의 내부 표현 해석 방법**

iWAX의 주요 기여는 **Wav2Vec 2.0, AASIST, XGBoost를 통합하여 시간 영역 및 주파수 영역의 이중 분석을 제공**함으로써 해석 가능성과 성능을 동시에 달성하는 것이다. 이는 기존의 순전히 딥러닝 기반 방법(높은 성능이지만 해석 불가능)과 전통적 머신러닝 방법(해석 가능하지만 성능 제한)의 한계를 극복한다.

### 2. 문제 정의 및 제안 방법

#### 2.1 해결 대상 문제

기존 음성 스푸핑 탐지 연구는 다음과 같은 한계를 지닌다:[1]

- **해석 가능성 부족**: Wav2Vec 2.0 등의 사전학습 대규모 모델은 수십억 개의 파라미터로 인해 의사결정 과정을 이해하기 어려움
- **음성 신호의 특수성 간과**: 컴퓨터 비전의 Grad-CAM과 같은 기법을 음성에 적용하면, 모델이 강조하는 특정 음성 구간이 인간의 직관과 연결되지 않음
- **주파수 분석의 부재**: 음성 스푸핑 탐지에 중요한 주파수 대역별 분석이 부족

#### 2.2 제안 방법론

iWAX는 **계층화된 아키텍처**를 제안한다:

**(1) 특성 추출 단계**: Wav2Vec 2.0 (XLS-R 1B) + AASIST

XLS-R(1B)은 48개의 Transformer 레이어와 약 965백만 개의 파라미터로 구성되어 있으나, 논문에서는 처음 12개 레이어만을 사용한다. 이 중:[1]
- 처음 9개 레이어는 **고정(frozen)** → 사전학습된 일반 음성 표현 유지
- 뒤의 3개 레이어는 **미세조정(fine-tuning)** → 음성 스푸핑 탐지 특화

결과적으로 Wav2Vec 2.0의 마지막 Transformer 레이어 출력은 다음 형태:

$$R^{T \times F}$$

여기서 $T$는 시간 차원, $F$는 특성 차원을 나타낸다.[1]

**AASIST (Audio Anti-Spoofing using Integrated Spectro-Temporal Graph Attention Networks)**는 원시 파형을 입력받아 시간-주파수 그래프 주의 메커니즘을 통해 판별적 특성을 학습한다.[1]

**Sinc 필터를 이용한 주파수 분석**[1]

원시 파형으로부터 특정 주파수 대역을 분리하기 위해 Sinc 필터를 사용한다:

$$h(n) = 2f_2 \text{sinc}(2\pi f_2 n) - 2f_1 \text{sinc}(2\pi f_1 n)$$

여기서:
- $f_1, f_2$: 저주파 및 고주파 차단 주파수
- $\text{sinc}(x) = \frac{\sin(x)}{x}$
- 커널 크기 = 513 (즉, $n \in [-256, 256]$)
- 나이퀴스트-섀넌 표본화 정리에 따라 차단 주파수 ≤ 8,000 Hz (16,000 Hz 표본화율 기준)
- 주파수 대역은 로그 스케일로 선택 (음역의 인지 스케일과 일치)

**(2) 시간 영역 분석**[1]

두 단계 과정으로 구성:

**Step 1. 특성 선택**: Wav2Vec 2.0 출력에서 세 개의 중간 행 벡터를 선택

$$\text{Time points: } T = \frac{1}{4}, \frac{2}{4}, \frac{3}{4}$$

(음성 시작과 끝의 침묵 구간 피함)

이들 벡터를 첫 번째 XGBoost 모델의 입력으로 사용하여 가장 빈번하게 선택되는 상위 3개 특성(feature) 식별

**Step 2. 시간 중요도 추출**: 식별된 상위 3개 특성에 대응하는 열 벡터를 추출

$$\text{Shape: } R^{T \times 1}$$

이들 시간 궤적을 두 번째 XGBoost 모델의 입력으로 사용하여 분류 결정에 가장 중요한 시간 구간 식별

**XGBoost의 특성 중요도 메커니즘**[1]

XGBoost는 F-점수(F-score)를 사용하여 특성 중요도를 정량화한다:

$$F\text{-score} = \text{(부스팅 라운드 전체에서 특성이 분할에 사용된 빈도)}$$

이는 각 입력 변수의 상대적 기여도를 반영하며, 모델의 예측 수정 성능을 개선한다.[1]

**정규화 및 과적합 억제**[1]

XGBoost는 L1 및 L2 정규화 항을 포함하여 모델 복잡도를 제어한다:

$$\text{Objective} = \sum_i l(y_i, \hat{y}_i) + \sum_k \Omega(f_k)$$

여기서 $\Omega(f_k) = \gamma T + \frac{1}{2}\lambda w^2$ (정규화 항, $T$는 잎 노드 수, $w$는 가중치)

### 3. 실험 결과 및 성능 향상

#### 3.1 실험 설정

**데이터셋**: ASVspoof 2019 Logical Access (LA) 데이터셋[1]

| 구성 | 스푸핑 샘플 | 진정 샘플 |
|------|-----------|---------|
| 학습 | 22,800 | 2,580 |
| 개발 | 22,296 | 2,548 |
| 평가 | 63,882 | 7,355 |

- 각 음성 샘플 길이: 약 4초
- 표본화율: 16,000 Hz

#### 3.2 성능 비교[1]

| 모델 | 시간점 | Dev EER (%) | Eval EER (%) |
|------|--------|-----------|------------|
| **iWAX (XGBoost)** | 1/4 | 0.2561±0.0170 | 0.3162±0.0128 |
| | 2/4 | **0.2560±0.0151** | **0.3136±0.0190** |
| | 3/4 | 0.2516±0.0374 | 0.3141±0.0228 |
| Kang et al. (w2v2-AASIST) | N/A | 0.1900±0.0000 | 0.3975±0.0000 |
| AASIST | N/A | N/A | 0.83 |
| Li et al. (Temporal CAR) | N/A | N/A | 0.51 |

**주목할 점**: 
- iWAX는 개발 세트에서 약간의 성능 손실이 있으나, **평가 세트에서 더 나은 일반화 능력** 보여줌[1]
- Wilcoxon 순위합 검정 (Bonferroni 보정, p < 0.05)에서 유의미한 개선 확인

#### 3.3 주파수 대역별 분석[1]

| 주파수 범위 (Hz) | Dev EER (%) | Eval EER (%) | 상위 특성 |
|---------------|-----------|------------|---------|
| 0–64 | 11.4973 | 18.4083 | N/A |
| 0–128 | 5.9345 | 13.9095 | N/A |
| 64–2048 | 0.6347 | **0.5589** | f85, f1000, f1001 |
| **128–8000** | **0.2742** | **0.2883** | f85, f1001, f1000 |
| 256–8000 | 2.9406 | 3.9869 | N/A |

**결론**: 모델은 **128–8000 Hz 범위에 집중**하며, 0–128 Hz 저주파 대역은 스푸핑 탐지에 덜 정보적

#### 3.4 시간 영역 중요도 분석[1]

세 가지 핵심 특성 (f85, f1000, f1001)에 대한 시간적 기여도:

| 특성 | Dev EER (%) | Eval EER (%) | 순위 |
|------|-----------|------------|------|
| f1000 | 0.2176±0.0245 | **0.3612±0.0212** | 1위 |
| f1001 | 0.2742±0.0278 | 0.6388±0.0347 | 2위 |
| f85 | 0.5602±0.0468 | 2.0992±0.0304 | 3위 |

모델은 **음성 샘플의 시작과 중간 부분**에 주로 주의를 집중한다.

#### 3.5 LightGBM 기반 검증 (절제 연구)[1]

| 모델 | 시간점 | Dev EER (%) | Eval EER (%) |
|------|--------|-----------|------------|
| **LightGBM** | 1/4 | 0.2477±0.0168 | 0.3032±0.0259 |
| | 2/4 | 0.2386±0.0192 | **0.2755±0.0242** |
| | 3/4 | 0.2516±0.0200 | 0.2793±0.0077 |

LightGBM이 XGBoost보다 약간 우수한 성능을 보임 (t-검정, 유의미)

### 4. 모델 일반화 성능 향상 분석

#### 4.1 일반화 성능 증진 메커니즘[1]

**1) 부분 미세조정 전략**

이 논문은 XLS-R의 첫 9개 레이어를 동결하고 뒤의 3개 레이어만 미세조정하는 방식이 중요함을 강조한다. 이는:[1]
- 사전학습된 일반 음성 표현의 강점 유지
- 과적합 위험 감소
- 도메인 간 전이학습 효율성 증가

**2) 주파수 대역 기반 설계**

128–8000 Hz 범위에 집중하는 방식은:
- 저주파(0–128 Hz)의 노이즈 같은 특성 자동 무시
- 더 안정적인 성능 제공
- 잠재적 신호 열화 하에서 견고성 향상[1]

**3) 안정적 특성 선택**

상위 3개 특성(f1000, f1001, f85)이 모든 시간점에서 일관되게 우수한 성능을 보이는 것은:
- 모델이 인스턴스별 아티팩트보다는 **강건한 신호**에 의존
- 데이터셋 전체의 반복되는 신호 단서 활용

#### 4.2 평가 세트에서의 우수한 일반화[1]

개발 세트 대비 평가 세트에서 Kang et al. 방법은 0.19% → 0.3975% EER로 성능 저하를 보인 반면, iWAX는 0.256% → 0.3136% EER로 보다 **균형잡힌 성능** 유지:

$$\text{성능 저하율} = \frac{\text{Eval EER} - \text{Dev EER}}{\text{Dev EER}} \times 100\%$$

- Kang et al.: 약 109% 저하
- iWAX: 약 22% 저하

이는 **과적합 억제 및 일반화 능력 향상**을 의미한다.

#### 4.3 크로스 데이터셋 평가의 필요성 및 한계

논문이 직접 다루지는 않지만, 최근 연구 동향에 따르면:[2][3][4]

- **크로스 데이터셋 평가의 심각한 성능 저하**: ASVspoof 2019에서 우수한 모델도 ASVspoof 2021이나 WaveFake 데이터셋에서 큰 성능 저하
- **합성 음성 생성 기술의 발전**: Zero-shot TTS 모델 등장으로 새로운 도메인의 스푸핑 음성 생성 용이
- **다중 도메인 평가의 중요성**: 단일 데이터셋 성능만으로는 실제 배포 시나리오의 견고성 보장 불가

### 5. 논문의 주요 한계

#### 5.1 명시된 한계

논문의 Discussion과 결론 섹션에서 제시된 한계:[1]

1. **인스턴스별 해석 부재**: XGBoost의 특성 중요도는 **전역적(global) 경향**만 포착하며, 개별 입력 예시(instance-specific)에 대한 분석은 제한적
   - 향후 개선 방향: TabNet, SHAP 등의 인스턴스별 해석 방법 활용

2. **단일 데이터셋 평가**: ASVspoof 2019 LA 데이터셋만 사용
   - 향후 필요: ASVspoof 2021, WaveFake 등 다중 데이터셋 평가

3. **수동 정의 주파수 대역**: Sinc 필터 주파수 대역을 수동으로 설정
   - 향후 개선: 학습 가능한 필터뱅크 최적화

4. **선형 분석 방법**: 다중 특성 조합의 개별 및 결합 기여도 분석 부족

5. **계산 부담**: 약 965백만 파라미터의 모델 미세조정 필요
   - 향후 개선: LoRA(Low-Rank Adaptation) 등 파라미터 효율적 미세조정 방법

#### 5.2 암시된 한계

1. **음성 신호의 다양한 왜곡에 대한 견고성 미검증**: 
   - 노이즈, 코덱 압축, 음향 환경 변화 등에 대한 평가 부재
   - 현재는 "clean" 조건의 평가만 제시

2. **도메인 간 일반화 능력 미검증**:
   - 학습 데이터와 상이한 스푸핑 공격 유형에 대한 평가 부재

3. **음성 특성의 개인차 고려 부족**:
   - 화자별, 언어별 특성 편차에 대한 분석 미제시

### 6. 최신 연구 기반의 영향 및 고려사항

#### 6.1 이 논문이 앞으로의 연구에 미치는 영향

**긍정적 영향:**[3][2][1]

1. **해석 가능성 패러다임 전환**
   - 딥러닝의 성능과 해석 가능성의 상충 관계 완화
   - XGBoost 같은 전통 머신러닝의 새로운 활용처 제시

2. **모달리티 특화 해석 방법론 제시**
   - 음성 신호 특화 해석 기법 개발의 기초 제공
   - 컴퓨터 비전 기법의 무분별한 적용 대신 음성 도메인 특화 방법 강조

3. **주파수 대역 기반 분석의 재조명**
   - 스푸핑 탐지에서 특정 주파수 대역의 중요성 재강조
   - 데이터 증강 및 모델 설계의 실증적 근거 제공

**부정적/제한적 측면:**

1. **크로스 도메인 일반화 문제 미해결**[4][2][3]
   - 동일 데이터셋 내에서만 우수한 성능
   - 실제 배포 환경의 미래 공격 유형에 대한 견고성 미검증

2. **계산 복잡도**[1]
   - 대규모 모델 (965억 파라미터) 미세조정 필요
   - 경량 모델 개발 동향과의 불일치

#### 6.2 앞으로의 연구에서 고려할 점

**1. 다중 도메인 평가 필수화**[5][6][2][3][4]

최근 연구는 **크로스 데이터셋 평가의 중대한 성능 저하**를 강조한다:[6][5]
- Zero-shot TTS (Seamless Expressive, GPT-SoVITS 등)로 생성된 음성에 대한 일반화 능력 평가 필수
- 다양한 음성 합성 방식(음성 변환, 음성 복제 등) 포함 평가
- "Bona fide cross-testing" 같은 새로운 평가 프레임워크 활용[6]

**2. 노이즈 견고성 강화**[7][8]

실제 배포 환경의 음향 조건을 반영:
- 배경 노이즈, 코덱 왜곡, 음향 환경 변화 시뮬레이션
- Frequency Feature Masking (FFM) 같은 데이터 증강 기법 통합[7]

**3. 인스턴스별 해석의 심화**[9][2]

개별 입력에 대한 의사결정 과정 규명:
- SHAP 값을 통한 특성별 기여도 정량화[2]
- Shapley 값 기반 확률론적 속성 임베딩 활용[9]

**4. 모달리티 확장 (Audio-Visual)**[1]

음성만이 아닌 시각 정보 결합:
- 음성과 영상 정보의 특성 중요도 통합 분석
- 멀티모달 해석 가능성 프레임워크 개발

**5. 경량화 및 효율성 개선**[10][1]

실시간 배포 가능성:
- LoRA, Adapter 등 파라미터 효율적 미세조정
- 엣지 디바이스 배포 가능 모델 설계
- TabNet, FT-Transformer 같은 경량 테이블러 딥러닝 아키텍처 탐구

**6. 다언어 및 다국가 데이터셋 필요성**[11]

현재 음성 스푸핑 데이터셋이 영어와 중국어에 편중:[11]
- MLAAD (Multi-Language Audio Anti-Spoofing Dataset) 같은 다언어 데이터셋 개발 촉진
- 언어별 음향적 특성 차이를 고려한 모델 설계

**7. 적대적 공격 및 안티 포렌식 대비**[3]

악의적 공격자의 진화 대응:
- 모델 자체를 표적으로 하는 적대적 예시(adversarial examples) 견고성 평가
- 안티-포렌식 기법(counter-forensics)으로 인한 성능 저하 분석

### 요약

**iWAX의 핵심 기여:**
Wav2Vec 2.0의 강력한 특성 추출 능력과 XGBoost의 해석 가능성을 결합하여, 음성 스푸핑 탐지에서 **성능(0.3136% EER)과 해석 가능성의 균형**을 달성했다. 특히 **시간 영역 및 주파수 대역 이중 분석**을 통해 모델이 주목하는 구체적 신호 특성을 규명하는 점이 혁신적이다.

**장점:**
- 해석 가능성과 성능의 상충 극복
- 음성 신호 특화 해석 방법론 제시
- 안정적 특성 선택으로 강건성 보증

**제한:**
- 단일 데이터셋 평가로 인한 일반화 능력 미검증
- 인스턴스별 해석 부재
- 향후 공격 유형(Zero-shot TTS 등)에 대한 대응 미흡

**향후 연구의 우선순위:**
1. 다중 도메인 (ASVspoof 2021, WaveFake, CD-ADD)에서의 성능 평가
2. 노이즈 및 현실 조건 견고성 강화  
3. SHAP, TabNet 등을 통한 인스턴스별 해석 심화
4. 다언어 데이터셋 및 멀티모달 접근법 개발

***

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/6c3f81ab-60ab-43d5-9a14-60eb00228046/iWAX-interpretable-Wav2vec-AASIST-XGBoost-framework-for-voice-spoofing-detection.pdf)
[2](http://arxiv.org/pdf/2406.08825.pdf)
[3](https://arxiv.org/pdf/2307.06669.pdf)
[4](https://arxiv.org/html/2509.00186v1)
[5](https://aclanthology.org/2024.emnlp-main.286.pdf)
[6](https://www.isca-archive.org/interspeech_2025/kwok25_interspeech.pdf)
[7](https://scholarworks.bwise.kr/cau/bitstream/2019.sw.cau/83524/1/Enhancingvoicespoofingdetectioninnoisyenvironmentsusingfrequencyfeaturemaskingaugmentation.pdf)
[8](https://etasr.com/index.php/ETASR/article/view/13400)
[9](https://arxiv.org/html/2502.04049v2)
[10](https://www.isca-archive.org/asvspoof_2024/kulkarni24_asvspoof.pdf)
[11](https://arxiv.org/pdf/2401.09512.pdf)
[12](http://arxiv.org/pdf/2308.11800.pdf)
[13](https://arxiv.org/pdf/2210.00417.pdf)
[14](http://arxiv.org/pdf/2305.19051.pdf)
[15](https://arxiv.org/pdf/2310.03856.pdf)
[16](https://arxiv.org/pdf/2402.18085.pdf)
[17](https://ceur-ws.org/Vol-4017/paper_13.pdf)
[18](https://www.isca-archive.org/interspeech_2016/korshunov16_interspeech.pdf)
[19](https://infoscience.epfl.ch/server/api/core/bitstreams/036a5e1c-ba4d-4256-9f3e-d76133a7307d/content)
