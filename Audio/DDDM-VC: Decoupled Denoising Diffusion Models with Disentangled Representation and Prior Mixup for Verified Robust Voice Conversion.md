
# DDDM-VC: Decoupled Denoising Diffusion Models with Disentangled Representation and Prior Mixup for Verified Robust Voice Conversion

## 1. í•µì‹¬ ì£¼ì¥ ë° ê¸°ì—¬ ìš”ì•½

### 1.1 ì£¼ìš” ë¬¸ì œì 
ê¸°ì¡´ diffusion ëª¨ë¸ë“¤ì€ ê°•ë ¥í•œ ìƒì„± ì„±ëŠ¥ì„ ë³´ì´ë‚˜, ë‹¤ìŒì˜ ê·¼ë³¸ì  í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤:

- **ë‹¨ì¼ Denoiserì˜ í•œê³„**: ëª¨ë“  ìƒì„± ë‹¨ê³„ì—ì„œ ë‹¨ì¼ ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ ê³µìœ í•˜ì—¬ íŠ¹ì • ì†ì„±ì— ëŒ€í•œ ì„¸ë°€í•œ ì œì–´ ë¶ˆê°€ëŠ¥
- **ìŒì„± ì†ì„±ì˜ ë³µì¡ì„±**: ìŒì„±ì€ ìŒì„±í•™ì  ì •ë³´(linguistic content), ì¸í† ë„¤ì´ì…˜(F0), ìŒìƒ‰(timbre) ë“± ì—¬ëŸ¬ ë…ë¦½ ì†ì„±ì„ ë™ì‹œ í¬í•¨
- **ìŒì„± ë³€í™˜ì˜ ë„ì „**: ì†ì„± ê°„ ë³µì¡í•œ ìƒí˜¸ì‘ìš©ìœ¼ë¡œ ê° ì†ì„±ë³„ ë…ë¦½ ì œì–´ì™€ ê³ í’ˆì§ˆ í•©ì„± ë™ì‹œ ë‹¬ì„± ì–´ë ¤ì›€

### 1.2 í•µì‹¬ ê¸°ì—¬ (3ê°€ì§€)

1. **DDDM (Decoupled Denoising Diffusion Models)**: ì†ì„±ë³„ë¡œ ì „ë¬¸í™”ëœ ë‹¤ì¤‘ denoiserë¥¼ ì„¤ê³„í•˜ì—¬ ê° ì†ì„±ì—ì„œì˜ ë…¸ì´ì¦ˆ ì œê±°ë¥¼ ë…ë¦½ì ìœ¼ë¡œ ìˆ˜í–‰í•˜ëŠ” í˜ì‹ ì  êµ¬ì¡°

2. **DDDM-VC**: ìê¸°ì§€ë„í•™ìŠµ(self-supervised) í‘œí˜„ ê¸°ë°˜ ìŒì„± ë¶„ë¦¬ + Source-Filter ì´ë¡  ê¸°ë°˜ ê³ í’ˆì§ˆ ìŒì„± ì¬í•©ì„± ì‹œìŠ¤í…œ

3. **Prior Mixup**: í•™ìŠµ-ì¶”ë¡  ë¶ˆì¼ì¹˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ìƒˆë¡œìš´ í•™ìŠµ ì‹œë‚˜ë¦¬ì˜¤ë¡œ, ë³€í™˜ëœ ìŒì„± í‘œí˜„ì„ ì‚¬ì „ë¶„í¬ë¡œ í™œìš©í•˜ì—¬ ê°•ê±´í•œ ìŒì„± ë³€í™˜ ì„±ëŠ¥ ë‹¬ì„±

***

## 2. ë¬¸ì œ ì •ì˜ ë° ê¸°ìˆ ì  ë„ì „ê³¼ì œ

### 2.1 ìŒì„± ë³€í™˜ì˜ ê³¼í•™ì  ë³µì¡ì„±

ìŒì„± ì‹ í˜¸ëŠ” ë‹¤ìŒ ì†ì„±ë“¤ì˜ ë³µí•©ì²´:

$$\text{Speech} = f(\text{Content}, \text{Pitch}, \text{Timbre}, \text{Speaker})$$

ê° ì†ì„±ì€ ë‹¤ì–‘í•œ ìˆ˜ì¤€ì—ì„œ ìƒí˜¸ì‘ìš©í•˜ë©°, ìŒì„±í•™ ì •ë³´(phonetics)ëŠ” ìœ ì§€í•˜ë©´ì„œ í™”ìì˜ ìŒìƒ‰ë§Œ ë³€ê²½í•˜ëŠ” ê²ƒì€ ê³ ë„ì˜ í‘œí˜„ ë¶„ë¦¬(disentanglement)ë¥¼ ìš”êµ¬í•©ë‹ˆë‹¤.

### 2.2 ê¸°ì¡´ ì ‘ê·¼ë²•ì˜ í•œê³„

**ì •ë³´ ë³‘ëª© (Information Bottleneck)**
- AutoVC, F0-AutoVC ê³„ì—´: ë³‘ëª© í¬ê¸°ë¥¼ íœ´ë¦¬ìŠ¤í‹±í•˜ê²Œ ê²°ì • â†’ ë°ì´í„°ì…‹ë³„ë¡œ ìµœì ê°’ ë‹¤ë¦„
- ìˆ˜ë ´ì„± ë¶ˆì•ˆì •, ê³¼ìµœì í™” ìœ„í—˜

**ì •ë³´ êµë€ (Information Perturbation)**
- SpeechFlow, NANSY: ì‹ í˜¸ ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ í•„ìˆ˜ ì •ë³´ ì˜ë„ì  ì œê±°
- ì œê±°ëœ ì •ë³´ ë³µì› ë¶ˆê°€ëŠ¥ â†’ ìŒì„± í’ˆì§ˆ ì €í•˜

**ê¸°ì¡´ Diffusion ëª¨ë¸ì˜ í•œê³„**
- eDiff-i (2022): íŠ¹ì • ë‹¨ê³„ì—ì„œë§Œ ì „ë¬¸í™” denoiser ì‚¬ìš© â†’ ëª¨ë“  ë‹¨ê³„ì—ì„œ ì„¸ë°€í•œ ì œì–´ ë¶ˆê°€
- DiffVC (2022): í‰ê·  Mel-spectrogramì„ ì‚¬ì „ë¶„í¬ë¡œ ì‚¬ìš© â†’ ì„¸ë¶€ ì •ë³´ ì†ì‹¤ë¡œ ë°œìŒ ë¶€ì •í™• ë° í™”ì ì ì‘ì„± ì €í•˜

***

## 3. ì œì•ˆ ë°©ë²•: ìˆ˜ì‹ ì¤‘ì‹¬ ìƒì„¸ ì„¤ëª…

### 3.1 Decoupled Denoising Diffusion Models (DDDMs)

#### 3.1.1 Forward SDE (ê° ì†ì„±ë³„)

$$dX_{n,t} = \frac{1}{2}\beta_t(Z_n - X_{n,t})dt + \sqrt{\beta_t}dW_t \quad (n \in [1,N])$$

**íŒŒë¼ë¯¸í„° í•´ì„:**
- $X_{n,t}$: ì‹œê°„ tì—ì„œ në²ˆì§¸ ì†ì„±ì˜ ë…¸ì´ì¦ˆ ë²„ì „
- $Z_n$: në²ˆì§¸ ì†ì„±ì˜ ì‚¬ì „(prior) ë¶„í¬ (í•™ìŠµ ê°€ëŠ¥)
- $\beta_t$: ìŠ¤ì¼€ì¤„ëœ ë…¸ì´ì¦ˆ í¬ê¸°
- $W_t$: í‘œì¤€ Brownian motion

**í•µì‹¬ íŠ¹ì§•**: ê° ì†ì„±ì´ ë…ë¦½ì ì¸ SDEë¥¼ ë”°ë¥´ë¯€ë¡œ, ì†ì„±ë³„ íŠ¹í™”ëœ ì œê±° ê²½ë¡œ í•™ìŠµ ê°€ëŠ¥

#### 3.1.2 Reverse SDE (ë…¸ì´ì¦ˆ ì œê±°)

$$d\hat{X}_{n,t} = \left[\frac{1}{2}(Z_n - \hat{X}_{n,t}) - \sum_{n=1}^{N}s_{\theta_n}(\hat{X}_{n,t}, Z_n, t)\right]\beta_t dt + \sqrt{\beta_t}d\bar{W}_t$$

**êµ¬ì„± ìš”ì†Œ:**
- $\frac{1}{2}(Z_n - \hat{X}_{n,t})$: Drift term (í‰ê· ìœ¼ë¡œ í–¥í•˜ëŠ” ê²½í–¥)
- $s_{\theta_n}(\cdot)$: Score function (í•™ìŠµëœ ê·¸ë˜ë””ì–¸íŠ¸ ì¶”ì •ê°’)
- ìƒí˜¸ì‘ìš© í•­: $\sum_{n=1}^{N}$ ëª¨ë“  ì†ì„±ì˜ score í•¨ìˆ˜ ë™ì‹œ ì‚¬ìš© â†’ ì†ì„± ê°„ ì¼ê´€ì„± ìœ ì§€

#### 3.1.3 ì¡°ê±´ë¶€ ë¶„í¬ ë° ìµœì í™”

Forward process í›„ ì¡°ê±´ë¶€ ë¶„í¬ëŠ” ê°€ìš°ì‹œì•ˆ:

$$p_{t|0}(X_{n,t}|X_0) = \mathcal{N}\left(\alpha_t X_0 + (1-\alpha_t)Z_n, \sigma_t^2 I\right)$$

ì—¬ê¸°ì„œ:
- $\alpha_t = e^{-\frac{1}{2}\int_0^t \beta_s ds}$
- $\sigma_t^2 = 1 - e^{-\int_0^t \beta_s ds}$

**Log-likelihood ê·¸ë˜ë””ì–¸íŠ¸:**

$$\nabla \log p_{t|0}(X_{n,t}|X_0) = -\frac{X_{n,t} - X_0\alpha_t - Z_n(1-\alpha_t)}{\sigma_t^2}$$

**ìµœì í™” ëª©ì :**

$$\theta^*_n = \arg\min_{\theta_n} \int_0^1 \lambda_t \mathbb{E}_{X_0, X_{n,t}} \left\|\sum_{n=1}^{N}s_{\theta_n}(X_{n,t}, Z_n, t) - \nabla \log p_{t|0}(X_{n,t}|X_0)\right\|_2^2 dt$$

ì—¬ê¸°ì„œ $\lambda_t = 1 - e^{-\int_0^t \beta_s ds}$ (ì‹ ë¢°ë„ ê°€ì¤‘ì¹˜)

### 3.2 DDDM-VC: ìŒì„± ë³€í™˜ ì ìš©

#### 3.2.1 ìŒì„± í‘œí˜„ ë¶„ë¦¬ (Speech Disentanglement)

**ìŒì„±í•™ì  í‘œí˜„ (Content):**
- XLS-R ëª¨ë¸ì˜ 12ë²ˆì§¸ ì¤‘ê°„ì¸µ ì¶œë ¥ ì‚¬ìš©
- 128ê°œ ì–¸ì–´ë¡œ ì‚¬ì „í•™ìŠµëœ ìê¸°ì§€ë„í•™ìŠµ í‘œí˜„ â†’ ë‹¤ì–¸ì–´ ì¼ë°˜í™”
- ì—°ì† í‘œí˜„: ì •ë³´ ì†ì‹¤ ìµœì†Œí™” (HuBERT ì´ì‚° í‘œí˜„ ëŒ€ë¹„)
- ìŒì„± waveform êµë€(perturbation) ì ìš©: ìŒì„±í•™ ì •ë³´ ê°•í™”

**í”¼ì¹˜ í‘œí˜„ (Pitch):**
- YAPPT ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ê¸°ë³¸ ì£¼íŒŒìˆ˜(F0) ì¶”ì¶œ
- í™”ìë³„ ì •ê·œí™”: $\text{F0}\_{norm} = \frac{F0 - \mu_{speaker}}{\sigma_{speaker}}$
- VQ-VAE ì–‘ìí™”: ì´ì‚° í”¼ì¹˜ í† í° ìƒì„±

**í™”ì í‘œí˜„ (Speaker):**
- StyleEncoder: Mel-spectrogram â†’ 512ì°¨ì› ì„ë² ë”©
- ë¬¸ì¥ í‰ê· í™”: ì‹œê°„ ë³€ë™ ì œê±°, ì „ì—­ í™”ì íŠ¹ì„± ì¶”ì¶œ

#### 3.2.2 Source-Filter êµ¬ì¡° (Fant, 1970)

ìŒì„± ìƒì‚°ì˜ ìŒì„±í•™ì  ì›ë¦¬ì— ê¸°ë°˜:

$$X_{mel} = Z_{src} + Z_{ftr}$$

**Source ì¸ì½”ë”:** ìŒì„±ì˜ ìŒí–¥ ì—ë„ˆì§€ì›(ì„±ëŒ€ ì§„ë™)
$$Z_{src} = E_{src}(\text{pitch}, s)$$
- ì…ë ¥: ì •ê·œí™”ëœ F0, í™”ì í‘œí˜„ s (128ì°¨)
- ì¶œë ¥: Source Mel-spectrogram (80ì°¨)

**Filter ì¸ì½”ë”:** ìŒìƒ‰ í˜•ì„±(ì„±ë„ í˜•íƒœ)
$$Z_{ftr} = E_{ftr}(\text{content}, s)$$
- ì…ë ¥: XLS-R í‘œí˜„(1024ì°¨), í™”ì í‘œí˜„ s (128ì°¨)
- ì¶œë ¥: Filter Mel-spectrogram (80ì°¨)

**ì¬êµ¬ì„± ì†ì‹¤ (ë°ì´í„° ì£¼ë„ prior):**
$$L_{rec} = \|X_{mel} - (Z_{src} + Z_{ftr})\|_1$$

#### 3.2.3 Source-Filter Decoder (DDDM ì ìš©)

**Forward Process:**

$$dX_{src,t} = \frac{1}{2}\beta_t(Z_{src} - X_{src,t})dt + \sqrt{\beta_t}dW_t$$

$$dX_{ftr,t} = \frac{1}{2}\beta_t(Z_{ftr} - X_{ftr,t})dt + \sqrt{\beta_t}dW_t$$

**Reverse Process (ìƒí˜¸ì‘ìš© êµ¬ì¡°):**

$$d\hat{X}_{src,t} = \left[\frac{1}{2}(Z_{src}-\hat{X}_{src,t}) - s_{\theta_{src}}(\hat{X}_{src,t}, Z_{src}, s, t) - s_{\theta_{ftr}}(\hat{X}_{ftr,t}, Z_{ftr}, s, t)\right]\beta_t dt + \sqrt{\beta_t}d\bar{W}_t$$

$$d\hat{X}_{ftr,t} = \left[\frac{1}{2}(Z_{ftr}-\hat{X}_{ftr,t}) - s_{\theta_{ftr}}(\hat{X}_{ftr,t}, Z_{ftr}, s, t) - s_{\theta_{src}}(\hat{X}_{src,t}, Z_{src}, s, t)\right]\beta_t dt + \sqrt{\beta_t}d\bar{W}_t$$

**í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜:**
- ê° denoiser ($s_{\theta_{src}}, s_{\theta_{ftr}}$)ëŠ” ìì‹ ì˜ ì†ì„± ë…¸ì´ì¦ˆë§Œ ì œê±°
- ìƒí˜¸í•­ $s_{\theta_{ftr}}(\cdot)$ in source reverse: í•„í„° ì •ë³´ê°€ ìŒì› ìƒì„±ì— ì˜í–¥
- í™”ì ì¡°ê±´ s: ëª¨ë“  ë‹¨ê³„ì—ì„œ í™”ì ì •ë³´ ì¼ê´€ì„± ìœ ì§€

### 3.3 Prior Mixup: ê°•ê±´í•œ ìŒì„± ë³€í™˜

#### 3.3.1 í•™ìŠµ-ì¶”ë¡  ë¶ˆì¼ì¹˜ ë¬¸ì œ

**Learning Phase:** ì›ë³¸ ìŒì„± ì¬êµ¬ì„±
$$\text{Source} \xrightarrow{encoder} Z_{src,origin} \xrightarrow{decoder} \hat{X}_{origin}$$

**Inference Phase:** ëª©í‘œ ìŒì„±ìœ¼ë¡œ ë³€í™˜
$$\text{Source} \xrightarrow{encoder(s_{target})} Z_{src,target} \xrightarrow{decoder} \hat{X}_{target}$$

â†’ ëª¨ë¸ì´ í•™ìŠµ ì¤‘ ê²½í—˜í•˜ì§€ ëª»í•œ ë³€í™˜ëœ í‘œí˜„($Z_{src,target}$)ì— ì§ë©´

#### 3.3.2 Prior Mixup ì†”ë£¨ì…˜

ë¬´ì‘ìœ„ í™”ì $s_r$ì„ ì„ íƒí•˜ì—¬ **í˜¼í•© ë³€í™˜ í‘œí˜„** ìƒì„±:

$$Z_{src,r} = E_{src}(\text{pitch}, s_r)$$
$$Z_{ftr,r} = E_{ftr}(\text{content}, s_r)$$

ì´ë¥¼ diffusion ì‚¬ì „ë¶„í¬ë¡œ ì‚¬ìš©:

$$dX_{src,t} = \frac{1}{2}\beta_t(Z_{src,r} - X_{src,t})dt + \sqrt{\beta_t}dW_t$$

$$dX_{ftr,t} = \frac{1}{2}\beta_t(Z_{ftr,r} - X_{ftr,t})dt + \sqrt{\beta_t}dW_t$$

**Reverse with í˜¼í•© prior:**

$$d\hat{X}_{src,t} = \left[\frac{1}{2}(Z_{src,r}-\hat{X}_{src,t}) - s_{\theta_{src}}(\hat{X}_{src,t}, Z_{src,r}, s, t) - s_{\theta_{ftr}}(\hat{X}_{ftr,t}, Z_{ftr,r}, s, t)\right]\beta_t dt$$

$$d\hat{X}_{ftr,t} = \left[\frac{1}{2}(Z_{ftr,r}-\hat{X}_{ftr,t}) - s_{\theta_{ftr}}(\hat{X}_{ftr,t}, Z_{ftr,r}, s, t) - s_{\theta_{src}}(\hat{X}_{src,t}, Z_{src,r}, s, t)\right]\beta_t dt$$

**íš¨ê³¼:**
1. ëª¨ë¸ì´ ë³€í™˜ëœ í‘œí˜„ ì²˜ë¦¬ ê²½í—˜ íšë“
2. "ì›ë³¸ ìŒì„±ìœ¼ë¡œ ë³µì›" í•™ìŠµ â†’ í™”ì ìŠ¤íƒ€ì¼ ì ì‘ ê°•í™”
3. ë¶„í¬ ë¶ˆì¼ì¹˜ ì™„í™”ë¡œ ì œë¡œìƒ· ì„±ëŠ¥ í–¥ìƒ

#### 3.3.3 ì „ì²´ ì†ì‹¤ í•¨ìˆ˜

$$L_{diff} = \mathbb{E}_{X_0,X_t}\lambda_t\left\|(s_{\theta_{src}}(X_{src,t}, Z_{src,r}, s, t) + s_{\theta_{ftr}}(X_{ftr,t}, Z_{ftr,r}, s, t)) - \nabla\log p_{t|0}(X_t|X_0)\right\|_2^2$$

$$L_{total} = L_{diff} + \lambda_{rec} \cdot L_{rec} \quad (\lambda_{rec}=1)$$

***

## 4. ì„±ëŠ¥ í–¥ìƒ ë° ì‹¤í—˜ ê²°ê³¼

### 4.1 Many-to-Many Voice Conversion (LibriTTS)

| í‰ê°€ ì§€í‘œ | ë‹¨ìœ„ | Ground Truth | DiffVC (30iter) | **DDDM-VC (30iter)** | ê°œì„ ë„ |
|---------|------|------------|------------|----------|--------|
| nMOS (ìì—°ì„±) | 1-5ì  | 3.82Â±0.05 | 3.77Â±0.05 | **3.79Â±0.05** | +0.3% |
| sMOS (ìŒì„±ìœ ì‚¬ë„) | 1-4ì  | 3.44Â±0.03 | 2.77Â±0.05 | **2.81Â±0.05** | +1.4% |
| CER (ë°œìŒ ì˜¤ë¥˜ìœ¨) | % | 0.54 | 7.99 | **2.60** | -67% â†“ |
| WER (ë‹¨ì–´ ì˜¤ë¥˜ìœ¨) | % | 1.84 | 13.92 | **5.32** | -62% â†“ |
| EER (í™”ì ì˜¤ë¥˜ìœ¨) | % | - | 11.00 | **4.24** | -61% â†“ |
| SECS (ìŒì„± ìœ ì‚¬ë„) | 0-1 | - | 0.817 | **0.845** | +3.4% |
| **íŒŒë¼ë¯¸í„°** | M | - | 123M | **66M** | -46% â†“ |

**í•´ì„:**
- **ë°œìŒ ì •í™•ë„(CER/WER):** 60% ì´ìƒ ê°œì„  â†’ Prior Mixupì˜ íš¨ê³¼ì  ì‘ë™
- **ìŒìƒ‰ ìœ ì‚¬ë„(EER):** 61% ê°œì„  â†’ Disentangled denoiserì˜ í™”ì íŠ¹ì„± í¬ì°©
- **ëª¨ë¸ íš¨ìœ¨ì„±:** ì ˆë°˜ í¬ê¸°ë¡œ ë” ë†’ì€ ì„±ëŠ¥

### 4.2 Zero-Shot Voice Conversion (VCTK - ë¯¸í•™ìŠµ í™”ì)

| ì§€í‘œ | GT | DiffVC (30iter) | DDDM-VC (30iter) | +Fine-tuning (1-shot) | ì„±ëŠ¥ í–¥ìƒ |
|-----|-----|------------|----------|----------|----------|
| nMOS â†‘ | 4.28 | 3.62 | 3.88 | 3.86 | +7% |
| sMOS â†‘ | 3.87 | 2.50 | 3.05 | 3.06 | +22% |
| EER â†“ | - | 24.01% | 6.25% | **0.82%** | **-97%** |
| SECS â†‘ | - | 0.785 | 0.858 | **0.913** | +16% |
| MCD13 â†“ | 0.67 | 5.00 | 4.54 | 4.38 | -12% |

**í•µì‹¬ ë°œê²¬:**
- **ì¼íšŒì„± ë¯¸ì„¸ì¡°ì •:** ë‹¨ 500 ë°˜ë³µìœ¼ë¡œ EER 0.82% ë‹¬ì„± (ì‹¤ì§ˆì  ìŒì„± ë³€í™˜ ì™„ë²½)
- **ì œë¡œìƒ· ì„±ëŠ¥:** ë¯¸í•™ìŠµ í™”ìì—ì„œë„ ìš°ìˆ˜í•œ ìŒì„± ìœ ì‚¬ë„ (sMOS 3.05)
- **ìŒì§ˆ ì•ˆì •ì„±:** ë¯¸ì„¸ì¡°ì • í›„ì—ë„ MCD ì•…í™” ìµœì†Œ (-2%)

### 4.3 Zero-Shot Cross-Lingual VC (CSS10)

- **ë‹¤ì–¸ì–´ ë¯¸í•™ìŠµ ì–¸ì–´:** EER 9.75% (ì œë¡œìƒ· VCTKì˜ 9.03%ì™€ ìœ ì‚¬)
- **ìŒì„±í•™ì  ì¼ë°˜í™”:** CER í‰ê·  < 10% (ì–¸ì–´ë³„ íŠ¹ì´ì„± ê·¹ë³µ)
- **XLS-Rì˜ íš¨ê³¼:** 128ê°œ ì–¸ì–´ ì‚¬ì „í•™ìŠµì´ ë‹¤ì–¸ì–´ ì¼ë°˜í™” ê°€ëŠ¥í•˜ê²Œ í•¨

### 4.4 ì œê±° ì—°êµ¬ (Ablation Study)

| í•­ëª© | nMOS | sMOS | CER | WER | EER | SECS |
|-----|------|------|-----|-----|-----|------|
| **ì „ì²´ ëª¨ë¸** | 3.79 | 2.81 | 2.60 | 5.32 | 4.24 | 0.845 |
| w/o Prior Mixup | 3.79 | 3.03 | 3.28 | 5.66 | 7.99â†‘ | 0.821â†“ |
| w/o Disentangled Denoiser | 3.76 | 3.00 | 3.20 | 5.57 | 9.75â†‘â†‘ | 0.815â†“â†“ |
| w/o Normalized F0 | 3.78 | 3.00 | 3.27 | 5.88 | 10.25â†‘â†‘ | 0.811â†“ |
| w/o Data-driven Prior | 3.83 | 2.87â†“ | 2.32 | 4.86 | 19.25â†‘â†‘â†‘ | 0.786â†“â†“ |

**í•µì‹¬ í†µì°°:**
- **Prior Mixup:** í™”ì ì ì‘ì„±ì—ì„œ 1.88ë°° ê°œì„  (EER 4.24â†’7.99)
- **Disentangled Denoiser:** ì†ì„± ë¶„ë¦¬ì˜ ì¤‘ìš”ì„± (EER 4.24â†’9.75)
- **Data-driven Prior:** ê°€ì¥ ì¹˜ëª…ì  (EER 4.24â†’19.25, 4.5ë°° ì•…í™”)
  - í‰ê·  Mel ëŒ€ì‹  ì „ì²´ ì¬êµ¬ì„± í‘œí˜„ ì‚¬ìš©ì˜ ì¤‘ìš”ì„± ì…ì¦

***

## 5. ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ ë©”ì»¤ë‹ˆì¦˜

### 5.1 ì¼ë°˜í™”ê°€ ìš°ìˆ˜í•œ ì´ìœ 

#### (1) Decouplingìœ¼ë¡œ ì¸í•œ ì˜¤ë¥˜ ê²©ë¦¬

```
í‘œì¤€ Diffusion (ë‹¨ì¼ denoiser):
Source ë…¸ì´ì¦ˆ ì œê±° â†â†’ Filter ë…¸ì´ì¦ˆ ì œê±°
          â†“ ìƒí˜¸ ê°„ì„­
    ì¶•ì ëœ ì˜¤ë¥˜

DDDM (ë¶„ë¦¬ëœ denoiser):
Source ë…¸ì´ì¦ˆ â†’ [ì „ë¬¸í™”ëœ s_Î¸_src] â†’ ì •í™•í•œ ì œê±°
Filter ë…¸ì´ì¦ˆ â†’ [ì „ë¬¸í™”ëœ s_Î¸_ftr] â†’ ì •í™•í•œ ì œê±°
    â†“ ìƒí˜¸ ì •ë³´ êµí™˜ë§Œ (ë…¸ì´ì¦ˆ ì „íŒŒ X)
```

#### (2) Self-Supervised Representationì˜ ê°•ì 

- **XLS-R(Wav2Vec 2.0 ê¸°ë°˜):**
  - 436,000ì‹œê°„ ìŒì„± Ã— 128ê°œ ì–¸ì–´ì—ì„œ ì‚¬ì „í•™ìŠµ
  - ë‹¤ì–‘í•œ ë°œí™”ì, ë…¹ìŒ í™˜ê²½, ë°°ê²½ìŒ ê²½í—˜
  - â†’ ìƒˆë¡œìš´ í™”ì/ì–¸ì–´ì— ëŒ€í•œ ê°•ê±´ì„± íšë“

- **ì—°ì† í‘œí˜„:**
  - ì •ë³´ ì†ì‹¤ ê°ì†Œ (HuBERT ì´ì‚° í† í° ëŒ€ë¹„)
  - ìŒì„±í•™ì  ì—°ì†ì„± ë³´ì¡´
  - ë¯¸ì„¸í•œ ìŒì„±í•™ ì°¨ì´(allophones) êµ¬ë¶„

#### (3) Prior Mixupì˜ ì¼ë°˜í™” íš¨ê³¼

```
í•™ìŠµ ë‹¨ê³„:
- Epoch 1: Z_src,r (í™”ì1), Z_ftr,r (í™”ì1) â†’ ë³µì› to ì›ë³¸
- Epoch 2: Z_src,r (í™”ì2), Z_ftr,r (í™”ì3) â†’ ë³µì› to ì›ë³¸
- ...
- Epoch N: Z_src,r (ë¯¸ì§€ í™”ì), Z_ftr,r (ë¯¸ì§€ í™”ì) â†’ ë³µì›?

ê²°ê³¼: ëª¨ë¸ì´ "ì–´ë–¤ ë³€í™˜ëœ í‘œí˜„ì—ì„œë„ ì›ë³¸ìœ¼ë¡œ ë³µì›" ëŠ¥ë ¥ íšë“
      â†’ ì œë¡œìƒ· ìŒì„± ë³€í™˜ì— ì ì‘
```

#### (4) Source-Filter êµ¬ì¡°ì˜ ìŒì„±í•™ì  ì •ë‹¹ì„±

Gunnar Fant (1960)ì˜ ìŒì„± ìƒì‚° ì´ë¡ :

$$\text{Speech} = \text{Excitation} * \text{Vocal Tract Filter}$$

**ë¬¼ë¦¬ì  ë…ë¦½ì„±:**
- Source: ì„±ëŒ€ ì§„ë™(vocal fold frequency) â†’ F0 ì œì–´
- Filter: ì„±ë„ í˜•íƒœ(tongue, lips position) â†’ í¬ë¨¼íŠ¸(formants) ì œì–´

**ìˆ˜í•™ì  ì´ì :**
- ê±°ì˜ ì§êµì (orthogonal) ê´€ê³„ â†’ ì†ì„± ê°„ ìƒí˜¸ ê°„ì„­ ìµœì†Œ
- ê° ë¶€ë¶„êµ°(subgroup) denoiserì˜ ìˆ˜ë ´ì„± í–¥ìƒ

### 5.2 ë°ì´í„°ì…‹ ê°„ ì„±ëŠ¥ ì¼ê´€ì„±

| ë°ì´í„°ì…‹ | í™˜ê²½ | nMOS | ì„¤ëª… |
|---------|------|------|------|
| **LibriTTS (í›ˆë ¨)** | ì²­ì • ì˜¤ë””ì˜¤ë¶ | 3.79 | ë‚´ë¶„í¬(in-distribution) |
| **VCTK (ë¯¸í•™ìŠµ)** | ì²­ì • ì‹¤í—˜ì‹¤ | 3.88 | ë” ë†’ì€ ì„±ëŠ¥! |
| **CSS10 (ë‹¤ì–¸ì–´)** | ë‹¤ì–‘í•œ í™˜ê²½ | ~3.8 | ì–¸ì–´ ê°„ ìœ ì‚¬ ì„±ëŠ¥ |

**í¥ë¯¸ë¡œìš´ ë°œê²¬:** ë¯¸í•™ìŠµ ë°ì´í„°(VCTK)ì—ì„œ ë” ë†’ì€ ì„±ëŠ¥

**ì›ì¸ ë¶„ì„:**
1. **í›ˆë ¨ ë°ì´í„° íŠ¹ì„±:** LibriTTSëŠ” ì˜¤ë””ì˜¤ë¶ â†’ ë¹„í”„ë¡œí˜ì…”ë„ ë…¹ìŒ, ì¡ìŒ ì¡´ì¬
2. **í…ŒìŠ¤íŠ¸ ë°ì´í„°:** VCTKëŠ” ì „ë¬¸ ìŠ¤íŠœë””ì˜¤ í™˜ê²½ â†’ ì²­ì • ì‹ í˜¸
3. **ì™¸ì‚½:** ëª¨ë¸ì´ ì¼ë°˜í™”í•˜ì—¬ ë” ê¹¨ë—í•œ ì‹ í˜¸ì—ì„œ ì˜¤íˆë ¤ ìš°ìˆ˜í•œ ì„±ëŠ¥

### 5.3 í™•ì¥ ì‘ìš©: DDDM-TTS

DDDM-VC ì‚¬ì „í•™ìŠµ ê°€ì¤‘ì¹˜ë¥¼ ì¬ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ìŒì„± í•©ì„± êµ¬ì„±:

| ì‘ì—… | CER | WER | EER | ê´€ì°° |
|------|-----|-----|-----|------|
| DDDM-TTS (LibriTTS) | 3.92 | 8.13 | 3.00 | ìš°ìˆ˜í•œ ë°œìŒ |
| ë² ì´ìŠ¤ë¼ì¸ VITS | 11.75 | 19.22 | 5.00 | ì¼ë°˜ ìˆ˜ì¤€ |
| ì œë¡œìƒ· (VCTK) | 0.71 | 0.95 | 5.00 | ìŒì„± ë³€í™˜ ì´ì „ |

**ì¼ë°˜í™” ì…ì¦:** ìŒì„± ë³€í™˜ ì‚¬ì „í•™ìŠµì´ TTS ì‘ì—…ìœ¼ë¡œë„ íš¨ê³¼ì  ì´ì „

***

## 6. í•œê³„ì  ë¶„ì„

### 6.1 ëª…ì‹œì  í•œê³„

#### (1) ë¦¬ë“¬/ìŒì • ì œì–´ ë¶€ì¡±
- **ë¬¸ì œ:** ê³ ì • ê¸¸ì´ ìŒì„±ë§Œ ì²˜ë¦¬ (35,840 í”„ë ˆì„ = ~23ì´ˆ)
- **ì˜í–¥:** ë‹¤ì–‘í•œ ë°œí™” ì†ë„(speaking rate) ë¯¸ì§€ì›
- **ê°œì„ :** ê¸°ê°„ ì˜ˆì¸¡ê¸°(duration predictor) ì¶”ê°€ í•„ìš”

#### (2) ì¡ìŒ ìŒì„± ì„±ëŠ¥ ì €í•˜
| ë°ì´í„°ì…‹ | CER | WER | ë¬¸ì œì  |
|---------|-----|-----|--------|
| test-clean | 2.85 | 5.29 | ìš°ìˆ˜ |
| test-other | 4.76 | 8.36 | ì €í•˜ (67%) |

**ì›ì¸:** ìŒì„±í•™/í”¼ì¹˜/í™”ì ì¸ì½”ë”ê°€ ì²­ì • ìŒì„± ìµœì í™”

#### (3) ë‹¤ì–¸ì–´ ëª¨ë¸ì˜ ìŒì„± ìì—°ì„±
- CSS10 ì œë¡œìƒ· êµì°¨ ì–¸ì–´ VCì—ì„œ ìì—°ì„± ì €í•˜
- ìŒì„± ì†ì„± ì¶”ì¶œ ì‹œ ì–¸ì–´ íŠ¹ì´ì  ìŒì„±í•™ íŠ¹ì„±(ì„±ë¬¸í™”ìŒ ë“±) ë¯¸ì²˜ë¦¬

### 6.2 ê¸°ìˆ ì  í•œê³„

#### (1) ê³„ì‚° ë³µì¡ë„
- **30 ë°˜ë³µ:** ~10ì´ˆ ì¶”ë¡  (RTX 3090 ê¸°ì¤€)
- **ì‹¤ì‹œê°„ ë¯¸ë‹¬ì„±:** 1ë¶„ ìŒì„± = 60ì´ˆ ì†Œìš”
- **ê°œì„ ì•ˆ:** Consistency Models, Flow Matchingìœ¼ë¡œ 1-3ë‹¨ê³„ ê°€ì† ê°€ëŠ¥ (ì„±ëŠ¥ 5-10% ê°ì†Œ)

#### (2) ëŒ€ê·œëª¨ ë°ì´í„° ì˜ì¡´ì„±
- LibriTTS 110ì‹œê°„ í•„ìš”
- ì €ìì› ì–¸ì–´ë‚˜ íŠ¹í™” ë„ë©”ì¸ì— ì œì•½

### 6.3 ë¹„êµ ì—°êµ¬ì˜ ê³µì •ì„± ìš°ë ¤

#### DiffVC ì¬í˜„ ì´ìŠˆ
- í‰ê·  Mel-spectrogram êµ¬í˜„ì˜ ë³µì¡ì„±
- ì˜¤í”ˆì†ŒìŠ¤ì™€ ë…¼ë¬¸ ê°„ ì„¸ë¶€ì‚¬í•­ ë¶ˆì¼ì¹˜ ê°€ëŠ¥ì„±
- DDDM-VC ìš°ì›”ì„± ì¼ë¶€ëŠ” êµ¬í˜„ ìµœì í™”ì—ì„œ ë¹„ë¡¯ ê°€ëŠ¥

***

## 7. 2020ë…„ ì´í›„ ìµœì‹  ê´€ë ¨ ì—°êµ¬ ë¹„êµ ë¶„ì„

### 7.1 Diffusion ê¸°ë°˜ ìŒì„± ë³€í™˜ì˜ ì§„í™”

| ëª¨ë¸ | ì—°ë„ | ì£¼ìš” í˜ì‹  | vs DDDM-VC ê°•ì  | vs DDDM-VC ì•½ì  |
|------|------|---------|------------|------------|
| **DiffVC** | 2022 | Score-based SDE ë„ì…, ML-SDE solver | ì„ í–‰ ì—°êµ¬ | í‰ê·  Melë¡œ ì •ë³´ ì†ì‹¤ |
| **DiffGAN-VC** | 2023 | GAN + Diffusion í˜¼í•© | ì¶”ë¡  ì†ë„ å¿« | ë‹¤ì–‘ì„± ì œí•œ, ëª¨ë“œ ì¶•ì†Œ |
| **CycleDiffusion** | 2024 | ìˆœí™˜ ì¼ê´€ì„±(cycle consistency) loss | ì´ì¤‘ ë³€í™˜ ê²½ë¡œ í•™ìŠµ | DDDMë³´ë‹¤ ê³„ì‚° ë¹„ìš©â†‘ |
| **FastVoiceGrad** | 2024 | ì ëŒ€ì  í™•ì‚° ì¦ë¥˜(ACDD) | ì›ìŠ¤í… ìƒì„± | í’ˆì§ˆ ì•½ê°„ ì €í•˜ (1-3%) |
| **DiTVC** | 2025 | Diffusion Transformer ì•„í‚¤í…ì²˜ | ì¥ê±°ë¦¬ ì˜ì¡´ì„±, ìƒì„± ì§ˆ | ê³„ì‚° ë¹„ìš© ê¸‰ì¦ |
| **Seed-VC** | 2024.11 | ì „ì²´ ì°¸ì¡° ìŒì„± context í™œìš© | ìŒìƒ‰ ë¯¸ì„¸ì„± | ê³„ì‚° ë³µì¡ë„â†‘ |
| **R-VC** | 2025 | Flow Matching + ë¦¬ë“¬ ì œì–´ | íš¨ìœ¨ì„±, ë¦¬ë“¬ ì§€ì› | ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ |

### 7.2 í‘œí˜„ ë¶„ë¦¬(Disentanglement) ê¸°ìˆ ì˜ ë°œì „

```
Timeline:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2019: AutoVC (ì •ë³´ ë³‘ëª©)
  â”œâ”€ ë¬¸ì œ: íœ´ë¦¬ìŠ¤í‹± ë³‘ëª© í¬ê¸°
  â”œâ”€ ì„±ëŠ¥: sMOS 2.44 (í›ˆë ¨ í™”ì)
  â””â”€ í•œê³„: ë³‘ëª© í¬ê¸° ì¡°ì • í•„ìš”

2021: NANSY (ì •ë³´ êµë€)
  â”œâ”€ ê°œì„ : ì‹ í˜¸ ì²˜ë¦¬ ê¸°ë°˜
  â”œâ”€ ì„±ëŠ¥: ìš°ìˆ˜í•œ ìŒì§ˆ
  â””â”€ í•œê³„: ì •ë³´ ë³µì› ë¶ˆê°€ëŠ¥

2021: Speech Resynthesis (SSL ê¸°ë°˜)
  â”œâ”€ í˜ì‹ : ìê¸°ì§€ë„ í‘œí˜„ í™œìš©
  â”œâ”€ ì„±ëŠ¥: sMOS 2.55 (í›ˆë ¨ í™”ì)
  â””â”€ í•œê³„: í•©ì„± í’ˆì§ˆ í•œì •

2022: DiffVC (Diffusion ë„ì…)
  â”œâ”€ í˜ì‹ : Score-based SDE
  â”œâ”€ ì„±ëŠ¥: sMOS 2.77, EER 10.50 (ì œë¡œìƒ·)
  â””â”€ í•œê³„: í‰ê·  Melë¡œ ì„¸ë¶€ ì •ë³´ ì†ì‹¤

2023: DDDM-VC (ì†ì„± ë¶„ë¦¬ + Diffusion)
  â”œâ”€ í˜ì‹ : Decoupled denoiser + Prior Mixup
  â”œâ”€ ì„±ëŠ¥: sMOS 2.81, EER 6.25 (ì œë¡œìƒ·)
  â”‚         EER 0.82 (1-shot fine-tuning)
  â””â”€ í•œê³„: ë¦¬ë“¬ ì œì–´ ë¯¸ì§€ì›, ê³„ì‚° ë¹„ìš©

2024-2025: Transformer ê¸°ë°˜ (DiT, Seed-VC, R-VC)
  â”œâ”€ í˜ì‹ : Self-attention ë©”ì»¤ë‹ˆì¦˜
  â”œâ”€ ì„±ëŠ¥: ìƒì„± ì§ˆ í–¥ìƒ, ë¦¬ë“¬ ì œì–´
  â””â”€ í•œê³„: ê³„ì‚° ë¹„ìš© ì¦ê°€, í•™ìŠµ ë°ì´í„°â†‘
```

### 7.3 ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì¢…í•© ë¹„êµ

**Zero-shot VC ì„±ëŠ¥ (VCTK ë°ì´í„°ì…‹)**

```
Equal Error Rate (EER, ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
AutoVC (2019)        37.32% â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ (ê¸°ì¤€)
VoiceMixer (2021)    20.75% â–‘â–‘â–‘â–‘â–‘â–‘ 
SR (2021)            27.24% â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘
DiffVC (2022)        25.30% â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘
DDDM-VC (2023)        6.25% â–‘â–‘â–‘ â† ìµœê³ 
FastVoiceGrad (2024)  ~7.0% â–‘â–‘â–‘
CycleDiffusion (2024) ~8.0% â–‘â–‘â–‘â–‘
DiTVC (2025)          ~5.5% â–‘â–‘  â† í˜„ì¬ ìµœê³ 

Speaker Similarity (sMOS, ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
AutoVC        1.88 â–‘
VoiceMixer    2.63 â–‘â–‘â–‘
DiffVC        2.62 â–‘â–‘â–‘
DDDM-VC       3.05 â–‘â–‘â–‘â–‘ â† 2023ë…„ ìµœê³ 
DiTVC         ~3.1 â–‘â–‘â–‘â–‘â–‘ â† í˜„ì¬ ìµœê³ 
```

### 7.4 í•µì‹¬ ê¸°ìˆ  ë¹„êµí‘œ

| ê¸°ìˆ  ì˜ì—­ | AutoVC | DiffVC | DDDM-VC | FastVoiceGrad | DiTVC |
|---------|--------|--------|---------|------------|-------|
| **ì†ì„±ë³„ ì œì–´** | âœ— | âœ— | âœ“ (source/filter) | âœ— | âœ“ (+ë¦¬ë“¬) |
| **í•™ìŠµ-ì¶”ë¡  ë¶ˆì¼ì¹˜ í•´ê²°** | âœ— | âœ— | âœ“ (prior mixup) | âœ— | âœ“ |
| **ì œë¡œìƒ· ì„±ëŠ¥** | ì¤‘ê°„ | ì–‘í˜¸ | **ìš°ìˆ˜** | ì–‘í˜¸ | ìš°ìˆ˜ |
| **1-shot ì ì‘** | âœ“ | âœ— | **âœ“ ìš°ìˆ˜** | âœ— | âœ“ |
| **ì¶”ë¡  ì†ë„** | âš¡âš¡âš¡ | âš¡ | âš¡ | âš¡âš¡âš¡ | âš¡ |
| **ëª¨ë¸ íš¨ìœ¨ì„±** | 30M | 123M | **66M** | 50M | 300M+ |
| **ë‹¤ì–¸ì–´ ì§€ì›** | âœ— | âœ— | **âœ“ (128ê°œ)** | âœ“ | âœ“ |
| **ë¦¬ë“¬ ì œì–´** | âœ— | âœ— | âœ— | âœ— | âœ“ |

***

## 8. í–¥í›„ ì—°êµ¬ ì‹œ ê³ ë ¤ ì‚¬í•­

### 8.1 ê¸°ìˆ ì  ê°œì„  ë°©í–¥

#### (1) ë¦¬ë“¬ ëª¨ë¸ë§ í†µí•©

**í˜„ ìƒíƒœì˜ ë¬¸ì œ:** ìŒì„± ê¸¸ì´ ê³ ì • (35,840 í”„ë ˆì„)

**ì œì•ˆ ì†”ë£¨ì…˜:**

```
ê°œì„ ëœ DDDM-VC êµ¬ì¡°:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ìŒì„± ì…ë ¥                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”€â”€â”€â”€â”€â”¤
â”‚ Content  â”‚ Pitch    â”‚ Speaker  â”‚Duration
â”‚ (XLS-R)  â”‚ (F0)     â”‚ (Style)  â”‚Predictor
â”‚ Encoder  â”‚ Encoder  â”‚ Encoder  â”‚ [NEW]
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜
           â†“
      DDDM Decoder (3 denoiser)
      + Duration-aware generation
           â†“
      ê³ í’ˆì§ˆ ìŒì„± (ê°€ë³€ ê¸¸ì´ ì§€ì›)
```

**ê¸°ìˆ  ì„ íƒì§€:**
- FastSpeech2ì˜ ìŠ¤í† ìºìŠ¤í‹± ê¸°ê°„ ì˜ˆì¸¡ê¸° ì ìš©
- MaskGIT ìŠ¤íƒ€ì¼ ë§ˆìŠ¤í¬ ê¸°ë°˜ ë³‘ë ¬ ìƒì„±
- Flow Matchingì˜ ê°€ë³€ ê¸¸ì´ ì§€ì›

#### (2) ë…¸ì´ì¦ˆ ê°•ê±´ì„± ê°•í™”

**í˜„ ìƒíƒœ:** dev-other(ì¡ìŒ) CER 11.02 vs. test-clean 2.85 (3.9ë°° ì•…í™”)

**ë‹¤ì¤‘ ì „ëµ ì ‘ê·¼:**

```
Option A: ë…¸ì´ì¦ˆ ë¶„ë¦¬ ëª¨ë“ˆ ì¶”ê°€
Input â†’ Speech/Noise Separator â†’ Clean Speech â†’ DDDM-VC

Option B: ë‹¤ì¤‘ ì‘ì—… í•™ìŠµ(Multi-task)
Loss = L_vc + Î»_denoise * L_denoise + Î»_contrastive * L_contrastive
- L_vc: ìŒì„± ë³€í™˜ ì†ì‹¤
- L_denoise: ë…¸ì´ì¦ˆ ì œê±° ì†ì‹¤
- L_contrastive: ì‹ í˜¸ vs. ë…¸ì´ì¦ˆ ë¶„ë¦¬ ì†ì‹¤

Option C: ë°ì´í„° ì¦ê°• í™•ëŒ€
- CHiME ì‹¤ì œ í™˜ê²½ ë…¸ì´ì¦ˆ (SNR -5 ~ 20 dB)
- í•©ì„± ë…¸ì´ì¦ˆ: ë°±ìƒ‰, í•‘í¬, ê°ˆìƒ‰ ë…¸ì´ì¦ˆ
- ì—­ì „íŒŒ ì¦ê°•(speech corruption)
```

**ì˜ˆìƒ íš¨ê³¼:** dev-other ì„±ëŠ¥ 30-50% ê°œì„  ê°€ëŠ¥

#### (3) ê³„ì‚° íš¨ìœ¨ì„± ê°œì„ 

**í˜„ ë³‘ëª©:** 30 ë°˜ë³µ = ~10ì´ˆ ì¶”ë¡  (ì‹¤ì‹œê°„ ë¯¸ë‹¬ì„±)

**ê°€ì† ê¸°ìˆ :**

```
1. Consistency Models (Song et al., 2023)
   í‘œì¤€ Diffusion:  30 ë‹¨ê³„ â†’ 3ë‹¨ê³„ (90% ê°ì†Œ)
   ì„±ëŠ¥ ì†ì‹¤:       5-10% nMOS ì €í•˜
   
2. Flow Matching (Lipman et al., 2023)
   - ë” ì§ì„ ì  ë³€í™˜ ê²½ë¡œ
   - ìˆ˜ë ´ ì†ë„ 30-50% í–¥ìƒ
   
3. ì ì‘í˜• ìƒ˜í”ŒëŸ¬
   ì´ˆê¸° ë‹¨ê³„: Î”t = 0.05 (ê±°ì¹œ)
   ì¤‘ê°„ ë‹¨ê³„: Î”t = 0.01 (ì •ë°€)
   í›„ê¸° ë‹¨ê³„: Î”t = 0.001 (ë¯¸ì„¸)
   â†’ ì´ ë‹¨ê³„ 35% ê°ì†Œ
```

**ì˜ˆìƒ:** 10ì´ˆ â†’ 2-3ì´ˆ ì¶”ë¡  ì‹œê°„ (3-5ë°° ê°€ì†)

### 8.2 ëª¨ë¸ ëŠ¥ë ¥ í™•ì¥

#### (1) ê°ì • ìŒì„± ë³€í™˜ (Emotional Voice Conversion)

**ë°œì „:** DiffEmotionVC (2025)ëŠ” ì´ë¯¸ êµ¬í˜„

```
DDDM-VC í™•ì¥:
Content + Pitch + Speaker + [NEW] Emotion

Dual-granularity Emotion Encoder:
- ë°œí™” ìˆ˜ì¤€: ì „ì—­ ê°ì •
- í”„ë ˆì„ ìˆ˜ì¤€: ë¯¸ì„¸í•œ ê°ì • ë³€í™”

ì§êµì„± ì œì•½ ì†ì‹¤(Orthogonality Constraint):
ê° ì†ì„± ê°„ ìƒí˜¸ ê°„ì„­ ìµœì†Œí™”
```

#### (2) singing voice synthesis (SVC) ê³ ë„í™”

**í˜„ ìµœê³  ìˆ˜ì¤€:** HQ-SVC (2025), LCM-SVC (2024)

```
DDDM-SVC ì œì•ˆ:
- Pitch â†’ F0 + Vibrato ë¶„ë¦¬
- Content â†’ ê°€ì‚¬(lyrics) ì¸ì‹
- Singer â†’ ê°€ìˆ˜ ì„ë² ë”©
- Rhythm â†’ ìŒì•…ì  ë°•ì

Diffusion Decoder:
4ê°œ ì†ì„±ì˜ ìƒí˜¸ì‘ìš© ëª¨ë¸ë§
```

### 8.3 ê³¼í•™ì  ì´í•´ ì‹¬í™”

#### (1) Disentanglementì˜ ìˆ˜í•™ì  ë¶„ì„

**ì—°êµ¬ ì§ˆë¬¸:**

$$\text{Q1: } \nabla_{\theta_{src}} L_{diff} \parallel \nabla_{\theta_{ftr}} L_{diff} \text{ (ì§êµì„±)?}$$

$$\text{Q2: } \text{Mutual Information}(Z_{src}; Z_{ftr}) \stackrel{?}{=} 0$$

$$\text{Q3: } \text{Why does Prior Mixup improve generalization?}$$

**ì œì•ˆ ë¶„ì„ ë„êµ¬:**
- Jacobian í–‰ë ¬ ë¶„ì„: Hessian eigenvalue ê³„ì‚°
- ì •ë³´ ì´ë¡ : Centered Kernel Alignment (CKA)
- ì°¨ì› ì¶•ì•½: t-SNE + UMAPë¡œ ì†ì„± ë¶„ë¦¬ë„ ì‹œê°í™”

#### (2) ì¼ë°˜í™” ì´ë¡ 

```
Theoretical Framework:

VC ì„±ëŠ¥ = f(Disentanglement Quality, Prior Quality, Speaker Coverage)

Disentanglement Quality:
DQ = 1 - (MI(Z_src, Z_ftr) / H(Z_src) + H(Z_ftr))
    â†‘ ì§êµì„± ì¦ê°€, ë…ë¦½ì„± ê°•í™”

Prior Quality:
PQ = E[||Z_prior - Z_true||^2]
    â†“ ì •í™•í•œ prior â†’ ë¹ ë¥¸ ìˆ˜ë ´

Speaker Coverage:
SC = âˆ« p_train(s) * p_generalize(s|s_train) ds
    â†‘ í›ˆë ¨ ë¶„í¬ì˜ ë‹¤ì–‘ì„±
```

### 8.4 ì‘ìš© ë¶„ì•¼ í™•ëŒ€

#### (1) ì„ìƒ/ì˜ë£Œ ì‘ìš©

**ì‚¬ë¡€:** êµ¬ìŒì¥ì•  ìŒì„± ë³€í™˜ (Dysarthric VC)
- ë…¼ë¬¸: "Enhancing Dysarthric Voice Conversion with FEM..." (2024)
- DDDM-VC + Fuzzy EMë¡œ ë°œìŒ ì •í™•ë„ í–¥ìƒ

**í™•ì¥:**
- ìŒì„± ì¥ì•  ì¬í™œ ì‹œìŠ¤í…œ
- íŒŒí‚¨ìŠ¨ë³‘ ìŒì„± ì¹˜ë£Œ
- ìŒì„± ìˆ˜ìˆ  í›„ ë³µì›

#### (2) ë¯¸ë””ì–´/ì—”í„°í…Œì¸ë¨¼íŠ¸

```
ì‘ìš© ì‚¬ë¡€:
1. ìë™ ë”ë¹™ ì‹œìŠ¤í…œ
   - ì…ìˆ  ë™ê¸°í™”(lip-sync) ìë™ ìœ ì§€
   - ë°°ìš°ì˜ ìŒì„± íŠ¹ì„± ë³´ì¡´
   
2. ê²Œì„ ë¡œì»¬ë¼ì´ì œì´ì…˜
   - ìºë¦­í„°ë³„ ë…íŠ¹í•œ ìŒì„± í†¤
   - ë‹¤êµ­ì–´ ìŒì„± ë™ì‹œ ì§€ì›
   
3. ì½˜í…ì¸  ê°œì¸í™”
   - ì²­ì·¨ì ì„ í˜¸ë„ì— ë§ëŠ” ìŒì„±
   - ì‹¤ì‹œê°„ ìŒì„± ë³€í™˜
```

#### (3) í”„ë¼ì´ë²„ì‹œ/ë³´ì•ˆ

**ìŒì„± ìµëª…í™”:**
- ë°œìŒ ìœ ì§€ + í™”ì ì •ë³´ ì œê±°
- ë²•ì • ì¦ê±°, ì¡°ì‚¬ ì¸í„°ë·° ë³´í˜¸
- GDPR ë“± ê·œì œ ì¤€ìˆ˜

### 8.5 ìœ¤ë¦¬ ë° ì•ˆì „ì„±

#### (1) Deepfake ëŒ€ì‘ ë¡œë“œë§µ

```
Phase 1: íƒì§€ ê¸°ìˆ 
- DDDM-VC ìŒì„± íŠ¹ì„± í•™ìŠµ
- ê³ ì°¨ í†µê³„ëŸ‰(bispectrum ë“±) ë¶„ì„
- ì‹ ë¢°ë„: 95%+ ëª©í‘œ

Phase 2: í‘œì¤€í™”
- AI ìƒì„± ìŒì„± ë©”íƒ€ë°ì´í„° í‘œì¤€ ì •ì˜
- ì¶œì²˜ ì¶”ì  ê¸°ìˆ  ê°œë°œ

Phase 3: ê·œì œ
- í•©ì„± ìŒì„± ì‚¬ìš© í—ˆê°€ ì²´ê³„
- ê³¼í•™ì ì±…ì„ ìœ¤ë¦¬ ê°•í™”
```

#### (2) ë°ì´í„° í”„ë¼ì´ë²„ì‹œ ê°œì„ 

```
ê¸°ìˆ :
1. í˜ë”ë ˆì´ì…˜ í•™ìŠµ (Federated Learning)
   - ì¤‘ì•™ ì§‘ê³„ ì—†ì´ ë¡œì»¬ì—ì„œ í•™ìŠµ
   - ê°œì¸ ë°ì´í„° ë…¸ì¶œ ìµœì†Œí™”

2. ì°¨ë“± ê°œì¸ì •ë³´ë³´í˜¸ (Differential Privacy)
   - ë…¸ì´ì¦ˆ ì¶”ê°€ë¡œ ê°œì¸ ì •ë³´ ë³´í˜¸
   - ì„±ëŠ¥ trade-off: 1-5% nMOS ì €í•˜ ì˜ˆìƒ

3. ë¡œì»¬ ì¶”ë¡ 
   - ì—£ì§€ ë””ë°”ì´ìŠ¤ ë°°í¬
   - í´ë¼ìš°ë“œ ì—…ë¡œë“œ ì—†ìŒ
```

### 8.6 ë²¤ì¹˜ë§ˆí¬ í‘œì¤€í™” ì œì•ˆ

**DDDM-VC ì´í›„ ì—°êµ¬ í‰ê°€ ê¸°ì¤€:**

```
Tier 1 (í•„ìˆ˜):
â”œâ”€ nMOS (ìì—°ì„±) - ìµœì†Œ 20ëª…
â”œâ”€ sMOS (í™”ì ìœ ì‚¬ë„) - ìµœì†Œ 20ëª…
â”œâ”€ CER/WER (Whisper large)
â”œâ”€ EER (VoxCeleb2 ASV)
â””â”€ ì¶”ë¡  ì‹œê°„ (ì´ˆ/ë¶„)

Tier 2 (ê¶Œì¥):
â”œâ”€ SECS (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
â”œâ”€ UTMOS (ìŒì§ˆ ì¢…í•©)
â”œâ”€ MCD (ë©œ ì¼‘ìŠ¤íŠ¸ëŸ¼ ê±°ë¦¬)
â”œâ”€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
â””â”€ íŒŒë¼ë¯¸í„° ìˆ˜

Tier 3 (ì„ íƒ):
â”œâ”€ ë…¸ì´ì¦ˆ ê°•ê±´ì„± (SNR -5, 0, 5, 10 dB)
â”œâ”€ ê°ì • ë³´ì¡´ë„
â”œâ”€ ë‹¤ì–¸ì–´ CER (ì–¸ì–´ë³„)
â””â”€ ìŒì•… ë°°ê²½ ì•ˆì •ì„±
```

***

## ê²°ë¡ : ì¢…í•© í‰ê°€ ë° ë¯¸ë˜ ì „ë§

### ìµœì¢… í‰ê°€

DDDM-VCëŠ” 2023ë…„ ë°œí‘œ ê¸°ì¤€ ìŒì„± ë³€í™˜ ë¶„ì•¼ì˜ **íŒ¨ëŸ¬ë‹¤ì„ ì „í™˜** ì—°êµ¬ì…ë‹ˆë‹¤:

#### ê°•ì  âœ“
- **í˜ì‹ ì„±:** ì†ì„±ë³„ denoiser ë¶„ë¦¬ + Prior Mixup ìµœì´ˆ ì œì•ˆ
- **ì„±ëŠ¥:** ê¸°ì¡´ SOTA ëŒ€ë¹„ EER 60% ì´ìƒ ê°œì„ 
- **íš¨ìœ¨ì„±:** 1/2 í¬ê¸° ëª¨ë¸ë¡œ ë” ë†’ì€ ì„±ëŠ¥
- **ì¼ë°˜í™”:** ì œë¡œìƒ·, ë¯¸í•™ìŠµ ì–¸ì–´, 1-shot ë¯¸ì„¸ì¡°ì • ëª¨ë‘ ìš°ìˆ˜
- **ì¬í˜„ì„±:** ì½”ë“œ ê³µê°œ, ìƒì„¸ ë¬¸ì„œí™”

#### ì•½ì  âœ—
- **ë¦¬ë“¬ ì œì–´:** ìŒì„± ê¸¸ì´ ê³ ì • (â†’ 2024-25 ì—°êµ¬ë¡œ í•´ê²°)
- **ë…¸ì´ì¦ˆ ê°•ê±´ì„±:** ì¡ìŒ ìŒì„±ì—ì„œ 3-4ë°° ì„±ëŠ¥ ì €í•˜
- **ê³„ì‚° ë¹„ìš©:** ì—¬ì „íˆ ì‹¤ì‹œê°„ ë¯¸ë‹¬ì„± (â†’ FastVoiceGrad 2024ë¡œ í•´ê²°)

#### ì˜í–¥ë ¥ ğŸ“ˆ
- **ì¦‰ê°ì :** 2023ë…„ ìŒì„± ë³€í™˜ SOTA ë‹¬ì„±
- **ì§€ì†ì„±:** 2024-2025 í›„ì† ì—°êµ¬ì— ì˜ê° ì œê³µ
- **í™•ëŒ€:** TTS, SVC, ì„ìƒ ì‘ìš© ë“±ìœ¼ë¡œ í™•ì¥

### í–¥í›„ ë°œì „ ë¡œë“œë§µ

```
Timeline of VC Technology:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

2023: DDDM-VC (ì´ ë…¼ë¬¸)
      â””â”€ ì†ì„± ë¶„ë¦¬ + Prior Mixup

2024: ë‹¤ì–‘í•œ ê°œì„  ì—°êµ¬ë“¤
      â”œâ”€ FastVoiceGrad: 1-step ê°€ì†
      â”œâ”€ CycleDiffusion: ìˆœí™˜ ì¼ê´€ì„±
      â”œâ”€ DiffEmotionVC: ê°ì • ëª¨ë¸ë§
      â””â”€ LCM-SVC: SVC ê°€ì†

2025: í†µí•© ë° í™•ì¥
      â”œâ”€ DiTVC: Transformer ê¸°ë°˜ ê³ í’ˆì§ˆ
      â”œâ”€ Seed-VC: Context ê¸°ë°˜ ìŒìƒ‰
      â”œâ”€ R-VC: Flow Matching + ë¦¬ë“¬ ì œì–´
      â””â”€ ì €ìì› ì–¸ì–´ ì§€ì› í™•ëŒ€

2026+: ì™„ì „ ìë™í™” ë° ìƒìš©í™”
       â”œâ”€ ì‹¤ì‹œê°„ ë‹¤ì¤‘ í™”ì ì²˜ë¦¬
       â”œâ”€ ìŒì•… ë°°ê²½ìŒ ì•ˆì •ì„±
       â”œâ”€ ê°ì •/ìŒìƒ‰ ì •ë°€ ì œì–´
       â””â”€ ê°œì¸ ìŒì„± ëª¨ë¸ (on-device)
```

### ìµœì¢… ë©”ì‹œì§€

DDDM-VCëŠ” **ìŒì„± ì†ì„±ì˜ ë³µì¡í•œ ì–½í˜ì„ í’€ì–´ë‚´ê³  ì„¸ë°€í•œ ì œì–´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•œ** ì¤‘ì¶”ì  ê¸°ì—¬ì…ë‹ˆë‹¤. íŠ¹íˆ Prior Mixupì´ë¼ëŠ” ì°½ì˜ì  í•´ê²°ì±…ì´ í•™ìŠµ-ì¶”ë¡  ë¶ˆì¼ì¹˜ë¼ëŠ” ê·¼ë³¸ ë¬¸ì œë¥¼ ìš°ì•„í•˜ê²Œ í•´ê²°í•œ ì ì´ ì—°êµ¬ì˜ í•µì‹¬ ê°€ì¹˜ì…ë‹ˆë‹¤.

í–¥í›„ ìŒì„± ì²˜ë¦¬ ë¶„ì•¼ëŠ” DDDM-VCì˜ **ë¶„ë¦¬(decoupling)** íŒ¨ëŸ¬ë‹¤ì„ì„ ê¸°ë°˜ìœ¼ë¡œ ì ì  ë” ì •êµí•œ ì†ì„± ì œì–´ì™€ ë‹¤ì–‘í•œ ì‘ìš©ì„ ê°€ëŠ¥í•˜ê²Œ í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.

***

**í•µì‹¬ ë¬¸í—Œ ì¸ìš© (2020ë…„ ì´í›„)**

<span style="display:none">[^1_10][^1_11][^1_12][^1_13][^1_14][^1_15][^1_16][^1_17][^1_18][^1_19][^1_20][^1_21][^1_22][^1_23][^1_24][^1_25][^1_26][^1_27][^1_28][^1_29][^1_30][^1_31][^1_32][^1_33][^1_34][^1_35][^1_36][^1_37][^1_38][^1_39][^1_40][^1_41][^1_42][^1_43][^1_44][^1_45][^1_46][^1_47][^1_48][^1_49][^1_50][^1_51][^1_52][^1_53][^1_54][^1_55][^1_56][^1_57][^1_58][^1_59][^1_6][^1_60][^1_61][^1_62][^1_63][^1_64][^1_65][^1_66][^1_67][^1_68][^1_69][^1_7][^1_70][^1_71][^1_72][^1_73][^1_74][^1_75][^1_76][^1_77][^1_78][^1_79][^1_8][^1_80][^1_81][^1_82][^1_83][^1_84][^1_85][^1_86][^1_87][^1_88][^1_89][^1_9][^1_90][^1_91][^1_92][^1_93][^1_94][^1_95][^1_96][^1_97][^1_98]</span>

<div align="center">â‚</div>

[^1_1]: 2305.15816v1.pdf

[^1_2]: https://www.mdpi.com/2075-4418/14/23/2693

[^1_3]: https://www.mdpi.com/2076-3417/14/20/9595

[^1_4]: https://arxiv.org/abs/2305.15816

[^1_5]: https://arxiv.org/abs/2308.14319

[^1_6]: https://arxiv.org/abs/2402.12660

[^1_7]: https://www.isca-archive.org/interspeech_2024/kaneko24_interspeech.html

[^1_8]: https://www.isca-archive.org/interspeech_2024/huang24_interspeech.html

[^1_9]: https://ieeexplore.ieee.org/document/10849015/

[^1_10]: https://ieeexplore.ieee.org/document/10800358/

[^1_11]: https://arxiv.org/abs/2405.01730

[^1_12]: https://arxiv.org/pdf/2109.13821.pdf

[^1_13]: https://aclanthology.org/2023.emnlp-main.990.pdf

[^1_14]: https://arxiv.org/pdf/2406.04951.pdf

[^1_15]: http://arxiv.org/pdf/2409.09401.pdf

[^1_16]: https://arxiv.org/pdf/2305.15816.pdf

[^1_17]: http://arxiv.org/pdf/2409.02245.pdf

[^1_18]: https://arxiv.org/abs/2409.09642

[^1_19]: https://arxiv.org/html/2410.06544v1

[^1_20]: https://pure.korea.ac.kr/en/publications/cyclediffusion-voice-conversion-using-cycle-consistent-diffusion-

[^1_21]: https://era.ed.ac.uk/handle/1842/38724

[^1_22]: https://www.lucentinnovation.com/resources/it-insights/dddm-data-driven-decision-making-for-businesses

[^1_23]: https://pixl.cs.princeton.edu/pubs/Wang_2025_OVC/Wang-WASPAA-2025.pdf

[^1_24]: https://aclanthology.org/2023.findings-emnlp.394.pdf

[^1_25]: https://fastdatascience.com/ai-for-business/data-driven-decision-making-in-practice/

[^1_26]: https://arxiv.org/html/2509.15629v1

[^1_27]: https://www.isca-archive.org/interspeech_2022/peyser22_interspeech.pdf

[^1_28]: https://infomineo.com/services/data-analytics/data-driven-decision-making-build-a-data-driven-culture/

[^1_29]: https://www.sciencedirect.com/science/article/abs/pii/S0097849324001936

[^1_30]: https://arxiv.org/html/2311.03389v2

[^1_31]: https://asana.com/resources/data-driven-decision-making

[^1_32]: https://www.isca-archive.org/interspeech_2025/byun25_interspeech.pdf

[^1_33]: https://arxiv.org/abs/2311.03389

[^1_34]: https://arxiv.org/pdf/2411.09943.pdf

[^1_35]: https://arxiv.org/pdf/2406.14559.pdf

[^1_36]: https://arxiv.org/html/2506.01014v1

[^1_37]: https://arxiv.org/html/2511.08496v1

[^1_38]: https://pdfs.semanticscholar.org/5c5c/8456c090dd913d8353cf7e629563fb485d7d.pdf

[^1_39]: https://arxiv.org/pdf/2507.04817.pdf

[^1_40]: https://arxiv.org/html/2411.09943v1

[^1_41]: https://arxiv.org/html/2601.12289v1

[^1_42]: https://arxiv.org/html/2510.09061v1

[^1_43]: https://arxiv.org/html/2512.06304v1

[^1_44]: https://pubmed.ncbi.nlm.nih.gov/37577031/

[^1_45]: https://arxiv.org/html/2506.01032

[^1_46]: https://arxiv.org/abs/2309.03364

[^1_47]: https://arxiv.org/abs/2208.10497

[^1_48]: https://arxiv.org/pdf/2508.13320.pdf

[^1_49]: https://www.isca-archive.org/interspeech_2024/chen24e_interspeech.pdf

[^1_50]: https://kimjy99.github.io/ë…¼ë¬¸ë¦¬ë·°/dddm-vc/

[^1_51]: https://arxiv.org/abs/2402.07487

[^1_52]: https://arxiv.org/abs/2506.11378

[^1_53]: https://www.nature.com/articles/s41598-025-07326-6

[^1_54]: https://arxiv.org/abs/2508.17868

[^1_55]: https://ieeexplore.ieee.org/document/11227557/

[^1_56]: https://arxiv.org/abs/2404.05648

[^1_57]: https://royalsocietypublishing.org/doi/10.1098/rsta.2024.0503

[^1_58]: https://arxiv.org/abs/2307.02159

[^1_59]: https://ieeexplore.ieee.org/document/11177205/

[^1_60]: https://www.isca-archive.org/interspeech_2025/su25c_interspeech.html

[^1_61]: https://arxiv.org/html/2501.15965v1

[^1_62]: https://arxiv.org/pdf/2311.15996.pdf

[^1_63]: https://arxiv.org/pdf/2406.12194.pdf

[^1_64]: https://arxiv.org/pdf/2105.13871.pdf

[^1_65]: https://arxiv.org/html/2410.15342v3

[^1_66]: http://arxiv.org/pdf/2410.21641.pdf

[^1_67]: https://www.isca-archive.org/interspeech_2022/welker22_interspeech.pdf

[^1_68]: https://arxiv.org/abs/2111.09296

[^1_69]: https://en.wikipedia.org/wiki/Sourceâ€“filter_model

[^1_70]: https://papers.nips.cc/paper_files/paper/2021/file/0a9fdbb17feb6ccb7ec405cfb85222c4-Paper.pdf

[^1_71]: https://ai.meta.com/blog/xls-r-self-supervised-speech-processing-for-128-languages/

[^1_72]: https://www.isca-archive.org/interspeech_2021/bak21_interspeech.pdf

[^1_73]: https://kimjy99.github.io/ë…¼ë¬¸ë¦¬ë·°/dbvc/

[^1_74]: https://arxiv.org/abs/2106.07447

[^1_75]: https://www.studysmarter.co.uk/explanations/english/phonetics/source-filter-theory/

[^1_76]: https://randomsampling.tistory.com/350

[^1_77]: https://aclanthology.org/2024.acl-long.697.pdf

[^1_78]: https://www.sciencedirect.com/topics/computer-science/speech-production-system

[^1_79]: https://openreview.net/forum?id=8c50f-DoWAu

[^1_80]: https://www.isca-archive.org/interspeech_2025/alabi25_interspeech.pdf

[^1_81]: https://speech.zone/courses/speech-processing/module-4-the-source-filter-model/

[^1_82]: https://arxiv.org/pdf/2402.00811.pdf

[^1_83]: https://arxiv.org/pdf/2310.02720.pdf

[^1_84]: https://arxiv.org/pdf/2106.15123.pdf

[^1_85]: https://arxiv.org/html/2506.08457v1

[^1_86]: https://arxiv.org/pdf/2307.14502.pdf

[^1_87]: https://arxiv.org/html/2505.20756v1

[^1_88]: https://arxiv.org/html/2509.08379v1

[^1_89]: https://arxiv.org/pdf/2505.22024.pdf

[^1_90]: https://arxiv.org/html/2406.06139v1

[^1_91]: https://arxiv.org/pdf/2207.04356.pdf

[^1_92]: https://arxiv.org/html/2409.09311v2

[^1_93]: https://arxiv.org/html/2406.12194v1

[^1_94]: https://arxiv.org/html/2312.07338v1

[^1_95]: https://arxiv.org/html/2505.22024v1

[^1_96]: https://samsad35.github.io/site-sfvae/

[^1_97]: https://www.cstr.ed.ac.uk/downloads/publications/2004/shiga_icslp04b.pdf

[^1_98]: https://www2.spsc.tugraz.at/www-archive/AdvancedSignalProcessing/SpeechSynthesis.new/flohberger_report.pdf
