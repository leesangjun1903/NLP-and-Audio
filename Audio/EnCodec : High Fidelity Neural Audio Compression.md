# High Fidelity Neural Audio Compression

**핵심 주장 및 주요 기여**  
Meta AI의 EnCodec 모델은 실시간으로 동작하면서도 고품질의 오디오 압축을 달성하는 **최신 신경망 기반 오디오 코덱**이다. 이 논문의 주요 기여는 다음과 같다.

1. **단일 멀티스케일 스펙트로그램 판별기**를 사용한 간결한 적대적 손실(adversarial loss) 설계로, 다양한 주파수 해상도에서 발생하는 인공음을 효과적으로 억제하고 인지 품질을 향상시켰다.  
2. **손실 밸런서(loss balancer)** 기법을 도입하여, 손실 항(loss term)들의 그래디언트 규모에 상관없이 각 항이 전체 그래디언트에서 차지하는 비중을 직접 조절할 수 있게 해 훈련을 안정화하고 하이퍼파라미터 해석을 용이하게 만들었다.  
3. **경량 Transformer 기반 언어 모델**을 활용한 엔트로피 부호화(entropy coding)를 추가해 비트레이트를 최대 40%까지 추가 저감하면서도 실시간 처리가 가능함을 보였다.  
4. 24 kHz 단음성과 48 kHz 입체 음향 모두에서 1.5–24 kbps 범위의 비트레이트를 지원하며, Opus·EVS·Lyra-v2 등 기존 전통·신경망 코덱을 상회하는 주관적(MUSHRA)·객관적(ViSQOL, SI-SNR) 성능을 입증했다.

***

## 1. 해결하고자 하는 문제  
- 인터넷 스트리밍 트래픽의 대다수를 차지하는 오디오 데이터의 **효율적·저지연 압축** 필요성 증대  
- 낮은 비트레이트에서 기존 코덱(Opus, EVS 등)의 **음질 열화** 문제  
- 신경망 기반 압축 방법은 가능성을 보였으나, 실시간 처리·훈련 안정성·고대역폭 지원이 아직 미약  

***

## 2. 제안 방법  

### 2.1 모델 구조  
EnCodec는 크게 세 부분으로 구성된다.  
1. **인코더(Encoder)**  
   - 1D 컨볼루션 + 잔차 유닛(residual unit) × B → 다운샘플링 → 양방향 LSTM → 최종 1D 컨볼루션  
   - 스트리밍 용과 비스트리밍 용 두 가지 설정 지원  
2. **잔차 벡터 양자화(Residual Vector Quantization, RVQ)**  
   - 다수의 코드북(codebook)을 순차 적용해 잔차를 재양자화  
   - 훈련 시 코드 사용 빈도 기반 EMA 업데이트, straight-through gradient 적용  
3. **디코더(Decoder)**  
   - 인코더 구조를 전치 컨볼루션(transposed convolution)으로 역연산  

### 2.2 손실 함수  
전체 손실은 **재구성 손실**, **적대적(perceptual) 손실**, **양자화 약속(Commitment) 손실**을 결합한 형태이다.  
- 시간 도메인: $$\ell_t(x,\hat x)=\|x-\hat x\|_1$$  
- 주파수 도메인:  

$$
  \ell_f(x,\hat x)=\frac{1}{|\alpha|\cdot|s|}\sum_{i\in\alpha}\sum_{k\in e}\Bigl(\|S_k(x)-S_k(\hat x)\|_1+\alpha_i\|S_k(x)-S_k(\hat x)\|_2\Bigr)
  $$  
  
  여기서 $$S_k$$는 멜 스펙트로그램, $$e$$는 윈도우 스케일 집합  
- 적대적 손실: 멀티스케일 STFT 기반 판별기 $$D_k$$에 대한 hinge loss  
- 약속 손실(commitment loss):  

$$
  \ell_w = \sum_{c=1}^C \|z_c - q_c(z_c)\|_2^2
  $$  

- **loss balancer**를 통해 각 손실 항의 그래디언트 기여도를 직접 제어하며, 가중치 $$\lambda_i$$의 합이 1일 때 각 $$\lambda_i$$는 전체 그래디언트에서 해당 손실이 차지하는 비율이 된다.

***

## 3. 성능 향상 및 한계  

### 3.1 주관적·객관적 평가  
- MUSHRA 테스트에서 3 kbps 환경에서 EnCodec은 Lyra-v2(6 kbps), Opus(12 kbps)보다 우수한 품질 달성  
- ViSQOL·SI-SNR 지표에서도 경쟁 모델 대비 평균 10–30% 향상  
- 스트리밍 설정(13 ms 초기 지연)과 비스트리밍 설정(1 s 초기 지연) 모두에서 높은 품질 유지  

### 3.2 한계  
- 48 kHz 스테레오 스트리밍 시 실시간 처리 속도(Real-Time Factor) < 1로, 더 가벼운 구현 또는 가속 하드웨어 필요  
- 비트레이트가 낮아질수록 Transformer 엔트로피 모델의 복잡도 제약으로 추가 압축 비율 감소  
- RVQ 코드북 개수·크기 조율, balancer 하이퍼파라미터 튜닝이 여전히 경험적  

***

## 4. 일반화 성능 향상 가능성  
- **다양한 도메인 학습**: 말소리·잡음·음악·일반 오디오 등 멀티도메인 데이터 혼합 전략으로 모델 과적합 방지  
- **적대적 손실 단순화**: 멀티스케일 STFT 판별기만으로도 고품질 달성, 구조 단순화로 일반화 안정성 강화  
- **손실 밸런서**: 손실 함수 조합에 대한 해석 가능성 확보로 도메인별 재조정 용이  
- **추가적 사전학습**: 대규모 무라벨 오디오 표현 학습(예: HuBERT)을 통해 인코더 초기화 시 일반화 성능 개선  

***

## 5. 향후 연구 영향 및 고려 사항  
EnCodec은 **실시간·저비트레이트 고품질 오디오 압축**의 새로운 기준을 제시하며, 향후 연구에서 다음을 고려하면 좋다.

1. **경량화 및 가속화**: CPU 환경에서 48 kHz 스트리밍도 실시간 달성할 수 있도록 모델 구조·코드 최적화  
2. **비지도 사전학습 활용**: 대규모 무라벨 오디오 표현을 활용해 다양한 환경·언어에서 일반화 성능 강화  
3. **내·외부 평가**: 실제 네트워크 환경(패킷 손실·재전송)에서 품질·지연·안정성 검증  
4. **윤리·공정성**: 사용자 생성 콘텐츠 압축 시 저작권·프라이버시 보호, 악용 방지 대책 마련  

EnCodec는 저비트 오디오 서비스를 더욱 **포용적**이고 **고품질**으로 발전시키는 토대를 마련한다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/39d0ed45-a3fd-4c6c-956b-a02a3c2d2a8d/2210.13438v1.pdf)
