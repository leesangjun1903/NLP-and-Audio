# MusicGen: Simple and Controllable Music Generation

## 핵심 주장과 주요 기여

**MusicGen**은 Meta AI에서 개발한 단일 단계 언어 모델 기반의 음악 생성 시스템으로, 기존의 계층적 또는 업샘플링 방식의 다단계 모델을 제거하고 효율적인 토큰 인터리빙 패턴을 통해 고품질 음악을 생성하는 혁신적인 접근법을 제시합니다.

### 주요 기여 사항

1. **단일 단계 모델**: 기존 연구들이 여러 모델을 연쇄적으로 사용하는 것과 달리, 단일 트랜스포머 언어 모델로 고품질 32kHz 음악 생성이 가능함을 증명
2. **효율적 코드북 인터리빙**: 다중 병렬 스트림의 압축된 이산 음악 표현을 효과적으로 처리하는 새로운 프레임워크 제시
3. **다중 조건부 생성**: 텍스트 설명과 멜로디 특성 모두를 조건으로 하는 통합 모델 구현
4. **스테레오 확장**: 추가 계산 비용 없이 스테레오 오디오 생성으로 확장 가능

## 해결하려는 문제와 제안 방법

### 문제 정의

음악 생성은 다음과 같은 고유한 도전과제를 가집니다:
- **높은 샘플링 레이트**: 음성(16kHz)과 달리 음악은 44.1kHz 또는 48kHz 필요
- **복잡한 구조**: 다양한 악기의 하모니와 멜로디가 만드는 복합적 구조
- **불협화음 민감성**: 인간 청취자는 멜로디 오류에 매우 민감
- **다양한 제어**: 키, 악기, 멜로디, 장르 등 다차원적 제어 필요

### 제안 방법

#### 1. 오디오 토큰화
EnCodec을 사용하여 오디오를 이산 토큰으로 변환:
- **Residual Vector Quantization (RVQ)** 사용
- K개의 병렬 코드북으로 구성: $$Q \in \{1, ..., M\}^{d \cdot f_r \times K}$$
- 각 시간 단계 t에 대해 K개의 양자화된 값 생성

#### 2. 코드북 인터리빙 패턴

**정확한 자기회귀 분해**:

$$
\forall t > 0, p_t(U_{t-1}, ..., U_0) \triangleq P[U_t|U_{t-1}, ..., U_0]
$$

**부정확한 자기회귀 분해** (효율성을 위해):

$$
p_{t,k}(V_{t-1}, ..., V_0) \triangleq P[V_{t,k}|V_{t-1}, ..., V_0]
$$

주요 인터리빙 패턴들:
- **Parallel Pattern**: $$P_s = \{(s,k) : k \in \{1,...,K\}\}$$
- **Delay Pattern**: $$P_s = \{(s-k+1,k) : k \in \{1,...,K\}, s-k \geq 0\}$$

#### 3. 조건부 생성

**텍스트 조건화**: T5 인코더를 사용하여 텍스트 설명을 조건 텐서 $$C \in R^{T_C \times D}$$로 변환

**멜로디 조건화**: 비지도 방식으로 크로마그램의 지배적 시간-주파수 빈을 선택하여 정보 병목 구현

## 모델 구조

### 전체 아키텍처
1. **코드북 투영 및 위치 임베딩**: 각 코드북별 학습된 임베딩 테이블 (N개 항목, D 차원)
2. **트랜스포머 디코더**: 
   - L개 레이어, D 차원
   - 인과적 셀프-어텐션 블록
   - 크로스-어텐션 블록 (조건 신호 처리)
   - FC 블록: D → 4D → D (ReLU 활성화)
3. **로짓 예측**: 코드북별 선형 레이어 (D → N 채널)

### 모델 크기별 성능
- **300M 파라미터**: 기본 실험용
- **1.5B 파라미터**: 최적 주관적 품질
- **3.3B 파라미터**: 향상된 텍스트 이해력

## 성능 향상

### 객관적 지표 (MusicCaps 데이터셋)
- **FAD (Fréchet Audio Distance)**: 3.8 (3.3B 모델)
- **KL Divergence**: 1.22 (최저값)
- **CLAP Score**: 0.31 (텍스트-오디오 정렬)

### 주관적 평가
- **전체 품질**: 84.8/100 (최고 성능 기준선 대비 80.5/100)
- **텍스트 관련성**: 82.47/100
- **멜로디 정렬**: 72.87/100 (멜로디 조건화 시)

### 코드북 패턴별 성능
- **Flattening**: 최고 성능이지만 높은 계산 비용 (6000 스텝)
- **Delay**: 균형잡힌 성능과 효율성 (1500 스텝)
- **Parallel**: 가장 빠르지만 낮은 품질

## 일반화 성능 향상 가능성

### 데이터셋 다양성
- **20K 시간의 라이선스 음악**: 내부 10K + ShutterStock 25K + Pond5 365K
- **장르 불균형**: Dance/EDM 장르 편중 문제 존재
- **서구 음악 편향**: 데이터셋의 문화적 다양성 부족

### 일반화 전략
1. **조건부 드롭아웃**: 훈련 시 20% 확률로 조건 제거
2. **Classifier-free Guidance**: 추론 시 가이던스 스케일 3.0 적용
3. **텍스트 증강**: 메타데이터 병합, 단어 드롭아웃 등

### 제로샷 성능
- **도메인 외 평가**: MusicCaps에서 훈련 데이터와 다른 장르에서도 안정적 성능
- **멜로디 일반화**: 비지도 크로마그램 조건화로 다양한 멜로디 구조 적응

## 한계점

### 기술적 한계
1. **세밀한 제어 부족**: Classifier-free guidance에 주로 의존, 조건 준수도의 세밀한 조정 불가
2. **오디오 데이터 증강**: 텍스트 대비 오디오 조건화를 위한 데이터 증강 기법 부족
3. **문화적 편향**: 서구 음악 위주의 데이터셋으로 인한 다양성 제약

### 성능 한계
- **기억 효과**: 긴 프롬프트에서 훈련 데이터 기억 경향 확인
- **객관적 지표 불일치**: FAD와 주관적 평가 간 상관관계 불명확
- **멜로디 조건화**: 객관적 지표 저하 (주관적 평가는 유지)

## 미래 연구에 미치는 영향

### 긍정적 영향
1. **단일 단계 패러다임**: 복잡한 다단계 시스템의 대안 제시로 후속 연구의 방향 전환 촉진
2. **효율적 토큰화**: 코드북 인터리빙 프레임워크가 다른 오디오 생성 작업에 적용 가능
3. **다중 모달 조건화**: 텍스트-멜로디 통합 조건화 방식이 멀티모달 AI 연구에 기여

### 연구 확장 가능성
- **실시간 생성**: 효율적 인터리빙으로 실시간 음악 생성 시스템 개발 가능
- **개인화 음악**: 사용자별 음악 선호도 학습을 통한 맞춤형 생성 모델
- **cross-cultural 음악**: 다양한 문화권 음악 데이터 확대를 통한 글로벌 적용성 향상

## 향후 연구 고려사항

### 데이터 측면
1. **데이터셋 다양성 확대**: 비서구 문화권 음악 데이터 수집 필요
2. **고품질 어노테이션**: 더 정교한 음악적 특성 라벨링 시스템 구축
3. **멀티링구얼 지원**: 다국어 음악 설명 데이터셋 확보

### 모델 측면
1. **세밀한 제어 메커니즘**: 조건 준수도의 동적 조정이 가능한 새로운 가이던스 방법
2. **계층적 조건화**: 장르, 악기, 감정 등 다층적 음악 속성의 독립적 제어
3. **적응형 아키텍처**: 다양한 음악 스타일에 자동 적응하는 모델 구조

### 평가 측면
1. **포괄적 평가 지표**: 음악적 일관성, 창의성, 다양성을 종합적으로 측정하는 새로운 메트릭
2. **문화적 적절성 평가**: 특정 문화권 음악의 진정성과 적절성 평가 방법론
3. **장기 품질 평가**: 30초를 넘어서는 장시간 음악의 구조적 일관성 측정

MusicGen은 음악 생성 AI의 새로운 패러다임을 제시했지만, 진정한 범용적 음악 생성 시스템을 위해서는 문화적 다양성, 세밀한 제어성, 그리고 창의적 표현력 향상이 핵심 과제로 남아있습니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/31b62317-a6bb-4698-9acf-5b31755586da/2306.05284v3.pdf)
