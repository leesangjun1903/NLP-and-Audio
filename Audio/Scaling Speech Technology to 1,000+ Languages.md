# Scaling Speech Technology to 1,000+ Languages

## 1. 핵심 주장 및 주요 기여  
Meta AI의 **MMS(Massively Multilingual Speech) 프로젝트**는 종교 텍스트(신약성서) 녹음을 기반으로 한 대규모 셀프-슈퍼바이즈드 및 파인튜닝 파이프라인을 통해  
-  언어 식별(LID) 4,017개  
-  음성인식(ASR) 1,107개  
-  음성합성(TTS) 1,107개  
언어로 **기존 대비 10–40배** 확장할 수 있음을 보였다. 이들 모델은 적은 라벨 데이터에서도 Whisper 대비 WER를 절반 이하로 낮추고, XLS-R 대비 CER을 평균 0.7 낮추며, CMU Wilderness 대비 CER을 2–5%p 개선했다.[1]

## 2. 문제 설정, 제안 기법, 모델 구조, 성능 및 한계  

### 해결하고자 하는 문제  
기존 음성 기술은 100개 안팎의 언어만 지원하며, 전 세계 7,000여 언어 중 극소수에 머문다.  
– 저자원 언어 대부분에서 라벨 데이터 부족  
– 대용량 모델이 긴 오디오를 처리하기 어려운 정렬(alignment) 문제  

### 데이터 구축 및 정렬  
1. **MMS-lab**: 성경 낭독 오디오+원문 정렬 → 1,107개 언어, 44.7K시간  
2. **MMS-unlab**: 오디오만 3,809개 언어, 7.7K시간  
– GPU 기반 CTC 강제정렬(Forced Alignment) 및 “☆토큰” 활용 → 평균 12초 분절, 메모리 O(L)로 대형 파일 처리  
– 정렬 품질 스코어 $$\frac{1}{T}\bigl(\ln P(Y_{\text{aligned}}|X)-\ln P(Y_{\text{greedy}}|X)\bigr)$$로 상위 샘플 재학습  

### 제안 모델 구조  
1. **Self-Supervised Pre-training**: wav2vec 2.0 기반, 300M·1B 파라미터 모델(MMS-(0.3B), MMS-(1B)), 1,406개 언어 491K시간 데이터  
2. **파인튜닝**  
  -  ASR: MMS(1B) + CTC 헤드 + 선택적 Language-Specific Adapter[Houlsby et al.]  
  -  LID: MMS(1B) + 선형 분류기  
  -  TTS: VITS 기반 시각모델(100K 스텝, 문자/유로만 입력)  

### 주요 수식  
– **CTC 강제정렬**: $$\hat\pi = \arg\max_{\pi\in B^{-1}(L)}\prod_{t=1}^T P(\pi_t\mid X)$$  
– **정렬 품질 스코어**:  

$$
\frac1T\Bigl[\ln P\bigl(Y_{\text{aligned}}\mid X\bigr)
-\ln P\bigl(Y_{\text{greedy}}\mid X\bigr)\Bigr]
$$  

### 성능 향상  
– **ASR**:  
  -  Whisper 대비 WER 58% 상대 감소[1]
  -  XLS-R 대비 CER 평균 0.7p 감소  
  -  1,107개 언어 ASR CER ≤5%(96% 언어)  
– **LID**: 4,017개 언어로 확장, 97.2% 정확도 유지  
– **TTS**: 1,107개 언어 MCD 평균 4.30, ASR CER ≤5%(85% 언어)  

### 한계  
- **단일 도메인(종교 텍스트)**: 일반화 위험, 평가 벤치마크(예: FLEURS) 외 타 도메인 성능 확인 필요  
- **성별 편향**: 남성 화자 다수 → MMS-ASR과 FLEURS-ASR 간 성별 CER 차이 미미  
- **편향된 언어 사용률**: 종교어(oﬀ-domain 단어) 생성 비율 MMS +0.7%p 상승  

## 3. 모델 일반화 성능 향상 가능성  
- **다중 도메인 학습**: MMS-lab+FLEURS+CommonVoice+VoxPopuli+MLS 결합 → 1,162개 언어 단일 ASR 모델, FLEURS CER 6.2%로 USM 대비 동등  
- **언어별 어댑터**: 1,107개 언어 ASR 시 어댑터 사용 → CER 저하폭 0.4p→0.2p로 방지  
- **셀프-슈퍼바이즈드 확대**: 1,406개 언어 사전학습이 XLS-R(128개) 대비 극저자원 일반화 개선  
- **강제정렬 알고리즘**: GPU 메모리 최적화 O(L)로 긴 오디오 처리 → 다양한 도메인 추출 용이  

## 4. 향후 연구 영향 및 고려 사항  
– **7,000+ 언어 확장**: 더 많은 종족어·방언 포함, 광범위 샘플 확보 전략 필요  
– **다중 작업 멀티태스크**: ASR, LID, TTS 통합 모델로 효율적 자원 활용  
– **평가 벤치마크 다각화**: 종교 외 뉴스·카카오톡·전화음성 등 실제 도메인 스펙트럼 확보  
– **윤리·문화적 고려**: 민감 종교 텍스트 사용 시 문화적·종교적 예민성 반영, 무결성 보장  

***

이 논문은 “언어 다양성” 관점에서 음성 기술의 문턱을 10–40배 낮추었으며, 대규모 셀프-슈퍼바이즈드 학습과 스케일러블 정렬 알고리즘이 일반화 성능과 자원 효율 양측을 극적으로 개선함을 보여 준다. 앞으로는 **도메인·문화적 확장**, **멀티태스크 통합**, **윤리적 프레임워크 강화**가 과제로 남는다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/e7177a88-5890-4766-aaf2-e5e68fdb9e79/2305.13516v1.pdf)ㅋ
